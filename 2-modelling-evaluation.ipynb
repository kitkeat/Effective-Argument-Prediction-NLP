{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kitkeat/Effective-Argument-Prediction-NLP/blob/main/2-modelling-evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "846e8047",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:20.338430Z",
          "iopub.status.busy": "2022-08-03T04:10:20.337968Z",
          "iopub.status.idle": "2022-08-03T04:10:20.344031Z",
          "shell.execute_reply": "2022-08-03T04:10:20.343146Z"
        },
        "id": "846e8047",
        "outputId": "95737c7e-f0e3-49ec-fc28-459f758c0c3c",
        "papermill": {
          "duration": 0.025493,
          "end_time": "2022-08-03T04:10:20.346442",
          "exception": false,
          "start_time": "2022-08-03T04:10:20.320949",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets==2.1.0\n",
            "  Downloading datasets-2.1.0-py3-none-any.whl (325 kB)\n",
            "\u001b[K     |████████████████████████████████| 325 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets==2.1.0) (6.0.1)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 43.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==2.1.0) (0.3.5.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets==2.1.0) (4.64.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==2.1.0) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets==2.1.0) (1.21.6)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.7.1-py3-none-any.whl (141 kB)\n",
            "\u001b[K     |████████████████████████████████| 141 kB 34.3 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 8.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets==2.1.0) (21.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets==2.1.0) (2.23.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 30.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets==2.1.0) (3.8.1)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets==2.1.0) (4.12.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 32.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.1.0) (4.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.1.0) (3.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets==2.1.0) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==2.1.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==2.1.0) (2022.6.15)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 55.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==2.1.0) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==2.1.0) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==2.1.0) (2.1.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==2.1.0) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==2.1.0) (1.7.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==2.1.0) (0.13.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==2.1.0) (6.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets==2.1.0) (3.8.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==2.1.0) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==2.1.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==2.1.0) (1.15.0)\n",
            "Installing collected packages: urllib3, pyyaml, fsspec, xxhash, responses, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed datasets-2.1.0 fsspec-2022.7.1 huggingface-hub-0.8.1 multiprocess-0.70.13 pyyaml-6.0 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.18.0\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 8.5 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 31.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (4.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (3.7.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (0.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.18.0) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.18.0) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0) (1.25.11)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.18.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.18.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.18.0) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=00b5dc730e2d3d5bc0156e163f8f546eea8998c525230ab3bb288441ad55029e\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece==0.1.96\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-lightning==1.6.5\n",
            "  Downloading pytorch_lightning-1.6.5-py3-none-any.whl (585 kB)\n",
            "\u001b[K     |████████████████████████████████| 585 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.5) (21.3)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.5) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.5) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.5) (4.64.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.5) (6.0)\n",
            "Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.5) (1.12.0+cu113)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.5) (2.8.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.5) (4.1.1)\n",
            "Requirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.5) (3.17.3)\n",
            "Collecting torchmetrics>=0.4.1\n",
            "  Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 55.6 MB/s \n",
            "\u001b[?25hCollecting pyDeprecate>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (2.23.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning==1.6.5) (3.0.9)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1->pytorch-lightning==1.6.5) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (1.47.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (3.4.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (1.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (0.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (0.37.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (3.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (22.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (2.1.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (0.13.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (1.7.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (1.2.0)\n",
            "Installing collected packages: torchmetrics, pyDeprecate, pytorch-lightning\n",
            "Successfully installed pyDeprecate-0.3.2 pytorch-lightning-1.6.5 torchmetrics-0.9.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics==0.9.2\n",
            "  Downloading torchmetrics-0.9.2-py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics==0.9.2) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics==0.9.2) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics==0.9.2) (1.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics==0.9.2) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics==0.9.2) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "  Attempting uninstall: torchmetrics\n",
            "    Found existing installation: torchmetrics 0.9.3\n",
            "    Uninstalling torchmetrics-0.9.3:\n",
            "      Successfully uninstalled torchmetrics-0.9.3\n",
            "Successfully installed torchmetrics-0.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb==0.12.21\n",
            "  Downloading wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.21) (7.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.21) (57.4.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.21) (2.23.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 50.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.21) (3.17.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.21) (5.4.8)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.21) (2.3)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.21) (1.15.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.21) (6.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 45.5 MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb==0.12.21) (4.1.1)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb==0.12.21) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb==0.12.21) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb==0.12.21) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb==0.12.21) (3.0.4)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=c2f4e81480b225784e679be3dd8f106689f57ae0b6b8ca937285851cbf4912e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.0 shortuuid-1.0.9 smmap-5.0.0 wandb-0.12.21\n"
          ]
        }
      ],
      "source": [
        "# # ! pip install accelerate nvidia-ml-py3\n",
        "! pip install datasets==2.1.0\n",
        "! pip install transformers==4.18.0\n",
        "! pip install sentencepiece==0.1.96\n",
        "! pip install pytorch-lightning==1.6.5\n",
        "! pip install torchmetrics==0.9.2\n",
        "! pip install wandb==0.12.21"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67e5d040",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:20.377496Z",
          "iopub.status.busy": "2022-08-03T04:10:20.376894Z",
          "iopub.status.idle": "2022-08-03T04:10:22.252350Z",
          "shell.execute_reply": "2022-08-03T04:10:22.251341Z"
        },
        "id": "67e5d040",
        "papermill": {
          "duration": 1.894221,
          "end_time": "2022-08-03T04:10:22.254831",
          "exception": false,
          "start_time": "2022-08-03T04:10:20.360610",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         os.path.join(dirname, filename)\n",
        "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "# run_type = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MRxrgzmPg4wE",
        "outputId": "9910844d-d5e2-41cf-91f2-88fcddc2299e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "MRxrgzmPg4wE",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d2d2abc7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:22.285149Z",
          "iopub.status.busy": "2022-08-03T04:10:22.283686Z",
          "iopub.status.idle": "2022-08-03T04:10:36.841733Z",
          "shell.execute_reply": "2022-08-03T04:10:36.840726Z"
        },
        "id": "d2d2abc7",
        "papermill": {
          "duration": 14.575056,
          "end_time": "2022-08-03T04:10:36.844191",
          "exception": false,
          "start_time": "2022-08-03T04:10:22.269135",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option(\"max_colwidth\", None)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding, AdamW, get_cosine_schedule_with_warmup\n",
        "from datasets import Dataset, Value, ClassLabel, Features, load_metric\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "from transformers import AutoModel, AutoModelForSequenceClassification\n",
        "import math\n",
        "\n",
        "from transformers import EarlyStoppingCallback\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.checkpoint import checkpoint # need to call when using gradient_checkpointing\n",
        "from sklearn.metrics import log_loss, confusion_matrix\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "from scipy.special import softmax\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import seed_everything\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "from pytorch_lightning.callbacks import TQDMProgressBar\n",
        "from torchmetrics.functional import accuracy,f1_score\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f1a46199",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:36.873248Z",
          "iopub.status.busy": "2022-08-03T04:10:36.872679Z",
          "iopub.status.idle": "2022-08-03T04:10:36.877608Z",
          "shell.execute_reply": "2022-08-03T04:10:36.876625Z"
        },
        "papermill": {
          "duration": 0.021512,
          "end_time": "2022-08-03T04:10:36.879595",
          "exception": false,
          "start_time": "2022-08-03T04:10:36.858083",
          "status": "completed"
        },
        "tags": [],
        "id": "f1a46199"
      },
      "outputs": [],
      "source": [
        "# # Check f1 score calculation\n",
        "# logits =  torch.tensor([[ 0.0484,  0.2124,  1.6748],\n",
        "#         [-1.0684,  0.5767,  1.0479],\n",
        "#         [ 0.0242,  2.3594, -0.2014],\n",
        "#         [ 1.2988, -1.6455,  0.5952],\n",
        "#         [-3.3828,  0.1713,  1.2539],\n",
        "#         [-1.3945,  1.7637,  0.8101],\n",
        "#         [ 0.2216,  0.3716,  1.0322],\n",
        "#         [-0.7559,  2.1699,  2.5234],\n",
        "#         [-3.0879,  0.6777, -0.9976],\n",
        "#         [ 1.4883, -1.2881,  0.4221],\n",
        "#         [ 0.4805,  0.1526, -0.6147],\n",
        "#         [ 0.7354,  1.1416, -0.3162],\n",
        "#         [-0.9248,  1.0898,  0.0663],\n",
        "#         [-1.2725, -0.4832, -2.3008],\n",
        "#         [ 0.2917,  1.3350,  0.0900],\n",
        "#         [ 4.8086, -1.4307,  0.8926]])\n",
        "\n",
        "# logits.shape\n",
        "# label = torch.tensor([0, 0, 2, 1, 0, 1, 0, 0, 2, 2, 0, 0, 0, 1, 0, 0])\n",
        "# # label.shape\n",
        "# # logits.argmax(dim=1)\n",
        "# # f1 = f1_score(logits.softmax(dim=1),label,num_classes=3,multiclass=True,average='weighted')\n",
        "# # f1 = f1_score(logits,label)\n",
        "# # f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a5aa0a80",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:36.907922Z",
          "iopub.status.busy": "2022-08-03T04:10:36.907222Z",
          "iopub.status.idle": "2022-08-03T04:10:36.911869Z",
          "shell.execute_reply": "2022-08-03T04:10:36.911025Z"
        },
        "papermill": {
          "duration": 0.020722,
          "end_time": "2022-08-03T04:10:36.913906",
          "exception": false,
          "start_time": "2022-08-03T04:10:36.893184",
          "status": "completed"
        },
        "tags": [],
        "id": "a5aa0a80"
      },
      "outputs": [],
      "source": [
        "# np.unique(label.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a69640f4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:36.942698Z",
          "iopub.status.busy": "2022-08-03T04:10:36.941929Z",
          "iopub.status.idle": "2022-08-03T04:10:36.946050Z",
          "shell.execute_reply": "2022-08-03T04:10:36.945115Z"
        },
        "papermill": {
          "duration": 0.020373,
          "end_time": "2022-08-03T04:10:36.947993",
          "exception": false,
          "start_time": "2022-08-03T04:10:36.927620",
          "status": "completed"
        },
        "tags": [],
        "id": "a69640f4"
      },
      "outputs": [],
      "source": [
        "# np.unique(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "edc43f62",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:36.976813Z",
          "iopub.status.busy": "2022-08-03T04:10:36.975443Z",
          "iopub.status.idle": "2022-08-03T04:10:36.979754Z",
          "shell.execute_reply": "2022-08-03T04:10:36.978925Z"
        },
        "papermill": {
          "duration": 0.020595,
          "end_time": "2022-08-03T04:10:36.981698",
          "exception": false,
          "start_time": "2022-08-03T04:10:36.961103",
          "status": "completed"
        },
        "tags": [],
        "id": "edc43f62"
      },
      "outputs": [],
      "source": [
        "# class_weights=class_weight.compute_class_weight(class_weight='balanced',classes=np.unique(label.tolist()),y=label.tolist())\n",
        "# class_weights=torch.tensor(class_weights,dtype=torch.float)\n",
        "# loss_func = nn.CrossEntropyLoss(weight=class_weights,reduction='mean')\n",
        "# loss = loss_func(logits,label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c09f8a84",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:37.010282Z",
          "iopub.status.busy": "2022-08-03T04:10:37.009656Z",
          "iopub.status.idle": "2022-08-03T04:10:37.013583Z",
          "shell.execute_reply": "2022-08-03T04:10:37.012575Z"
        },
        "papermill": {
          "duration": 0.020455,
          "end_time": "2022-08-03T04:10:37.015490",
          "exception": false,
          "start_time": "2022-08-03T04:10:36.995035",
          "status": "completed"
        },
        "tags": [],
        "id": "c09f8a84"
      },
      "outputs": [],
      "source": [
        "# loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "61d89226",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:37.043740Z",
          "iopub.status.busy": "2022-08-03T04:10:37.043166Z",
          "iopub.status.idle": "2022-08-03T04:10:37.048139Z",
          "shell.execute_reply": "2022-08-03T04:10:37.047323Z"
        },
        "papermill": {
          "duration": 0.021131,
          "end_time": "2022-08-03T04:10:37.049961",
          "exception": false,
          "start_time": "2022-08-03T04:10:37.028830",
          "status": "completed"
        },
        "tags": [],
        "id": "61d89226"
      },
      "outputs": [],
      "source": [
        "# logits.softmax(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ce2c111",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:37.077746Z",
          "iopub.status.busy": "2022-08-03T04:10:37.077489Z",
          "iopub.status.idle": "2022-08-03T04:10:37.086090Z",
          "shell.execute_reply": "2022-08-03T04:10:37.085197Z"
        },
        "id": "4ce2c111",
        "outputId": "86cd26ba-4ac8-4c32-f58b-88b078c2dc08",
        "papermill": {
          "duration": 0.025539,
          "end_time": "2022-08-03T04:10:37.088922",
          "exception": false,
          "start_time": "2022-08-03T04:10:37.063383",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e33894f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:37.118194Z",
          "iopub.status.busy": "2022-08-03T04:10:37.117450Z",
          "iopub.status.idle": "2022-08-03T04:10:57.158029Z",
          "shell.execute_reply": "2022-08-03T04:10:57.156415Z"
        },
        "id": "9e33894f",
        "outputId": "2efe6a97-3598-4bc5-abca-3a54b3b8c2de",
        "papermill": {
          "duration": 20.057784,
          "end_time": "2022-08-03T04:10:57.161130",
          "exception": false,
          "start_time": "2022-08-03T04:10:37.103346",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wandb failed to login...\n"
          ]
        }
      ],
      "source": [
        "from kaggle_secrets import UserSecretsClient\n",
        "try:\n",
        "    user_secrets = UserSecretsClient()\n",
        "    secret_value = user_secrets.get_secret(\"wand_api\")\n",
        "    !wandb login {secret_value}\n",
        "except:\n",
        "    print(\"wandb failed to login...\")\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5de53cd",
      "metadata": {
        "papermill": {
          "duration": 0.013352,
          "end_time": "2022-08-03T04:10:57.189509",
          "exception": false,
          "start_time": "2022-08-03T04:10:57.176157",
          "status": "completed"
        },
        "tags": [],
        "id": "f5de53cd"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "037ab383",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:57.217894Z",
          "iopub.status.busy": "2022-08-03T04:10:57.217597Z",
          "iopub.status.idle": "2022-08-03T04:10:57.594837Z",
          "shell.execute_reply": "2022-08-03T04:10:57.593886Z"
        },
        "papermill": {
          "duration": 0.394411,
          "end_time": "2022-08-03T04:10:57.597316",
          "exception": false,
          "start_time": "2022-08-03T04:10:57.202905",
          "status": "completed"
        },
        "tags": [],
        "id": "037ab383",
        "outputId": "9113d7cf-1e07-443a-a272-9c4158e81620",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.seed:Global seed set to 91\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "\n",
        "attributes = [\"Adequate\" ,\"Effective\",\"Ineffective\"]\n",
        "\n",
        "\n",
        "# data_path = pd.read_csv('/kaggle/input/feedback-prize-effectiveness/train.csv')\n",
        "# test_path = pd.read_csv('/kaggle/input/feedback-prize-effectiveness/test.csv')\n",
        "data_path = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/train.csv')\n",
        "\n",
        "\n",
        "deberta_config={'name':'deberta',\n",
        "                'model_name': '../input/deberta-v3-base/deberta-v3-base',\n",
        "                'PATH' : '../input/debertav3basefinetuned3172022/deberta_E3Size16Lr3e-05Warm0.01Weight0.01Freeze2Drop0.1Text0.pth',\n",
        "                'n_labels': 3,\n",
        "                'batch_size': 16,\n",
        "                'lr': 3e-5,\n",
        "                'warmup': 0.01, \n",
        "                'weight_decay': 0.01,\n",
        "                'n_epochs': 4,\n",
        "                'n_freeze' : 2,#9,\n",
        "                'p_dropout':0.65,\n",
        "                'text_method': 2\n",
        "                }\n",
        "\n",
        "distilbert_config={'name': 'distilbert',\n",
        "                'model_name': '../input/transformers-pretrained-distilbert/distilbert-base-uncased-distilled-squad',\n",
        "                'PATH' : '../input/distilberttuned/distilbert-frozenembedding2transformlayer-5epoch-lr6e5-drop02.pth',\n",
        "                'n_labels': 3,\n",
        "                'batch_size': 64,\n",
        "                'lr': 8e-4,#6e-5,\n",
        "                'warmup': 0.2, \n",
        "                'weight_decay': 0.001,\n",
        "                'n_epochs': 5,#4,\n",
        "                'n_freeze' : 3,\n",
        "                'p_dropout':0.6,#0.2,#0.6,\n",
        "                'text_method': 1\n",
        "                }\n",
        "\n",
        "bertofa_config={'name':'bertofa',\n",
        "                'model_name': '../input/bertlargeuncasedsparse90unstructuredpruned/bert-large-uncased-sparse-90-unstructured-pruneofa',\n",
        "                'PATH' : '../input/bert-ofa-pretuned3072022/Bert_OFA_E3Size64Lr0.0001Warm02Weight1e-06Freeze21Drop001_full.pth',\n",
        "                'n_labels': 3,\n",
        "                'batch_size': 64,\n",
        "                'lr': 1e-4,\n",
        "                'warmup': 0.2, \n",
        "                'weight_decay': 1e-6,\n",
        "                'n_epochs': 3,\n",
        "                'n_freeze' : 21,\n",
        "                'p_dropout':0.1,\n",
        "                'text_method': 2\n",
        "                }\n",
        "\n",
        "distilroberta_config={'name':'distilroberta',\n",
        "                'model_name': '../input/distilrobertabase/distilroberta-base',\n",
        "                'PATH' : '../input/distilrobertafinetuned3072022/epoch7-step1840.pth',\n",
        "                'n_labels': 3,\n",
        "                'batch_size': 128,\n",
        "                'lr': 6e-5,\n",
        "                'warmup': 0.2, \n",
        "                'weight_decay': 0.001,\n",
        "                'n_epochs': 10,\n",
        "                'n_freeze' : 5,\n",
        "                'p_dropout':0,\n",
        "                'text_method': 2\n",
        "                }\n",
        "\n",
        "seed_everything(91, workers=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19fb0eb2",
      "metadata": {
        "papermill": {
          "duration": 0.013589,
          "end_time": "2022-08-03T04:10:57.625005",
          "exception": false,
          "start_time": "2022-08-03T04:10:57.611416",
          "status": "completed"
        },
        "tags": [],
        "id": "19fb0eb2"
      },
      "source": [
        "# Utility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db50a6c6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:57.653697Z",
          "iopub.status.busy": "2022-08-03T04:10:57.653410Z",
          "iopub.status.idle": "2022-08-03T04:10:57.662169Z",
          "shell.execute_reply": "2022-08-03T04:10:57.661254Z"
        },
        "papermill": {
          "duration": 0.025553,
          "end_time": "2022-08-03T04:10:57.664205",
          "exception": false,
          "start_time": "2022-08-03T04:10:57.638652",
          "status": "completed"
        },
        "tags": [],
        "id": "db50a6c6"
      },
      "outputs": [],
      "source": [
        "def get_essay(essay_id, is_train=True):\n",
        "    INPUT_DIR = '../input/feedback-prize-effectiveness/'\n",
        "    parent_path = INPUT_DIR + 'train' if is_train else INPUT_DIR + 'test'\n",
        "    \n",
        "    try:\n",
        "        essay_path = os.path.join(parent_path, f\"{essay_id}.txt\")\n",
        "        essay_text = open(essay_path, 'r').read()\n",
        "    except:\n",
        "        parent_path = INPUT_DIR + 'train'\n",
        "        essay_path = os.path.join(parent_path, f\"{essay_id}.txt\")\n",
        "        essay_text = open(essay_path, 'r').read()        \n",
        "    return essay_text\n",
        "\n",
        "def freeze(module):\n",
        "    \"\"\"\n",
        "    Freezes module's parameters.\n",
        "    \"\"\"\n",
        "    \n",
        "    for parameter in module.parameters():\n",
        "        parameter.requires_grad = False\n",
        "        \n",
        "def get_freezed_parameters(module):\n",
        "    \"\"\"\n",
        "    Returns names of freezed parameters of the given module.\n",
        "    \"\"\"\n",
        "    \n",
        "    freezed_parameters = []\n",
        "    for name, parameter in module.named_parameters():\n",
        "        if not parameter.requires_grad:\n",
        "            freezed_parameters.append(name)\n",
        "            \n",
        "    return freezed_parameters\n",
        "\n",
        "\n",
        "# from text_unidecode import unidecode\n",
        "# from typing import Dict, List, Tuple\n",
        "# import codecs\n",
        "\n",
        "# def replace_encoding_with_utf8(error: UnicodeError) -> Tuple[bytes, int]:\n",
        "#     return error.object[error.start : error.end].encode(\"utf-8\"), error.end\n",
        "\n",
        "\n",
        "# def replace_decoding_with_cp1252(error: UnicodeError) -> Tuple[str, int]:\n",
        "#     return error.object[error.start : error.end].decode(\"cp1252\"), error.end\n",
        "\n",
        "# # Register the encoding and decoding error handlers for `utf-8` and `cp1252`.\n",
        "# codecs.register_error(\"replace_encoding_with_utf8\", replace_encoding_with_utf8)\n",
        "# codecs.register_error(\"replace_decoding_with_cp1252\", replace_decoding_with_cp1252)\n",
        "\n",
        "# def resolve_encodings_and_normalize(text: str) -> str:\n",
        "#     \"\"\"Resolve the encoding problems and normalize the abnormal characters.\"\"\"\n",
        "#     text = (\n",
        "#         text.encode(\"raw_unicode_escape\")\n",
        "#         .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n",
        "#         .encode(\"cp1252\", errors=\"replace_encoding_with_utf8\")\n",
        "#         .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n",
        "#     )\n",
        "#     text = unidecode(text)\n",
        "#     return text\n",
        "\n",
        "def normalizecodec(row):\n",
        "    row = unicodedata.normalize(\"NFKD\", row)\n",
        "    row = re.sub(r'\\n',' ',row)\n",
        "    return row"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e74049e5",
      "metadata": {
        "id": "e74049e5",
        "papermill": {
          "duration": 0.013423,
          "end_time": "2022-08-03T04:10:57.691171",
          "exception": false,
          "start_time": "2022-08-03T04:10:57.677748",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Dataset\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a0a27d1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:57.719934Z",
          "iopub.status.busy": "2022-08-03T04:10:57.719661Z",
          "iopub.status.idle": "2022-08-03T04:10:57.738324Z",
          "shell.execute_reply": "2022-08-03T04:10:57.737491Z"
        },
        "id": "6a0a27d1",
        "papermill": {
          "duration": 0.035622,
          "end_time": "2022-08-03T04:10:57.740397",
          "exception": false,
          "start_time": "2022-08-03T04:10:57.704775",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class _Dataset(Dataset):\n",
        "    def __init__(self,data_path,test_path, tokenizer,label_encoder,attributes, max_token_len: int = 512, is_train=True,is_test=False, text_method=0):\n",
        "        self.data_path = data_path\n",
        "        self.test_path = test_path\n",
        "        self.tokenizer = tokenizer\n",
        "        self.attributes = attributes\n",
        "        self.max_token_len = max_token_len\n",
        "        self.is_train = is_train\n",
        "        self.is_test = is_test\n",
        "        self.label_encoder = label_encoder\n",
        "        self.text_method = text_method\n",
        "        self._prepare_data()\n",
        "\n",
        "    def _prepare_data(self):\n",
        "\n",
        "\n",
        "\n",
        "        SEP = self.tokenizer.sep_token # different model uses different to text as seperator (e.g. [SEP], </s>)\n",
        "        if self.is_test:\n",
        "#             df = pd.read_csv(self.test_path)\n",
        "            df = self.test_path\n",
        "            try:\n",
        "                df['essay_text']  = df['essay_id'].apply(lambda x: get_essay(x, is_train=False))\n",
        "            except:\n",
        "                print(\"Fail to get essay\")\n",
        "            df['discourse_text'] = df['discourse_text'].apply(normalizecodec)\n",
        "            df['discourse_text'] = df['discourse_text'].replace(r'\\n',' ', regex=True)\n",
        "            \n",
        "            try:\n",
        "                if self.text_method == 0:\n",
        "                    df['text'] = df['discourse_text']\n",
        "                elif self.text_method == 1:\n",
        "                    df['text'] = df['discourse_type'] + SEP + df['discourse_text']\n",
        "                elif self.text_method == 2:\n",
        "                    df['text'] = df['discourse_type'] + ' ' + df['discourse_text'] + SEP + df['essay_text'] # BERT was trained on 2 sentences\n",
        "            except:\n",
        "                df['text'] = df['discourse_text']\n",
        "                \n",
        "            try:\n",
        "                # Validation use\n",
        "                df = df.loc[:,['text','labels']]\n",
        "            except:\n",
        "                # Test use\n",
        "                df = df.loc[:,['text']]\n",
        "\n",
        "        else:\n",
        "#             df = pd.read_csv(self.data_path)\n",
        "            df = self.data_path\n",
        "            df = df.sample(5000)\n",
        "            try:\n",
        "                df['essay_text']  = df['essay_id'].apply(lambda x: get_essay(x, is_train=True))\n",
        "            except:\n",
        "                print('Fail to get essay')\n",
        "                \n",
        "            y = df['discourse_effectiveness']\n",
        "\n",
        "            train_df, val_df = train_test_split(df, test_size=0.2,stratify=y,random_state=91)\n",
        "\n",
        "            if self.is_train:\n",
        "                df = train_df.copy()\n",
        "            else:\n",
        "                df = val_df.copy()\n",
        "\n",
        "            df['discourse_text'] = df['discourse_text'].apply(normalizecodec)\n",
        "            df['discourse_text'] = df['discourse_text'].replace(r'\\n',' ', regex=True)\n",
        "            try:\n",
        "                if self.text_method == 0:\n",
        "                    df['text'] = df['discourse_text']\n",
        "                elif self.text_method == 1:\n",
        "                    df['text'] = df['discourse_type'] + SEP + df['discourse_text']\n",
        "                elif self.text_method == 2:\n",
        "                    df['text'] = df['discourse_type'] + ' ' + df['discourse_text'] + SEP + df['essay_text'] # BERT was trained on 2 sentences\n",
        "            except:\n",
        "                df['text'] = df['discourse_text']\n",
        "                \n",
        "            df = df.rename(columns={'discourse_effectiveness':'labels'})\n",
        "            df = df.loc[:,['text','labels']]\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        item = self.df.iloc[index]\n",
        "        text = str(item.text)\n",
        "        tokens = self.tokenizer.encode_plus(text,\n",
        "                                  add_special_tokens= True,\n",
        "                                  return_tensors='pt',\n",
        "                                  truncation=True,\n",
        "#                                   padding='max_length',\n",
        "                                  max_length=self.max_token_len,\n",
        "                                  return_attention_mask = True)\n",
        "        if self.is_test:\n",
        "            return {'input_ids':tokens.input_ids.flatten(),'attention_mask': tokens.attention_mask.flatten()}\n",
        "        else:\n",
        "            # # Convert strings to numerics, follow alphabetical order\n",
        "            attributes = item['labels'].split()\n",
        "            self.label_encoder.fit(self.attributes)\n",
        "            attributes = self.label_encoder.transform(attributes)\n",
        "            attributes = torch.as_tensor(attributes)\n",
        "            #         attributes = torch.FloatTensor(item[self.attributes])\n",
        "        return {'input_ids':tokens.input_ids.flatten(),'attention_mask': tokens.attention_mask.flatten(), 'labels':attributes}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe5c5ea9",
      "metadata": {
        "papermill": {
          "duration": 0.013412,
          "end_time": "2022-08-03T04:10:57.768035",
          "exception": false,
          "start_time": "2022-08-03T04:10:57.754623",
          "status": "completed"
        },
        "tags": [],
        "id": "fe5c5ea9"
      },
      "source": [
        "# Collate (Dynamic Padding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7067e7c7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:57.797035Z",
          "iopub.status.busy": "2022-08-03T04:10:57.796174Z",
          "iopub.status.idle": "2022-08-03T04:10:57.807289Z",
          "shell.execute_reply": "2022-08-03T04:10:57.806403Z"
        },
        "papermill": {
          "duration": 0.027762,
          "end_time": "2022-08-03T04:10:57.809290",
          "exception": false,
          "start_time": "2022-08-03T04:10:57.781528",
          "status": "completed"
        },
        "tags": [],
        "id": "7067e7c7"
      },
      "outputs": [],
      "source": [
        "class Collate:\n",
        "    def __init__(self, tokenizer, isTrain=True):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.isTrain = isTrain\n",
        "        # self.args = args\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        output = dict()\n",
        "        output[\"input_ids\"] = [sample[\"input_ids\"] for sample in batch]\n",
        "        output[\"attention_mask\"] = [sample[\"attention_mask\"] for sample in batch]\n",
        "        if self.isTrain:\n",
        "            output[\"labels\"] = [sample[\"labels\"] for sample in batch]\n",
        "\n",
        "        # calculate max token length of this batch\n",
        "        batch_max = max([len(ids) for ids in output[\"input_ids\"]])\n",
        "\n",
        "        # add padding\n",
        "        if self.tokenizer.padding_side == \"right\":\n",
        "            output[\"input_ids\"] = [s.tolist() + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"input_ids\"]]\n",
        "            output[\"attention_mask\"] = [s.tolist() + (batch_max - len(s)) * [0] for s in output[\"attention_mask\"]]\n",
        "\n",
        "#             output[\"input_ids\"] = [torch.cat(s, torch.FloatTensor((batch_max - len(s)) * [0]), 0) for s in output[\"input_ids\"]]\n",
        "#             output[\"attention_mask\"] = [torch.cat(s, torch.FloatTensor((batch_max - len(s)) * [0]), 0) for s in output[\"attention_mask\"]]\n",
        "        else:\n",
        "            output[\"input_ids\"] = [torch.FloatTensor((batch_max - len(s)) * [self.tokenizer.pad_token_id].tolist()) + s.tolist() for s in output[\"input_ids\"]]\n",
        "            output[\"attention_mask\"] = [torch.FloatTensor((batch_max - len(s)) * [0]) + s.tolist() for s in output[\"attention_mask\"]]\n",
        "            \n",
        "        # convert to tensors\n",
        "        output[\"input_ids\"] = torch.tensor(output[\"input_ids\"], dtype=torch.long)\n",
        "        output[\"attention_mask\"] = torch.tensor(output[\"attention_mask\"], dtype=torch.long)\n",
        "        if self.isTrain:\n",
        "            output[\"labels\"] = torch.tensor(output[\"labels\"], dtype=torch.long)\n",
        "        return output\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3fa5287",
      "metadata": {
        "id": "e3fa5287",
        "papermill": {
          "duration": 0.013472,
          "end_time": "2022-08-03T04:10:57.836161",
          "exception": false,
          "start_time": "2022-08-03T04:10:57.822689",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Data Module\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "228815d9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:57.864782Z",
          "iopub.status.busy": "2022-08-03T04:10:57.864519Z",
          "iopub.status.idle": "2022-08-03T04:10:57.875932Z",
          "shell.execute_reply": "2022-08-03T04:10:57.875124Z"
        },
        "id": "228815d9",
        "papermill": {
          "duration": 0.028184,
          "end_time": "2022-08-03T04:10:57.877827",
          "exception": false,
          "start_time": "2022-08-03T04:10:57.849643",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class _Data_Module(pl.LightningDataModule):\n",
        "\n",
        "    def __init__(self, data_path, test_path,attributes,label_encoder,tokenizer, model_name, batch_size: int = 8, max_token_length: int = 512,text_method=0 ):\n",
        "        super().__init__()\n",
        "        self.data_path = data_path\n",
        "        self.test_path = test_path\n",
        "        self.attributes = attributes\n",
        "        self.batch_size = batch_size\n",
        "        self.max_token_length = max_token_length\n",
        "        self.model_name = model_name\n",
        "        self.tokenizer = tokenizer #AutoTokenizer.from_pretrained(model_name)\n",
        "        self.label_encoder = label_encoder\n",
        "        self.text_method = text_method\n",
        "\n",
        "    def setup(self, stage = None):\n",
        "        if stage in (None, \"fit\"):\n",
        "            self.train_dataset = _Dataset(self.data_path, self.test_path, label_encoder = self.label_encoder,  attributes=self.attributes, is_train=True, tokenizer=self.tokenizer,text_method=self.text_method)\n",
        "            self.val_dataset = _Dataset(self.data_path, self.test_path, label_encoder = self.label_encoder, attributes=self.attributes, is_train=False,  tokenizer=self.tokenizer,text_method=self.text_method)\n",
        "        if stage == 'predict':\n",
        "            self.test_dataset = _Dataset(self.data_path, self.test_path, label_encoder = self.label_encoder, attributes=self.attributes, is_train=False,is_test=True, tokenizer=self.tokenizer,text_method=self.text_method)\n",
        "\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        collate_fn = Collate(self.tokenizer, \n",
        "                             isTrain=True)\n",
        "\n",
        "        return DataLoader(self.train_dataset, \n",
        "                          batch_size = self.batch_size, \n",
        "                          num_workers=2, \n",
        "                          shuffle=True,\n",
        "                          collate_fn = collate_fn)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        collate_fn = Collate(self.tokenizer, \n",
        "                             isTrain=True)\n",
        "\n",
        "        return DataLoader(self.val_dataset, \n",
        "                          batch_size = self.batch_size, \n",
        "                          num_workers=2, \n",
        "                          shuffle=False,\n",
        "                          collate_fn = collate_fn)\n",
        "\n",
        "    def predict_dataloader(self):\n",
        "        collate_fn = Collate(self.tokenizer, \n",
        "                             isTrain=False)\n",
        "\n",
        "        return DataLoader(self.test_dataset, \n",
        "                          batch_size = self.batch_size, \n",
        "                          num_workers=2, \n",
        "                          shuffle=False,\n",
        "                          collate_fn = collate_fn)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbd44e90",
      "metadata": {
        "id": "dbd44e90",
        "papermill": {
          "duration": 0.013636,
          "end_time": "2022-08-03T04:10:57.904850",
          "exception": false,
          "start_time": "2022-08-03T04:10:57.891214",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Classifier\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68c733c0",
      "metadata": {
        "papermill": {
          "duration": 0.013792,
          "end_time": "2022-08-03T04:10:57.932097",
          "exception": false,
          "start_time": "2022-08-03T04:10:57.918305",
          "status": "completed"
        },
        "tags": [],
        "id": "68c733c0"
      },
      "source": [
        "## BertOFA Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a205e376",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:57.961322Z",
          "iopub.status.busy": "2022-08-03T04:10:57.960688Z",
          "iopub.status.idle": "2022-08-03T04:10:57.978948Z",
          "shell.execute_reply": "2022-08-03T04:10:57.978035Z"
        },
        "id": "a205e376",
        "papermill": {
          "duration": 0.035063,
          "end_time": "2022-08-03T04:10:57.980869",
          "exception": false,
          "start_time": "2022-08-03T04:10:57.945806",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class BertOFA_Text_Classifier(pl.LightningModule):\n",
        "    \n",
        "    def __init__(self, config: dict,data_module):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.data_module=data_module\n",
        "        self.pretrained_model = AutoModel.from_pretrained(config['model_name'], return_dict = False)\n",
        "        freeze((self.pretrained_model).embeddings)\n",
        "        freeze((self.pretrained_model).encoder.layer[:config['n_freeze']])\n",
        "        print(get_freezed_parameters(self.pretrained_model))\n",
        "        # Adding an additional hidden layer on top of the pretrained model\n",
        "        self.hidden = torch.nn.Linear(self.pretrained_model.config.hidden_size, self.pretrained_model.config.hidden_size)\n",
        "        \n",
        "        # Adding classifier on top of the pretrained model\n",
        "        self.classifier = torch.nn.Linear(self.pretrained_model.config.hidden_size, self.config['n_labels'])\n",
        "        \n",
        "        # Used to initialize the weight of the newly created classifier layer, not sure whether hidden layer need it or not\n",
        "        torch.nn.init.xavier_uniform_(self.classifier.weight)\n",
        "        \n",
        "        self.loss_func = nn.CrossEntropyLoss() # do not put SoftMax, just use CrossEntropyLoss\n",
        "        \n",
        "        self.dropout = nn.Dropout(config['p_dropout'])\n",
        "\n",
        "    # For inference        \n",
        "    def forward(self, input_ids, attention_mask, labels = None):\n",
        "        outputs = self.pretrained_model(input_ids = input_ids, attention_mask = attention_mask)\n",
        "#         pooled_output = torch.mean(outputs.last_hidden_state, 1) \n",
        "#         pooled_output = self.dropout(pooled_output)\n",
        "#         pooled_output = self.dropout(outputs[1])\n",
        "        pooled_output = self.hidden(outputs[1])\n",
        "        pooled_output = F.relu(pooled_output)\n",
        "        pooled_output = self.hidden(pooled_output)\n",
        "        pooled_output = F.relu(pooled_output)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        # calculate loss\n",
        "        loss = 0\n",
        "        if labels is not None:\n",
        "            loss = self.loss_func(logits,labels)\n",
        "        return loss, logits\n",
        "    \n",
        "    def training_step(self, batch, batch_index):\n",
        "        loss, logits = self(**batch)  # self(**batch) = model(**batch), where **batch = unpack batch\n",
        "        f1 = f1_score(logits.argmax(dim=1),batch['labels'],num_classes=3,multiclass=True)\n",
        "        f1_weighted = f1_score(logits.softmax(dim=1),batch['labels'],num_classes=3,multiclass=True,average='weighted')\n",
        "            #wandb.log({\"Training Loss\": loss.item(),'Train F1 Score':f1,'Train F1_weighted Score':f1_weighted})\n",
        "        self.log(\"f1\", f1, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"f1_weighted\", f1_weighted, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"loss \", loss,on_step=False,on_epoch = True, prog_bar = True, logger=True)\n",
        "        return {\"loss\":loss}#, \"predictions\":logits, \"labels\": batch[\"labels\"],\"progress_bar\":pbar}\n",
        "    \n",
        "    def validation_step(self, batch, batch_index):\n",
        "        loss, logits = self(**batch)\n",
        "        f1 = f1_score(logits.argmax(dim=1),batch['labels'],num_classes=3,multiclass=True)\n",
        "        f1_weighted = f1_score(logits.softmax(dim=1),batch['labels'],num_classes=3,multiclass=True,average='weighted')\n",
        "            #wandb.log({\"Validation Loss\": loss.item(),'Validation F1 Score':f1,'Validation F1_weighted Score':f1_weighted})\n",
        "        self.log(\"f1\", f1, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"f1_weighted\", f1_weighted, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"val_loss\", loss, on_step=False,on_epoch = True, prog_bar = True, logger=True)\n",
        "        return {\"val_loss\": loss}#, \"predictions\":logits, \"labels\": batch[\"labels\"]}\n",
        "\n",
        "    def predict_step(self, batch, batch_index):\n",
        "        loss, logits = self(**batch)\n",
        "        return logits\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        train_size = len(self.data_module.train_dataloader())\n",
        "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.config['lr'], weight_decay=self.config['weight_decay'])\n",
        "        total_steps = train_size/self.config['batch_size']\n",
        "        warmup_steps = math.floor(total_steps * self.config['warmup'])\n",
        "        scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "        return [optimizer],[scheduler]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dfb7916",
      "metadata": {
        "papermill": {
          "duration": 0.013401,
          "end_time": "2022-08-03T04:10:58.007717",
          "exception": false,
          "start_time": "2022-08-03T04:10:57.994316",
          "status": "completed"
        },
        "tags": [],
        "id": "0dfb7916"
      },
      "source": [
        "## DistilBert classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a253d316",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:58.036466Z",
          "iopub.status.busy": "2022-08-03T04:10:58.036178Z",
          "iopub.status.idle": "2022-08-03T04:10:58.056028Z",
          "shell.execute_reply": "2022-08-03T04:10:58.055157Z"
        },
        "papermill": {
          "duration": 0.036696,
          "end_time": "2022-08-03T04:10:58.058038",
          "exception": false,
          "start_time": "2022-08-03T04:10:58.021342",
          "status": "completed"
        },
        "tags": [],
        "id": "a253d316"
      },
      "outputs": [],
      "source": [
        "class DistilBert_Text_Classifier(pl.LightningModule):\n",
        "    \n",
        "    def __init__(self, config: dict,data_module):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.data_module=data_module\n",
        "        self.pretrained_model = AutoModel.from_pretrained(config['model_name'], return_dict = True)\n",
        "        freeze((self.pretrained_model).embeddings)\n",
        "        freeze((self.pretrained_model).transformer.layer[:config['n_freeze']])\n",
        "        print(get_freezed_parameters(self.pretrained_model))\n",
        "        # Adding an additional hidden layer on top of the pretrained model\n",
        "        self.hidden = torch.nn.Linear(self.pretrained_model.config.hidden_size,self.pretrained_model.config.hidden_size)\n",
        "#         self.hidden2 = torch.nn.Linear(self.pretrained_model.config.hidden_size,100)\n",
        "\n",
        "#         self.batchnorm = nn.BatchNorm1d(self.pretrained_model.config.hidden_size)\n",
        "        # Adding classifier on top of the pretrained model\n",
        "        self.classifier = torch.nn.Linear(self.pretrained_model.config.hidden_size, self.config['n_labels'])\n",
        "        \n",
        "        # Used to initialize the weight of the newly created classifier layer, not sure whether hidden layer need it or not\n",
        "        torch.nn.init.xavier_uniform_(self.classifier.weight)\n",
        "        \n",
        "        self.loss_func = nn.CrossEntropyLoss() # do not put SoftMax, just use CrossEntropyLoss\n",
        "        \n",
        "        self.dropout = nn.Dropout(config['p_dropout'])\n",
        "\n",
        "    # For inference        \n",
        "    def forward(self, input_ids, attention_mask, labels = None):\n",
        "        output = self.pretrained_model(input_ids = input_ids, attention_mask = attention_mask)\n",
        "        pooled_output = torch.mean(output.last_hidden_state, 1) \n",
        "        pooled_output = self.hidden(pooled_output)\n",
        "        pooled_output = F.relu(pooled_output)\n",
        "#         pooled_output = self.batchnorm(pooled_output)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "            \n",
        "        # calculate loss\n",
        "        loss = 0\n",
        "        if labels is not None:\n",
        "            loss = self.loss_func(logits,labels)\n",
        "        return loss, logits\n",
        "    \n",
        "#     def training_step(self, batch, batch_index):\n",
        "#         logits = self(**batch)  # self(**batch) = model(**batch), where **batch = unpack batch\n",
        "# #         print(f\"batch[labels] = {batch['labels']}\")\n",
        "# #         print(f\"{type(batch['labels'])}\")\n",
        "#         class_weights=class_weight.compute_class_weight(class_weight='balanced',classes=np.unique(batch['labels'].tolist()),y=batch['labels'].tolist())\n",
        "#         class_weights=torch.tensor(class_weights,dtype=torch.float)\n",
        "#         loss_func = nn.CrossEntropyLoss(weight=class_weights,reduction='mean').to('cuda:0')\n",
        "#         loss = loss_func(logits,batch['labels']).to('cuda:0')\n",
        "        \n",
        "#         f1 = f1_score(logits.argmax(dim=1),batch['labels'],num_classes=3,multiclass=True)\n",
        "#         f1_weighted = f1_score(logits.softmax(dim=1),batch['labels'],num_classes=3,multiclass=True,average='weighted')\n",
        "#         wandb.log({\"Training Loss\": loss.item(),'Train F1 Score':f1,'Train F1_weighted Score':f1_weighted})\n",
        "#         self.log(\"f1\", f1, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "#         self.log(\"f1_weighted\", f1_weighted, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "#         self.log(\"loss \", loss,on_step=False,on_epoch = True, prog_bar = True, logger=True)\n",
        "#         return {\"loss\":loss}#, \"predictions\":logits, \"labels\": batch[\"labels\"],\"progress_bar\":pbar}\n",
        "    \n",
        "#     def validation_step(self, batch, batch_index):\n",
        "#         logits = self(**batch)\n",
        "# #         print(f\"batch[labels] = {batch['labels']}\")\n",
        "#         class_weights=class_weight.compute_class_weight(class_weight='balanced',classes=np.unique(batch['labels'].tolist()),y=batch['labels'].tolist())\n",
        "#         class_weights=torch.tensor(class_weights,dtype=torch.float)\n",
        "#         loss_func = nn.CrossEntropyLoss(weight=class_weights,reduction='mean').to('cuda:0')\n",
        "#         loss = loss_func(logits,batch['labels']).to('cuda:0')\n",
        "        \n",
        "        \n",
        "#         f1 = f1_score(logits.argmax(dim=1),batch['labels'],num_classes=3,multiclass=True)\n",
        "#         f1_weighted = f1_score(logits.softmax(dim=1),batch['labels'],num_classes=3,multiclass=True,average='weighted')\n",
        "#         wandb.log({\"Validation Loss\": loss.item(),'Validation F1 Score':f1,'Validation F1_weighted Score':f1_weighted})\n",
        "#         self.log(\"f1\", f1, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "#         self.log(\"f1_weighted\", f1_weighted, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "#         self.log(\"val_loss\", loss, on_step=False,on_epoch = True, prog_bar = True, logger=True)\n",
        "#         return {\"val_loss\": loss}#, \"predictions\":logits, \"labels\": batch[\"labels\"]}\n",
        "#     \n",
        "#     def predict_step(self, batch, batch_index):\n",
        "#         logits = self(**batch)\n",
        "#         return logits\n",
        "\n",
        "    def training_step(self, batch, batch_index):\n",
        "        loss, logits = self(**batch)  # self(**batch) = model(**batch), where **batch = unpack batch\n",
        "        f1 = f1_score(logits.argmax(dim=1),batch['labels'],num_classes=3,multiclass=True)\n",
        "        f1_weighted = f1_score(logits.softmax(dim=1),batch['labels'],num_classes=3,multiclass=True,average='weighted')\n",
        "        wandb.log({\"Training Loss\": loss.item(),'Train F1 Score':f1,'Train F1_weighted Score':f1_weighted})\n",
        "        self.log(\"f1\", f1, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"f1_weighted\", f1_weighted, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"loss \", loss,on_step=False,on_epoch = True, prog_bar = True, logger=True)\n",
        "        return {\"loss\":loss}#, \"predictions\":logits, \"labels\": batch[\"labels\"],\"progress_bar\":pbar}\n",
        "    \n",
        "    def validation_step(self, batch, batch_index):\n",
        "        loss, logits = self(**batch)\n",
        "        f1 = f1_score(logits.argmax(dim=1),batch['labels'],num_classes=3,multiclass=True)\n",
        "        f1_weighted = f1_score(logits.softmax(dim=1),batch['labels'],num_classes=3,multiclass=True,average='weighted')\n",
        "        wandb.log({\"Validation Loss\": loss.item(),'Validation F1 Score':f1,'Validation F1_weighted Score':f1_weighted})\n",
        "        self.log(\"f1\", f1, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"f1_weighted\", f1_weighted, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"val_loss\", loss, on_step=False,on_epoch = True, prog_bar = True, logger=True)\n",
        "        return {\"val_loss\": loss}#, \"predictions\":logits, \"labels\": batch[\"labels\"]}\n",
        "\n",
        "    def predict_step(self, batch, batch_index):\n",
        "        loss, logits = self(**batch)\n",
        "        return logits\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        train_size = len(self.data_module.train_dataloader())\n",
        "        print(train_size)\n",
        "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.config['lr'], weight_decay=self.config['weight_decay'])\n",
        "        total_steps = train_size/self.config['batch_size']\n",
        "        warmup_steps = math.floor(total_steps * self.config['warmup'])\n",
        "        scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "        return [optimizer],[scheduler]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "017d7e61",
      "metadata": {
        "papermill": {
          "duration": 0.013791,
          "end_time": "2022-08-03T04:10:58.085284",
          "exception": false,
          "start_time": "2022-08-03T04:10:58.071493",
          "status": "completed"
        },
        "tags": [],
        "id": "017d7e61"
      },
      "source": [
        "## Deberta Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c147463",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:58.114231Z",
          "iopub.status.busy": "2022-08-03T04:10:58.113594Z",
          "iopub.status.idle": "2022-08-03T04:10:58.130992Z",
          "shell.execute_reply": "2022-08-03T04:10:58.130180Z"
        },
        "papermill": {
          "duration": 0.03398,
          "end_time": "2022-08-03T04:10:58.132994",
          "exception": false,
          "start_time": "2022-08-03T04:10:58.099014",
          "status": "completed"
        },
        "tags": [],
        "id": "1c147463"
      },
      "outputs": [],
      "source": [
        "class DeBerta_Text_Classifier(pl.LightningModule):\n",
        "    \n",
        "    def __init__(self, config: dict,data_module):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.data_module = data_module\n",
        "        self.pretrained_model = AutoModel.from_pretrained(config['model_name'], return_dict = True)\n",
        "        freeze((self.pretrained_model).embeddings)\n",
        "        freeze((self.pretrained_model).encoder.layer[:config['n_freeze']])\n",
        "        print(get_freezed_parameters(self.pretrained_model))\n",
        "\n",
        "        # Adding an additional hidden layer on top of the pretrained model\n",
        "        self.hidden = torch.nn.Linear(self.pretrained_model.config.hidden_size,self.pretrained_model.config.hidden_size)\n",
        "        \n",
        "        # Adding classifier on top of the pretrained model\n",
        "        self.classifier = torch.nn.Linear(self.pretrained_model.config.hidden_size, self.config['n_labels'])\n",
        "        \n",
        "        # Used to initialize the weight of the newly created classifier layer, not sure whether hidden layer need it or not\n",
        "        torch.nn.init.xavier_uniform_(self.classifier.weight)\n",
        "        \n",
        "        self.loss_func = nn.CrossEntropyLoss() # do not put SoftMax, just use CrossEntropyLoss\n",
        "        \n",
        "        self.dropout = nn.Dropout(config['p_dropout'])\n",
        "\n",
        "    # For inference        \n",
        "    def forward(self, input_ids, attention_mask, labels = None):\n",
        "        # deBERTa layer\n",
        "        output = self.pretrained_model(input_ids = input_ids, attention_mask = attention_mask)\n",
        "\n",
        "        ## instead of only using the first token from the output, we will take the mean of all the tokens in the outputs to learn the representation of the entire sentence\n",
        "        ## pooled_output is the output before going into the final classifier\n",
        "        pooled_output = torch.mean(output.last_hidden_state, 1) \n",
        "        \n",
        "        # final logits\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        pooled_output = self.hidden(pooled_output)\n",
        "        pooled_output = F.relu(pooled_output)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        \n",
        "        # calculate loss\n",
        "        loss = 0\n",
        "        if labels is not None:\n",
        "            loss = self.loss_func(logits,labels)\n",
        "        return loss, logits\n",
        "    \n",
        "    def training_step(self, batch, batch_index):\n",
        "        loss, logits = self(**batch)  # self(**batch) = model(**batch), where **batch = unpack batch\n",
        "        f1 = f1_score(logits.argmax(dim=1),batch['labels'],num_classes=3,multiclass=True)\n",
        "        f1_weighted = f1_score(logits.softmax(dim=1),batch['labels'],num_classes=3,multiclass=True,average='weighted')\n",
        "            #wandb.log({\"Training Loss\": loss.item(),'Train F1 Score':f1,'Train F1_weighted Score':f1_weighted})\n",
        "        self.log(\"f1\", f1, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"f1_weighted\", f1_weighted, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"loss \", loss,on_step=False,on_epoch = True, prog_bar = True, logger=True)\n",
        "        return {\"loss\":loss}#, \"predictions\":logits, \"labels\": batch[\"labels\"],\"progress_bar\":pbar}\n",
        "    \n",
        "    def validation_step(self, batch, batch_index):\n",
        "        loss, logits = self(**batch)\n",
        "        f1 = f1_score(logits.argmax(dim=1),batch['labels'],num_classes=3,multiclass=True)\n",
        "        f1_weighted = f1_score(logits.softmax(dim=1),batch['labels'],num_classes=3,multiclass=True,average='weighted')\n",
        "            #wandb.log({\"Validation Loss\": loss.item(),'Validation F1 Score':f1,'Validation F1_weighted Score':f1_weighted})\n",
        "        self.log(\"f1\", f1, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"f1_weighted\", f1_weighted, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"val_loss\", loss, on_step=False,on_epoch = True, prog_bar = True, logger=True)\n",
        "        return {\"val_loss\": loss}#, \"predictions\":logits, \"labels\": batch[\"labels\"]}\n",
        "\n",
        "    def predict_step(self, batch, batch_index):\n",
        "        loss, logits = self(**batch)\n",
        "        return logits\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        train_size = len(self.data_module.train_dataloader())\n",
        "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.config['lr'], weight_decay=self.config['weight_decay'])\n",
        "        total_steps = train_size/self.config['batch_size']\n",
        "        warmup_steps = math.floor(total_steps * self.config['warmup'])\n",
        "        scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "        return [optimizer],[scheduler]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79c18db7",
      "metadata": {
        "papermill": {
          "duration": 0.013374,
          "end_time": "2022-08-03T04:10:58.159889",
          "exception": false,
          "start_time": "2022-08-03T04:10:58.146515",
          "status": "completed"
        },
        "tags": [],
        "id": "79c18db7"
      },
      "source": [
        "Information\n",
        "\n",
        "logit shape =  torch.Size([16, 3])\n",
        "loss shape =  torch.Size([])\n",
        "logits =  tensor([[ 0.0484,  0.2124,  1.6748],\n",
        "        [-1.0684,  0.5767,  1.0479],\n",
        "        [ 0.0242,  2.3594, -0.2014],\n",
        "        [ 1.2988, -1.6455,  0.5952],\n",
        "        [-3.3828,  0.1713,  1.2539],\n",
        "        [-1.3945,  1.7637,  0.8101],\n",
        "        [ 0.2216,  0.3716,  1.0322],\n",
        "        [-0.7559,  2.1699,  2.5234],\n",
        "        [-3.0879,  0.6777, -0.9976],\n",
        "        [ 1.4883, -1.2881,  0.4221],\n",
        "        [ 0.4805,  0.1526, -0.6147],\n",
        "        [ 0.7354,  1.1416, -0.3162],\n",
        "        [-0.9248,  1.0898,  0.0663],\n",
        "        [-1.2725, -0.4832, -2.3008],\n",
        "        [ 0.2917,  1.3350,  0.0900],\n",
        "        [ 4.8086, -1.4307,  0.8926]], device='cuda:0', dtype=torch.float16,\n",
        "       grad_fn=<AddmmBackward0>)\n",
        "logits['labels'] = tensor([0, 0, 2, 1, 0, 1, 0, 0, 2, 2, 0, 0, 0, 1, 0, 0], device='cuda:0')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acf2efc6",
      "metadata": {
        "papermill": {
          "duration": 0.013589,
          "end_time": "2022-08-03T04:10:58.187193",
          "exception": false,
          "start_time": "2022-08-03T04:10:58.173604",
          "status": "completed"
        },
        "tags": [],
        "id": "acf2efc6"
      },
      "source": [
        "# Distil RoBerta Classifer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bbadc25",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:58.216016Z",
          "iopub.status.busy": "2022-08-03T04:10:58.215762Z",
          "iopub.status.idle": "2022-08-03T04:10:58.232585Z",
          "shell.execute_reply": "2022-08-03T04:10:58.231602Z"
        },
        "papermill": {
          "duration": 0.033827,
          "end_time": "2022-08-03T04:10:58.234966",
          "exception": false,
          "start_time": "2022-08-03T04:10:58.201139",
          "status": "completed"
        },
        "tags": [],
        "id": "0bbadc25"
      },
      "outputs": [],
      "source": [
        "class DistilRoBerta_Text_Classifier(pl.LightningModule):\n",
        "    \n",
        "    def __init__(self, config: dict,data_module):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.data_module=data_module\n",
        "        self.pretrained_model = AutoModel.from_pretrained(config['model_name'], return_dict = True)\n",
        "        freeze((self.pretrained_model).embeddings)\n",
        "        freeze((self.pretrained_model).encoder.layer[:config['n_freeze']]) # 5 layer\n",
        "        print(get_freezed_parameters(self.pretrained_model))\n",
        "        # Adding an additional hidden layer on top of the pretrained model\n",
        "        self.hidden = torch.nn.Linear(self.pretrained_model.config.hidden_size,self.pretrained_model.config.hidden_size)\n",
        "        \n",
        "        # Adding classifier on top of the pretrained model\n",
        "        self.classifier = torch.nn.Linear(self.pretrained_model.config.hidden_size, self.config['n_labels'])\n",
        "        \n",
        "        # Used to initialize the weight of the newly created classifier layer, not sure whether hidden layer need it or not\n",
        "        torch.nn.init.xavier_uniform_(self.classifier.weight)\n",
        "        \n",
        "        self.loss_func = nn.CrossEntropyLoss() # do not put SoftMax, just use CrossEntropyLoss\n",
        "        \n",
        "        self.dropout = nn.Dropout(config['p_dropout'])\n",
        "\n",
        "    # For inference        \n",
        "    def forward(self, input_ids, attention_mask, labels = None):\n",
        "        output = self.pretrained_model(input_ids = input_ids, attention_mask = attention_mask)\n",
        "        pooled_output = torch.mean(output.last_hidden_state, 1)\n",
        "        logits = self.classifier(pooled_output)        \n",
        "#         pooled_output = self.hidden(pooled_output)\n",
        "#         pooled_output = F.relu(pooled_output)\n",
        "#         pooled_output = self.dropout(pooled_output)\n",
        "        \n",
        "        # calculate loss\n",
        "        loss = 0\n",
        "        if labels is not None:\n",
        "            loss = self.loss_func(logits,labels)\n",
        "        return loss, logits\n",
        "    \n",
        "    def training_step(self, batch, batch_index):\n",
        "        loss, logits = self(**batch)  # self(**batch) = model(**batch), where **batch = unpack batch\n",
        "        f1 = f1_score(logits.argmax(dim=1),batch['labels'],num_classes=3,multiclass=True)\n",
        "        f1_weighted = f1_score(logits.softmax(dim=1),batch['labels'],num_classes=3,multiclass=True,average='weighted')\n",
        "            #wandb.log({\"Training Loss\": loss.item(),'Train F1 Score':f1,'Train F1_weighted Score':f1_weighted})\n",
        "        self.log(\"f1\", f1, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"f1_weighted\", f1_weighted, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"loss \", loss,on_step=False,on_epoch = True, prog_bar = True, logger=True)\n",
        "        return {\"loss\":loss}#, \"predictions\":logits, \"labels\": batch[\"labels\"],\"progress_bar\":pbar}\n",
        "    \n",
        "    def validation_step(self, batch, batch_index):\n",
        "        loss, logits = self(**batch)\n",
        "        f1 = f1_score(logits.argmax(dim=1),batch['labels'],num_classes=3,multiclass=True)\n",
        "        f1_weighted = f1_score(logits.softmax(dim=1),batch['labels'],num_classes=3,multiclass=True,average='weighted')\n",
        "            #wandb.log({\"Validation Loss\": loss.item(),'Validation F1 Score':f1,'Validation F1_weighted Score':f1_weighted})\n",
        "        self.log(\"f1\", f1, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"f1_weighted\", f1_weighted, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"val_loss\", loss, on_step=False,on_epoch = True, prog_bar = True, logger=True)\n",
        "        return {\"val_loss\": loss}#, \"predictions\":logits, \"labels\": batch[\"labels\"]}\n",
        "\n",
        "    def predict_step(self, batch, batch_index):\n",
        "        loss, logits = self(**batch)\n",
        "        return logits\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        train_size = len(self.data_module.train_dataloader())\n",
        "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.config['lr'], weight_decay=self.config['weight_decay'])\n",
        "        total_steps = train_size/self.config['batch_size']\n",
        "        warmup_steps = math.floor(total_steps * self.config['warmup'])\n",
        "        scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "        return [optimizer],[scheduler]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7679262",
      "metadata": {
        "papermill": {
          "duration": 0.013628,
          "end_time": "2022-08-03T04:10:58.262024",
          "exception": false,
          "start_time": "2022-08-03T04:10:58.248396",
          "status": "completed"
        },
        "tags": [],
        "id": "f7679262"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c2989fc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:58.290285Z",
          "iopub.status.busy": "2022-08-03T04:10:58.290023Z",
          "iopub.status.idle": "2022-08-03T04:10:58.299153Z",
          "shell.execute_reply": "2022-08-03T04:10:58.298048Z"
        },
        "papermill": {
          "duration": 0.025497,
          "end_time": "2022-08-03T04:10:58.301201",
          "exception": false,
          "start_time": "2022-08-03T04:10:58.275704",
          "status": "completed"
        },
        "tags": [],
        "id": "8c2989fc"
      },
      "outputs": [],
      "source": [
        "def train(config,Text_Classifier,project,samplesize, notes,text_method=0):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(config['model_name'], use_fast=True)\n",
        "    le = LabelEncoder()\n",
        "    \n",
        "    data_module = _Data_Module(data_path,\n",
        "                                    test_path,\n",
        "                                    attributes,\n",
        "                                    le,\n",
        "                                    tokenizer,\n",
        "                                    config['model_name'],\n",
        "                                    batch_size=config['batch_size'],\n",
        "                                    text_method=text_method\n",
        "                                   )\n",
        "    data_module.setup()\n",
        "    \n",
        "    # model\n",
        "    model = Text_Classifier(config,data_module)\n",
        "\n",
        "    # trainer and fit\n",
        "    trainer = pl.Trainer(max_epochs=config['n_epochs'],\n",
        "                         accelerator='auto',\n",
        "                         callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\",patience = 3),TQDMProgressBar(refresh_rate=30)],\n",
        "                         default_root_dir=\"./checkpoints\",\n",
        "                         precision = 16,\n",
        "                        ) # automatic mixed precision to reduce memory\n",
        "\n",
        "    # Create a W&B Run\n",
        "    run = wandb.init(name = f\"E{config['n_epochs']}Size{config['batch_size']}Lr{config['lr']}Warm{config['warmup']}Weight{config['weight_decay']}Freeze{config['n_freeze']}Drop{config['p_dropout']}Text{config['text_method']}\" + samplesize,\n",
        "                     notes = str(config) + notes,\n",
        "                     project=project)\n",
        "    trainer.fit(model, data_module)\n",
        "    \n",
        "    run.finish()\n",
        "    \n",
        "    PATH = f\"./{config['name']}_E{config['n_epochs']}Size{config['batch_size']}Lr{config['lr']}Warm{config['warmup']}Weight{config['weight_decay']}Freeze{config['n_freeze']}Drop{config['p_dropout']}Text{config['text_method']}.pth\"\n",
        "    config['PATH'] = PATH\n",
        "    torch.save(model.state_dict(), PATH)\n",
        "    \n",
        "    return model,config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be9ae05a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:58.329997Z",
          "iopub.status.busy": "2022-08-03T04:10:58.329165Z",
          "iopub.status.idle": "2022-08-03T04:10:58.333817Z",
          "shell.execute_reply": "2022-08-03T04:10:58.332980Z"
        },
        "papermill": {
          "duration": 0.021285,
          "end_time": "2022-08-03T04:10:58.335973",
          "exception": false,
          "start_time": "2022-08-03T04:10:58.314688",
          "status": "completed"
        },
        "tags": [],
        "id": "be9ae05a"
      },
      "outputs": [],
      "source": [
        "# bertofa_model,bertofa_config = train(config = bertofa_config,\n",
        "#                       Text_Classifier = BertOFA_Text_Classifier,\n",
        "#                       project = 'BertOFA_Text_Classifier',\n",
        "#                       samplesize = ' full',\n",
        "#                       notes = \n",
        "#                       \"\"\"\n",
        "#                         outputs = self.pretrained_model(input_ids = input_ids, attention_mask = attention_mask), \n",
        "#                         pooled_output = self.hidden(outputs[1]), \n",
        "#                         pooled_output = F.relu(pooled_output), \n",
        "#                         pooled_output = self.hidden(pooled_output), \n",
        "#                         pooled_output = F.relu(pooled_output), \n",
        "#                         pooled_output = self.dropout(pooled_output), \n",
        "#                         logits = self.classifier(pooled_output)\n",
        "#                         \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b047d7e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:58.364530Z",
          "iopub.status.busy": "2022-08-03T04:10:58.363629Z",
          "iopub.status.idle": "2022-08-03T04:10:58.368201Z",
          "shell.execute_reply": "2022-08-03T04:10:58.367406Z"
        },
        "papermill": {
          "duration": 0.020797,
          "end_time": "2022-08-03T04:10:58.370184",
          "exception": false,
          "start_time": "2022-08-03T04:10:58.349387",
          "status": "completed"
        },
        "tags": [],
        "id": "4b047d7e"
      },
      "outputs": [],
      "source": [
        "# distilroberta_model,distilroberta_config = train(config = distilroberta_config,\n",
        "#                       Text_Classifier = DistilRoBerta_Text_Classifier,\n",
        "#                       project = 'DistilRoBerta_Text_Classifier',\n",
        "#                       samplesize = ' Full',\n",
        "#                       notes = \n",
        "# \"\"\"\n",
        "# output = self.pretrained_model(input_ids = input_ids, attention_mask = attention_mask),\n",
        "# pooled_output = torch.mean(output.last_hidden_state, 1), \n",
        "# logits = self.classifier(pooled_output)  \n",
        "# \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb02fa51",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:58.398746Z",
          "iopub.status.busy": "2022-08-03T04:10:58.398014Z",
          "iopub.status.idle": "2022-08-03T04:10:58.402690Z",
          "shell.execute_reply": "2022-08-03T04:10:58.401753Z"
        },
        "papermill": {
          "duration": 0.021006,
          "end_time": "2022-08-03T04:10:58.404627",
          "exception": false,
          "start_time": "2022-08-03T04:10:58.383621",
          "status": "completed"
        },
        "tags": [],
        "id": "fb02fa51"
      },
      "outputs": [],
      "source": [
        "# distilbert_model, distilbert_config  = train(config = distilbert_config,\n",
        "#                                       Text_Classifier = DistilBert_Text_Classifier,\n",
        "#                                       project = 'DistilBert_Text_Classifier',\n",
        "#                                       samplesize = ' 5000 test without weighted loss',\n",
        "#                                       notes = \n",
        "# \"\"\"\n",
        "# output = self.pretrained_model(input_ids = input_ids, attention_mask = attention_mask),\n",
        "# pooled_output = torch.mean(output.last_hidden_state, 1),\n",
        "# pooled_output = self.hidden(pooled_output),\n",
        "# pooled_output = F.relu(pooled_output),\n",
        "# pooled_output = self.dropout(pooled_output),\n",
        "# logits = self.classifier(pooled_output)\n",
        "# \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f2eb63b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:58.433167Z",
          "iopub.status.busy": "2022-08-03T04:10:58.432439Z",
          "iopub.status.idle": "2022-08-03T04:10:58.437041Z",
          "shell.execute_reply": "2022-08-03T04:10:58.436229Z"
        },
        "papermill": {
          "duration": 0.020552,
          "end_time": "2022-08-03T04:10:58.438840",
          "exception": false,
          "start_time": "2022-08-03T04:10:58.418288",
          "status": "completed"
        },
        "tags": [],
        "id": "0f2eb63b"
      },
      "outputs": [],
      "source": [
        "# deberta_model,deberta_config = train(config = deberta_config,\n",
        "#                       Text_Classifier = DeBerta_Text_Classifier,\n",
        "#                       project = 'DeBerta_Text_Classifier',\n",
        "#                       samplesize = ' full',\n",
        "#                       notes = \n",
        "# \"\"\"\n",
        "# pooled_output = self.dropout(pooled_output), \n",
        "# pooled_output = self.hidden(pooled_output), \n",
        "# pooled_output = F.relu(pooled_output), \n",
        "# pooled_output = self.dropout(pooled_output), \n",
        "# logits = self.classifier(pooled_output)\n",
        "# \"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fabfc170",
      "metadata": {
        "papermill": {
          "duration": 0.013522,
          "end_time": "2022-08-03T04:10:58.466384",
          "exception": false,
          "start_time": "2022-08-03T04:10:58.452862",
          "status": "completed"
        },
        "tags": [],
        "id": "fabfc170"
      },
      "source": [
        "# Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "968c8e0b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:58.494462Z",
          "iopub.status.busy": "2022-08-03T04:10:58.494162Z",
          "iopub.status.idle": "2022-08-03T04:10:58.504925Z",
          "shell.execute_reply": "2022-08-03T04:10:58.504072Z"
        },
        "papermill": {
          "duration": 0.02695,
          "end_time": "2022-08-03T04:10:58.506803",
          "exception": false,
          "start_time": "2022-08-03T04:10:58.479853",
          "status": "completed"
        },
        "tags": [],
        "id": "968c8e0b"
      },
      "outputs": [],
      "source": [
        "def validate(_Text_Classifier,config,data_path,val_path,attributes):    \n",
        "    tokenizer = AutoTokenizer.from_pretrained(config['model_name'], use_fast=True)\n",
        "    le = LabelEncoder()\n",
        "    \n",
        "    val_data_module = _Data_Module(data_path,\n",
        "                                    val_path, # using \n",
        "                                    attributes,\n",
        "                                    le,\n",
        "                                    tokenizer,\n",
        "                                    config['model_name'],\n",
        "                                    batch_size=config['batch_size'],\n",
        "                                    text_method = config['text_method']\n",
        "                                   )\n",
        "    val_data_module.setup()\n",
        "\n",
        "    # Initialize Model\n",
        "    model = _Text_Classifier(config,val_data_module)\n",
        "    model.load_state_dict(torch.load(config['PATH']))\n",
        "\n",
        "    # Initialize Trainer\n",
        "    trainer = pl.Trainer(accelerator='auto')\n",
        "\n",
        "    run = wandb.init(name = f\"Validation\",notes = str(config),project= 'Validation')\n",
        "    \n",
        "    logits = trainer.predict(model, datamodule=val_data_module)\n",
        "\n",
        "    run.finish()\n",
        "    \n",
        "    pred_list = []\n",
        "    for logit in logits:\n",
        "        pred_list.append(logit)\n",
        "    y_pred = torch.cat(pred_list)\n",
        "\n",
        "    argmax_output = y_pred.argmax(dim=1)\n",
        "    argmax_output = argmax_output.numpy()\n",
        "    \n",
        "    val_df = val_path.copy()\n",
        "    output_df = pd.concat([val_df.reset_index(drop=True), pd.DataFrame(argmax_output,columns=['pred_discourse_effectiveness'])], axis=1)\n",
        "    output_df['pred_discourse_effectiveness'] = output_df['pred_discourse_effectiveness'].map({0:'Adequate',1:'Effective',2:'Ineffective'})\n",
        "    # Plot Confusion Matrix\n",
        "#     y_true = output_df['discourse_effectiveness'].values\n",
        "#     y_pred = output_df['pred_discourse_effectiveness'].values\n",
        "#     ax= plt.subplot()\n",
        "#     do_conf_matrix(y_true, y_pred, ax=ax)\n",
        "\n",
        "    return output_df,y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ea8aab5",
      "metadata": {
        "papermill": {
          "duration": 0.013448,
          "end_time": "2022-08-03T04:10:58.533610",
          "exception": false,
          "start_time": "2022-08-03T04:10:58.520162",
          "status": "completed"
        },
        "tags": [],
        "id": "5ea8aab5"
      },
      "source": [
        "## Retrieve Validation Data set from train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cd27d94",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:58.563104Z",
          "iopub.status.busy": "2022-08-03T04:10:58.561554Z",
          "iopub.status.idle": "2022-08-03T04:10:58.613118Z",
          "shell.execute_reply": "2022-08-03T04:10:58.612297Z"
        },
        "papermill": {
          "duration": 0.068019,
          "end_time": "2022-08-03T04:10:58.615117",
          "exception": false,
          "start_time": "2022-08-03T04:10:58.547098",
          "status": "completed"
        },
        "tags": [],
        "id": "2cd27d94"
      },
      "outputs": [],
      "source": [
        "# data_path = '/kaggle/input/feedback-prize-effectiveness/train.csv'\n",
        "# test_path = '/kaggle/input/feedback-prize-effectiveness/test.csv'\n",
        "# val_path = './val.csv'\n",
        "attributes = [\"Adequate\" ,\"Effective\",\"Ineffective\"]\n",
        "\n",
        "# Create validation csv file from traintestsplit\n",
        "df = data_path.copy()\n",
        "y = df['discourse_effectiveness']\n",
        "train_df,val_df = train_test_split(df, test_size=0.2,stratify=y,random_state=91)\n",
        "# y = val_df['discourse_effectiveness']\n",
        "# train_df,val_df = train_test_split(val_df, test_size=0.01,stratify=y,random_state=91)\n",
        "val_path = val_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abff50eb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:58.643797Z",
          "iopub.status.busy": "2022-08-03T04:10:58.643018Z",
          "iopub.status.idle": "2022-08-03T04:10:58.653251Z",
          "shell.execute_reply": "2022-08-03T04:10:58.652310Z"
        },
        "papermill": {
          "duration": 0.026631,
          "end_time": "2022-08-03T04:10:58.655301",
          "exception": false,
          "start_time": "2022-08-03T04:10:58.628670",
          "status": "completed"
        },
        "tags": [],
        "id": "abff50eb",
        "outputId": "8e3dedce-4f2c-4c53-ba46-3e998acf913d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Adequate       4196\n",
              "Effective      1865\n",
              "Ineffective    1292\n",
              "Name: discourse_effectiveness, dtype: int64"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_df['discourse_effectiveness'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c705cae6",
      "metadata": {
        "papermill": {
          "duration": 0.013341,
          "end_time": "2022-08-03T04:10:58.682719",
          "exception": false,
          "start_time": "2022-08-03T04:10:58.669378",
          "status": "completed"
        },
        "tags": [],
        "id": "c705cae6"
      },
      "source": [
        "## Run Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5185eaed",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:58.711920Z",
          "iopub.status.busy": "2022-08-03T04:10:58.711150Z",
          "iopub.status.idle": "2022-08-03T04:10:58.716391Z",
          "shell.execute_reply": "2022-08-03T04:10:58.715550Z"
        },
        "papermill": {
          "duration": 0.02162,
          "end_time": "2022-08-03T04:10:58.718460",
          "exception": false,
          "start_time": "2022-08-03T04:10:58.696840",
          "status": "completed"
        },
        "tags": [],
        "id": "5185eaed"
      },
      "outputs": [],
      "source": [
        "# val_output_df_distilbert, y_pred_distilbert = validate(DistilBert_Text_Classifier,\n",
        "#                                                       distilbert_config,\n",
        "#                                                       data_path,\n",
        "#                                                       val_path,\n",
        "#                                                       attributes)\n",
        "\n",
        "# val_output_df_deberta,y_pred_deberta = validate(DeBerta_Text_Classifier,\n",
        "#                                                   deberta_config,\n",
        "#                                                   data_path,\n",
        "#                                                   val_path,\n",
        "#                                                   attributes)\n",
        "\n",
        "# val_output_df_bertofa, y_pred_bertofa = validate(BertOFA_Text_Classifier,\n",
        "#                                                   bertofa_config,\n",
        "#                                                   data_path,\n",
        "#                                                   val_path,\n",
        "#                                                   attributes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bce4094",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:58.747382Z",
          "iopub.status.busy": "2022-08-03T04:10:58.747105Z",
          "iopub.status.idle": "2022-08-03T04:10:58.751293Z",
          "shell.execute_reply": "2022-08-03T04:10:58.750250Z"
        },
        "papermill": {
          "duration": 0.020892,
          "end_time": "2022-08-03T04:10:58.753521",
          "exception": false,
          "start_time": "2022-08-03T04:10:58.732629",
          "status": "completed"
        },
        "tags": [],
        "id": "9bce4094"
      },
      "outputs": [],
      "source": [
        "## val_output_df_distilroberta, y_pred_distilroberta = validate(DistilRoBerta_Text_Classifier,\n",
        "##                                                               distilroberta_config,\n",
        "##                                                               data_path,\n",
        "##                                                               val_path,\n",
        "##                                                               attributes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1046bf2",
      "metadata": {
        "papermill": {
          "duration": 0.013405,
          "end_time": "2022-08-03T04:10:58.780657",
          "exception": false,
          "start_time": "2022-08-03T04:10:58.767252",
          "status": "completed"
        },
        "tags": [],
        "id": "a1046bf2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a655604f",
      "metadata": {
        "papermill": {
          "duration": 0.013351,
          "end_time": "2022-08-03T04:10:58.807666",
          "exception": false,
          "start_time": "2022-08-03T04:10:58.794315",
          "status": "completed"
        },
        "tags": [],
        "id": "a655604f"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1c37d70",
      "metadata": {
        "papermill": {
          "duration": 0.013294,
          "end_time": "2022-08-03T04:10:58.834735",
          "exception": false,
          "start_time": "2022-08-03T04:10:58.821441",
          "status": "completed"
        },
        "tags": [],
        "id": "c1c37d70"
      },
      "source": [
        "## Save Validation Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff492af7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:58.864186Z",
          "iopub.status.busy": "2022-08-03T04:10:58.863331Z",
          "iopub.status.idle": "2022-08-03T04:10:58.868077Z",
          "shell.execute_reply": "2022-08-03T04:10:58.867247Z"
        },
        "papermill": {
          "duration": 0.021224,
          "end_time": "2022-08-03T04:10:58.870027",
          "exception": false,
          "start_time": "2022-08-03T04:10:58.848803",
          "status": "completed"
        },
        "tags": [],
        "id": "ff492af7"
      },
      "outputs": [],
      "source": [
        "# df_distilbert = pd.concat([val_output_df_distilbert.reset_index(drop=True),pd.DataFrame(y_pred_distilbert.tolist(),columns=attributes)],axis=1)\n",
        "# df_deberta = pd.concat([val_output_df_deberta.reset_index(drop=True),pd.DataFrame(y_pred_deberta.tolist(),columns=attributes)],axis=1)\n",
        "# df_bertofa = pd.concat([val_output_df_bertofa.reset_index(drop=True),pd.DataFrame(y_pred_bertofa.tolist(),columns=attributes)],axis=1)\n",
        "\n",
        "# df_distilbert.to_csv('./distilbert_valresult.csv',index=False)\n",
        "# df_deberta.to_csv('./deberta_valresult.csv',index=False)\n",
        "# df_bertofa.to_csv('./bertofa_valresult.csv',index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0147804",
      "metadata": {
        "papermill": {
          "duration": 0.01344,
          "end_time": "2022-08-03T04:10:58.897068",
          "exception": false,
          "start_time": "2022-08-03T04:10:58.883628",
          "status": "completed"
        },
        "tags": [],
        "id": "c0147804"
      },
      "source": [
        "# Explore Validation Results\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ab9e2e3",
      "metadata": {
        "papermill": {
          "duration": 0.013391,
          "end_time": "2022-08-03T04:10:58.924152",
          "exception": false,
          "start_time": "2022-08-03T04:10:58.910761",
          "status": "completed"
        },
        "tags": [],
        "id": "3ab9e2e3"
      },
      "source": [
        "## Read data from Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea5ae8c0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:10:58.953073Z",
          "iopub.status.busy": "2022-08-03T04:10:58.952297Z",
          "iopub.status.idle": "2022-08-03T04:11:01.173461Z",
          "shell.execute_reply": "2022-08-03T04:11:01.172491Z"
        },
        "papermill": {
          "duration": 2.238418,
          "end_time": "2022-08-03T04:11:01.176332",
          "exception": false,
          "start_time": "2022-08-03T04:10:58.937914",
          "status": "completed"
        },
        "tags": [],
        "id": "ea5ae8c0"
      },
      "outputs": [],
      "source": [
        "df_distilbert=pd.read_csv('../input/validation-result/distilbert_valresult.csv')\n",
        "df_deberta=pd.read_csv('../input/validation-result/deberta_valresult.csv')\n",
        "df_bertofa=pd.read_csv('../input/validation-result/bertofa_valresult.csv')\n",
        "\n",
        "ypred_distilbert = torch.from_numpy(df_distilbert.loc[:,['Adequate','Effective','Ineffective']].values)\n",
        "ypred_deberta = torch.from_numpy(df_deberta.loc[:,['Adequate','Effective','Ineffective']].values)\n",
        "ypred_bertofa = torch.from_numpy(df_bertofa.loc[:,['Adequate','Effective','Ineffective']].values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cc7488d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:11:01.205630Z",
          "iopub.status.busy": "2022-08-03T04:11:01.205289Z",
          "iopub.status.idle": "2022-08-03T04:11:01.209883Z",
          "shell.execute_reply": "2022-08-03T04:11:01.208853Z"
        },
        "papermill": {
          "duration": 0.021617,
          "end_time": "2022-08-03T04:11:01.212176",
          "exception": false,
          "start_time": "2022-08-03T04:11:01.190559",
          "status": "completed"
        },
        "tags": [],
        "id": "8cc7488d"
      },
      "outputs": [],
      "source": [
        "weight ={\n",
        "        'deberta':0.10,\n",
        "        'distilbert':0.50,\n",
        "        'bertofa':0.40,\n",
        "#         'distilroberta':0.25\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "# weight ={\n",
        "#         'deberta':0.33,\n",
        "#         'distilbert':0.33,\n",
        "#         'bertofa':0.33,\n",
        "# #         'distilroberta':0.25\n",
        "#         }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "940f4543",
      "metadata": {
        "papermill": {
          "duration": 0.013316,
          "end_time": "2022-08-03T04:11:01.239092",
          "exception": false,
          "start_time": "2022-08-03T04:11:01.225776",
          "status": "completed"
        },
        "tags": [],
        "id": "940f4543"
      },
      "source": [
        "## Utility Function for Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "948c6498",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:11:01.268213Z",
          "iopub.status.busy": "2022-08-03T04:11:01.267944Z",
          "iopub.status.idle": "2022-08-03T04:11:01.287274Z",
          "shell.execute_reply": "2022-08-03T04:11:01.286247Z"
        },
        "papermill": {
          "duration": 0.036932,
          "end_time": "2022-08-03T04:11:01.289618",
          "exception": false,
          "start_time": "2022-08-03T04:11:01.252686",
          "status": "completed"
        },
        "tags": [],
        "id": "948c6498"
      },
      "outputs": [],
      "source": [
        "def pred_to_argmax(y_pred,df,model_name):\n",
        "    argmax_output = y_pred.argmax(dim=1)\n",
        "    argmax_output = argmax_output.numpy()\n",
        "    df = pd.concat([df.reset_index(drop=True),pd.DataFrame(argmax_output,columns=[f'pred_effectiveness_{model_name}'])], axis=1)\n",
        "    df[f'pred_effectiveness_{model_name}'] = df[f'pred_effectiveness_{model_name}'].map({0:'Adequate',1:'Effective',2:'Ineffective'})\n",
        "    return df\n",
        "\n",
        "# def plot_confusionmatrix(df,model_name):\n",
        "#     y_true = output_df['discourse_effectiveness'].values\n",
        "#     y_pred = output_df[f'pred_discourse_effectiveness_{model_name}'].values\n",
        "#     ax= plt.subplot()\n",
        "#     do_conf_matrix(y_true, y_pred, ax=ax)\n",
        "\n",
        "def do_conf_matrix(y_true, y_pred, ax, title=None):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=attributes)\n",
        "    cm\n",
        "\n",
        "    sns.heatmap(cm/np.sum(cm), annot=True, fmt='.2%', ax=ax, cmap='Blues');  \n",
        "    \n",
        "    \n",
        "    # labels, title and ticks\n",
        "    ax.set_xlabel('Predicted labels');\n",
        "    ax.set_ylabel('True labels'); \n",
        "    ax.set_title(f'Confusion Matrix - {title}'); \n",
        "\n",
        "    ax.xaxis.set_ticklabels(attributes)\n",
        "    ax.yaxis.set_ticklabels(attributes);\n",
        "\n",
        "    \n",
        "def calculate_score(y_pred,df):\n",
        "    cel = nn.CrossEntropyLoss()\n",
        "    f1 = f1_score(y_pred.argmax(dim=1),torch.tensor(df['discourse_effectiveness_numeric'].values),num_classes=3,average=None)\n",
        "    f1_weighted = f1_score(y_pred.softmax(dim=1),torch.tensor(df['discourse_effectiveness_numeric'].values),num_classes=3,multiclass=True,average='weighted')\n",
        "    loss = cel(y_pred,torch.tensor(df['discourse_effectiveness_numeric'].values))\n",
        "    \n",
        "    return f1, f1_weighted, loss\n",
        "    \n",
        "def validate_result(y_pred_deberta,y_pred_distilbert,y_pred_bertofa,weight,val_path,preds):\n",
        "\n",
        "#     y_pred_overall = (y_pred_deberta*weight[preds[0]] + y_pred_distilbert*weight[preds[1]] + y_pred_bertofa*weight[preds[2]])/(weight[preds[0]]+weight[preds[1]]+weight[preds[2]])\n",
        "    \n",
        "    weight_deberta = torch.tensor([weight['deberta']])\n",
        "    weight_distilbert = torch.tensor([weight['distilbert']])\n",
        "    weight_bertofa = torch.tensor([weight['bertofa']])\n",
        "\n",
        "    weight_deberta=weight_deberta.repeat(ypred_deberta.shape[0],1)\n",
        "    weight_distilbert=weight_distilbert.repeat(ypred_distilbert.shape[0],1)\n",
        "    weight_bertofa=weight_bertofa.repeat(ypred_bertofa.shape[0],1)\n",
        "\n",
        "#     Method 1\n",
        "#     for idx,ypred in enumerate(ypred_deberta):\n",
        "#         if (ypred[2]>ypred[0]) &(ypred[2]>ypred[1]):\n",
        "#             ratio_bertofa = weight_bertofa[idx]/(weight_distilbert[idx]+weight_deberta[idx])\n",
        "#             ratio_distilbert = weight_distilbert[idx]/(weight_bertofa[idx]+weight_deberta[idx])\n",
        "#             weight_deberta[idx]=0.35\n",
        "#             weight_bertofa[idx]=(1-weight_deberta[idx])*ratio_bertofa\n",
        "#             weight_distilbert[idx]=(1-weight_deberta[idx])*ratio_distilbert\n",
        "\n",
        "# Method 3\n",
        "    for idx,ypred in enumerate(ypred_deberta):\n",
        "        if (ypred[2]>ypred[0]) &(ypred[2]>ypred[1]):# & (ypred_distilbert[idx][2]>ypred_distilbert[idx][0]) &(ypred_distilbert[idx][2]>ypred_distilbert[idx][1]):\n",
        "            ratio_bertofa = weight_bertofa[idx]/(weight_distilbert[idx]+weight_deberta[idx])\n",
        "            ratio_distilbert = weight_distilbert[idx]/(weight_bertofa[idx]+weight_deberta[idx])\n",
        "            weight_deberta[idx]=0.6\n",
        "            weight_bertofa[idx]=0.02\n",
        "            weight_distilbert[idx]=0.38 \n",
        "\n",
        "    \n",
        "    numerator = torch.mul(ypred_deberta,weight_deberta) + torch.mul(ypred_distilbert,weight_bertofa) + torch.mul(ypred_bertofa,weight_distilbert)\n",
        "    denominator = torch.add(torch.add(weight_deberta,weight_bertofa),weight_distilbert)\n",
        "    y_pred_overall = torch.div(numerator,denominator)\n",
        "    \n",
        "#         # Method 2\n",
        "#     for idx,ypred in enumerate(y_pred_overall):\n",
        "#         if ypred[]\n",
        "#         if (ypred[2]>ypred[0]) &(ypred[2]>ypred[1])& (ypred_distilbert[idx][2]<ypred_distilbert[idx][0])& (ypred_distilbert[idx][2]<ypred_distilbert[idx][1]):\n",
        "#             ratio_bertofa = weight_bertofa[idx]/(weight_distilbert[idx]+weight_deberta[idx])\n",
        "#             ratio_distilbert = weight_distilbert[idx]/(weight_bertofa[idx]+weight_deberta[idx])\n",
        "#             weight_deberta[idx]=0.35\n",
        "#             weight_bertofa[idx]=(1-weight_deberta[idx])*ratio_bertofa\n",
        "#             weight_distilbert[idx]=(1-weight_deberta[idx])*ratio_distilbert  \n",
        "    \n",
        "    df = val_path.copy()\n",
        "    df['discourse_effectiveness_numeric'] = df['discourse_effectiveness'].map({'Adequate':0,'Effective':1,'Ineffective':2})\n",
        "    y_true = df['discourse_effectiveness'].values\n",
        "    \n",
        "\n",
        "    \n",
        "    fig, axs = plt.subplots(2,2,figsize=(20, 10))\n",
        "    \n",
        "    df = pred_to_argmax(y_pred_deberta,df,preds[0])    \n",
        "    df = pred_to_argmax(y_pred_distilbert,df,preds[1])\n",
        "    df = pred_to_argmax(y_pred_bertofa,df,preds[2])\n",
        "    df = pred_to_argmax(y_pred_overall,df,preds[3])\n",
        "    \n",
        "    print(df.info())\n",
        "    do_conf_matrix(y_true, df[f'pred_effectiveness_deberta'].values, ax=axs[0,0],title = preds[0])\n",
        "    do_conf_matrix(y_true, df[f'pred_effectiveness_distilbert'].values, ax=axs[1,0],title = preds[1])\n",
        "    do_conf_matrix(y_true, df[f'pred_effectiveness_bertofa'].values, ax=axs[0,1],title = preds[2])\n",
        "    do_conf_matrix(y_true, df[f'pred_effectiveness_OVERALL'].values, ax=axs[1,1],title = preds[3])\n",
        "\n",
        "    output1 = calculate_score(y_pred_deberta,df)\n",
        "    output2 = calculate_score(y_pred_distilbert,df)\n",
        "    output3 = calculate_score(y_pred_bertofa,df)\n",
        "    output4 = calculate_score(y_pred_overall,df)\n",
        "\n",
        "    return output1, output2, output3, output4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2a3134a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:11:01.318770Z",
          "iopub.status.busy": "2022-08-03T04:11:01.318498Z",
          "iopub.status.idle": "2022-08-03T04:11:02.710194Z",
          "shell.execute_reply": "2022-08-03T04:11:02.709282Z"
        },
        "papermill": {
          "duration": 1.408998,
          "end_time": "2022-08-03T04:11:02.712887",
          "exception": false,
          "start_time": "2022-08-03T04:11:01.303889",
          "status": "completed"
        },
        "tags": [],
        "id": "b2a3134a",
        "outputId": "009c86d6-30ff-4121-e426-8df9ca50f845"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7353 entries, 0 to 7352\n",
            "Data columns (total 10 columns):\n",
            " #   Column                           Non-Null Count  Dtype \n",
            "---  ------                           --------------  ----- \n",
            " 0   discourse_id                     7353 non-null   object\n",
            " 1   essay_id                         7353 non-null   object\n",
            " 2   discourse_text                   7353 non-null   object\n",
            " 3   discourse_type                   7353 non-null   object\n",
            " 4   discourse_effectiveness          7353 non-null   object\n",
            " 5   discourse_effectiveness_numeric  7353 non-null   int64 \n",
            " 6   pred_effectiveness_deberta       7353 non-null   object\n",
            " 7   pred_effectiveness_distilbert    7353 non-null   object\n",
            " 8   pred_effectiveness_bertofa       7353 non-null   object\n",
            " 9   pred_effectiveness_OVERALL       7353 non-null   object\n",
            "dtypes: int64(1), object(9)\n",
            "memory usage: 574.6+ KB\n",
            "None\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 8 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "preds = ['deberta','distilbert','bertofa','OVERALL']\n",
        "\n",
        "output1, output2, output3, output4 = validate_result(ypred_deberta,ypred_distilbert,ypred_bertofa,weight,val_path, preds)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cdd7a8e",
      "metadata": {
        "papermill": {
          "duration": 0.044027,
          "end_time": "2022-08-03T04:11:02.772668",
          "exception": false,
          "start_time": "2022-08-03T04:11:02.728641",
          "status": "completed"
        },
        "tags": [],
        "id": "4cdd7a8e"
      },
      "source": [
        "## Read F1 Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f7ead8c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:11:02.804016Z",
          "iopub.status.busy": "2022-08-03T04:11:02.803704Z",
          "iopub.status.idle": "2022-08-03T04:11:02.820805Z",
          "shell.execute_reply": "2022-08-03T04:11:02.819741Z"
        },
        "papermill": {
          "duration": 0.035581,
          "end_time": "2022-08-03T04:11:02.823491",
          "exception": false,
          "start_time": "2022-08-03T04:11:02.787910",
          "status": "completed"
        },
        "tags": [],
        "id": "6f7ead8c",
        "outputId": "bdad6b62-a1a8-40da-a2a5-0cd1d4201310"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>deberta</th>\n",
              "      <th>distilbert</th>\n",
              "      <th>bertofa</th>\n",
              "      <th>overall</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Adequate</th>\n",
              "      <td>0.170911</td>\n",
              "      <td>0.754998</td>\n",
              "      <td>0.729256</td>\n",
              "      <td>0.688338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Effective</th>\n",
              "      <td>0.571105</td>\n",
              "      <td>0.665716</td>\n",
              "      <td>0.731481</td>\n",
              "      <td>0.752194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ineffective</th>\n",
              "      <td>0.408585</td>\n",
              "      <td>0.337416</td>\n",
              "      <td>0.046372</td>\n",
              "      <td>0.399535</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              deberta  distilbert   bertofa   overall\n",
              "label                                                \n",
              "Adequate     0.170911    0.754998  0.729256  0.688338\n",
              "Effective    0.571105    0.665716  0.731481  0.752194\n",
              "Ineffective  0.408585    0.337416  0.046372  0.399535"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "f1_score_df = pd.DataFrame({'deberta':output1[0].tolist(),\n",
        "                         'distilbert':output2[0].tolist(),\n",
        "                         'bertofa':output3[0].tolist(),\n",
        "                         'overall':output4[0].tolist(),\n",
        "                            })\n",
        "f1_score_df['label']=attributes\n",
        "f1_score_df.set_index(['label'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1998868d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:11:02.854596Z",
          "iopub.status.busy": "2022-08-03T04:11:02.854278Z",
          "iopub.status.idle": "2022-08-03T04:11:02.868335Z",
          "shell.execute_reply": "2022-08-03T04:11:02.867426Z"
        },
        "papermill": {
          "duration": 0.031416,
          "end_time": "2022-08-03T04:11:02.870195",
          "exception": false,
          "start_time": "2022-08-03T04:11:02.838779",
          "status": "completed"
        },
        "tags": [],
        "id": "1998868d",
        "outputId": "f73fbc4d-2d5f-442f-9d8b-09393773a43e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1_weighted_score</th>\n",
              "      <th>log loss</th>\n",
              "      <th>model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.314177</td>\n",
              "      <td>1.583759</td>\n",
              "      <td>deberta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.658979</td>\n",
              "      <td>0.712088</td>\n",
              "      <td>distilbert</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.609831</td>\n",
              "      <td>0.728091</td>\n",
              "      <td>bertofa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.653788</td>\n",
              "      <td>0.704765</td>\n",
              "      <td>OVERALL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   f1_weighted_score  log loss       model\n",
              "0           0.314177  1.583759     deberta\n",
              "1           0.658979  0.712088  distilbert\n",
              "2           0.609831  0.728091     bertofa\n",
              "3           0.653788  0.704765     OVERALL"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f1_weight_score = []\n",
        "f1_weight_score.append(output1[1].item())\n",
        "f1_weight_score.append(output2[1].item())\n",
        "f1_weight_score.append(output3[1].item())\n",
        "f1_weight_score.append(output4[1].item())\n",
        "f1_weight_score\n",
        "\n",
        "logloss_score = []\n",
        "logloss_score.append(output1[2].item())\n",
        "logloss_score.append(output2[2].item())\n",
        "logloss_score.append(output3[2].item())\n",
        "logloss_score.append(output4[2].item())\n",
        "logloss_score\n",
        "\n",
        "score_df = pd.DataFrame({'f1_weighted_score':f1_weight_score})\n",
        "score_df['log loss'] = logloss_score\n",
        "score_df['model']=preds\n",
        "score_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db1eb607",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:11:02.901318Z",
          "iopub.status.busy": "2022-08-03T04:11:02.901055Z",
          "iopub.status.idle": "2022-08-03T04:11:02.905786Z",
          "shell.execute_reply": "2022-08-03T04:11:02.904750Z"
        },
        "papermill": {
          "duration": 0.022778,
          "end_time": "2022-08-03T04:11:02.907859",
          "exception": false,
          "start_time": "2022-08-03T04:11:02.885081",
          "status": "completed"
        },
        "tags": [],
        "id": "db1eb607"
      },
      "outputs": [],
      "source": [
        "# # y_pred_overall = (y_pred_deberta*weight['deberta'] + y_pred_distilroberta*weight['distilbert'] + y_pred_bertofa*weight['bertofa'] + y_pred_distilbert*weight['distilroberta'])/4\n",
        "# y_pred_overall = (y_pred_deberta*weight['deberta'] + y_pred_distilbert*weight['distilbert'] + y_pred_bertofa*weight['bertofa'])/(weight['deberta']+weight['distilbert']+weight['bertofa'])\n",
        "\n",
        "\n",
        "# argmax_output = y_pred_overall.argmax(dim=1)\n",
        "# argmax_output = argmax_output.numpy()\n",
        "# output_overall_df = pd.concat([val_df.reset_index(drop=True), pd.DataFrame(argmax_output,columns=['pred_discourse_effectiveness'])], axis=1)\n",
        "# output_overall_df['pred_discourse_effectiveness'] = output_overall_df['pred_discourse_effectiveness'].map({0:'Adequate',1:'Effective',2:'Ineffective'})\n",
        "# #Plot Confusion Matrix\n",
        "# y_true = output_df['discourse_effectiveness'].values\n",
        "# y_pred = output_df['pred_discourse_effectiveness'].values\n",
        "# ax= plt.subplot()\n",
        "# do_conf_matrix(y_true, y_pred, ax=ax)\n",
        "# output_overall_df['discourse_effectiveness_numeric'] = output_overall_df['discourse_effectiveness'].map({'Adequate':0,'Effective':1,'Ineffective':2})\n",
        "# output_overall_df.info()\n",
        "# f1 = f1_score(y_pred_overall.argmax(dim=1),torch.tensor(output_overall_df['discourse_effectiveness_numeric'].values),average=None)\n",
        "# f1\n",
        "# f1_weighted = f1_score(y_pred_overall.softmax(dim=1),torch.tensor(output_overall_df['discourse_effectiveness_numeric'].values),num_classes=3,multiclass=True,average='weighted')\n",
        "# f1_weighted\n",
        "# cel = nn.CrossEntropyLoss()\n",
        "# loss = cel(y_pred_overall,torch.tensor(output_overall_df['discourse_effectiveness_numeric'].values))\n",
        "# loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68dc5623",
      "metadata": {
        "papermill": {
          "duration": 0.015087,
          "end_time": "2022-08-03T04:11:02.937797",
          "exception": false,
          "start_time": "2022-08-03T04:11:02.922710",
          "status": "completed"
        },
        "tags": [],
        "id": "68dc5623"
      },
      "source": [
        "## Read text with wrong classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dd71802",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:11:02.968705Z",
          "iopub.status.busy": "2022-08-03T04:11:02.968443Z",
          "iopub.status.idle": "2022-08-03T04:11:02.987765Z",
          "shell.execute_reply": "2022-08-03T04:11:02.986401Z"
        },
        "papermill": {
          "duration": 0.037185,
          "end_time": "2022-08-03T04:11:02.989890",
          "exception": false,
          "start_time": "2022-08-03T04:11:02.952705",
          "status": "completed"
        },
        "tags": [],
        "id": "6dd71802",
        "outputId": "85ba7b33-16dc-42c9-e85d-3c1e6e8a8fb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7353 entries, 0 to 7352\n",
            "Data columns (total 6 columns):\n",
            " #   Column                        Non-Null Count  Dtype \n",
            "---  ------                        --------------  ----- \n",
            " 0   discourse_id                  7353 non-null   object\n",
            " 1   essay_id                      7353 non-null   object\n",
            " 2   discourse_text                7353 non-null   object\n",
            " 3   discourse_type                7353 non-null   object\n",
            " 4   discourse_effectiveness       7353 non-null   object\n",
            " 5   pred_discourse_effectiveness  7353 non-null   object\n",
            "dtypes: object(6)\n",
            "memory usage: 344.8+ KB\n"
          ]
        }
      ],
      "source": [
        "y_pred_overall = (ypred_deberta*weight['deberta'] + ypred_distilbert*weight['distilbert'] + ypred_bertofa*weight['bertofa'])/(weight['deberta']+weight['distilbert']+weight['bertofa'])\n",
        "argmax_output = y_pred_overall.argmax(dim=1)\n",
        "argmax_output = argmax_output.numpy()\n",
        "output_overall_df = pd.concat([val_df.reset_index(drop=True), pd.DataFrame(argmax_output,columns=['pred_discourse_effectiveness'])], axis=1)\n",
        "output_overall_df['pred_discourse_effectiveness'] = output_overall_df['pred_discourse_effectiveness'].map({0:'Adequate',1:'Effective',2:'Ineffective'})\n",
        "\n",
        "output_overall_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea7fe8da",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:11:03.021883Z",
          "iopub.status.busy": "2022-08-03T04:11:03.021121Z",
          "iopub.status.idle": "2022-08-03T04:11:03.027958Z",
          "shell.execute_reply": "2022-08-03T04:11:03.027127Z"
        },
        "papermill": {
          "duration": 0.02464,
          "end_time": "2022-08-03T04:11:03.029928",
          "exception": false,
          "start_time": "2022-08-03T04:11:03.005288",
          "status": "completed"
        },
        "tags": [],
        "id": "ea7fe8da"
      },
      "outputs": [],
      "source": [
        "bad_pred_df = output_overall_df[output_overall_df['pred_discourse_effectiveness']!=output_overall_df['discourse_effectiveness']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74beec13",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:11:03.061502Z",
          "iopub.status.busy": "2022-08-03T04:11:03.060691Z",
          "iopub.status.idle": "2022-08-03T04:11:03.066809Z",
          "shell.execute_reply": "2022-08-03T04:11:03.065956Z"
        },
        "papermill": {
          "duration": 0.023785,
          "end_time": "2022-08-03T04:11:03.068727",
          "exception": false,
          "start_time": "2022-08-03T04:11:03.044942",
          "status": "completed"
        },
        "tags": [],
        "id": "74beec13"
      },
      "outputs": [],
      "source": [
        "ineffective_bad_pred_df = bad_pred_df.loc[(bad_pred_df['pred_discourse_effectiveness']!=bad_pred_df['discourse_effectiveness'])& (bad_pred_df['discourse_effectiveness']=='Ineffective')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39b2e129",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:11:03.099623Z",
          "iopub.status.busy": "2022-08-03T04:11:03.099335Z",
          "iopub.status.idle": "2022-08-03T04:11:03.110993Z",
          "shell.execute_reply": "2022-08-03T04:11:03.110170Z"
        },
        "papermill": {
          "duration": 0.029413,
          "end_time": "2022-08-03T04:11:03.112974",
          "exception": false,
          "start_time": "2022-08-03T04:11:03.083561",
          "status": "completed"
        },
        "tags": [],
        "id": "39b2e129"
      },
      "outputs": [],
      "source": [
        "def get_text(ids):\n",
        "    with open(f'../input/feedback-prize-effectiveness/train/{ids}.txt', 'r') as file: data = file.read()\n",
        "    return data\n",
        "\n",
        "def display_sample(essay_id,bad_df,train_df):\n",
        "    char_pos = 0\n",
        "    ex = [{\"text\": '',\"ents\": []}]\n",
        "    ex2 = [{\"text\": '',\"ents\": []}]\n",
        "    text = ''\n",
        "    for idx in range(train_df.loc[(train_df['essay_id']==essay_id)].shape[0]):\n",
        "        \n",
        "        discourse_text = train_df.loc[(df.essay_id == essay_id),'discourse_text'].values[idx]\n",
        "        discourse_text = normalizecodec(discourse_text)\n",
        "        begin = char_pos\n",
        "        end = begin + len(discourse_text)\n",
        "        discoursetype = train_df.loc[(train_df.essay_id == essay_id),'discourse_type'].values[idx]\n",
        "        discourse_id = train_df.loc[(train_df.essay_id == essay_id),'discourse_id'].values[idx]\n",
        "        \n",
        "        if bad_df[bad_df.discourse_id == discourse_id].shape[0] != 0:\n",
        "            label_bad = bad_df.loc[(bad_df.discourse_id == discourse_id),'pred_discourse_effectiveness'].values[0]\n",
        "            label_good = bad_df.loc[(bad_df.discourse_id == discourse_id),'discourse_effectiveness'].values[0]\n",
        "            ex[0]['ents'].append({\"start\":begin,\n",
        "                  \"end\":end,\n",
        "                  \"label\":label_bad + '/' + label_good+ ' (Predict/True)' + ' - ' + discoursetype\n",
        "                    })\n",
        "\n",
        "            ex2[0]['ents'].append({\"start\":begin,\n",
        "                  \"end\":end,\n",
        "                  \"label\":label_good + ' - ' + discoursetype + ' (True)'\n",
        "                    })\n",
        "        char_pos = end\n",
        "        text += discourse_text\n",
        "    ex[0]['text']=text\n",
        "    ex2[0]['text']=text\n",
        "    \n",
        "    displacy.render(ex, style=\"ent\", manual=True,jupyter=True,options={\"distance\":100})\n",
        "    print()\n",
        "#     displacy.render(ex2, style=\"ent\", manual=True,jupyter=True,options={\"distance\":100})\n",
        "    return\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08356bb8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:11:03.144430Z",
          "iopub.status.busy": "2022-08-03T04:11:03.143646Z",
          "iopub.status.idle": "2022-08-03T04:11:03.220751Z",
          "shell.execute_reply": "2022-08-03T04:11:03.218593Z"
        },
        "papermill": {
          "duration": 0.094975,
          "end_time": "2022-08-03T04:11:03.222852",
          "exception": false,
          "start_time": "2022-08-03T04:11:03.127877",
          "status": "completed"
        },
        "tags": [],
        "id": "08356bb8",
        "outputId": "2b9341be-363a-4e29-8f22-79d10312af9c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">l believe that all students should perform community service I believe this because we are handed opportunities to make our world a better place, an i think community service is one way to do it. We should take this opportunity by storm. We can be helping a lot of people an communities. I also think if kid do community service it will make them a better person in the future. They will see all the people they helped all the places they fixed an all the plant an animals habitats they saved. I think community service is a great thing for communities, people, plants an animals an the kids their self. \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    We can make this world a better place for the generations to come. \n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Adequate/Ineffective (Predict/True) - Evidence</span>\n",
              "</mark>\n",
              "Kids mite think your being unfair now but they will thank you for it latter. This is a great opportunity. i encourages you to require all students to perform community service. I think they can learn a lot from it.  </div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "display_sample(\"B3E4B633261B\",bad_pred_df,data_path.sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41c3ebb8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:11:03.255506Z",
          "iopub.status.busy": "2022-08-03T04:11:03.253856Z",
          "iopub.status.idle": "2022-08-03T04:11:03.338204Z",
          "shell.execute_reply": "2022-08-03T04:11:03.337138Z"
        },
        "papermill": {
          "duration": 0.102844,
          "end_time": "2022-08-03T04:11:03.340823",
          "exception": false,
          "start_time": "2022-08-03T04:11:03.237979",
          "status": "completed"
        },
        "tags": [],
        "id": "41c3ebb8",
        "outputId": "f361c02d-cc96-4f0c-b051-aedc78530d73"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Being assingned president of the united states is a very big deal, especially to the millions of people that live in this god blessed country.  herThe united states of america has had different presidents ever since the beginning of this country. These presidents are not in it for the money, but they are holding the title  &quot;  president&quot;  because these people want what is right for this country. But, how do we pick who gets to be president? It all comes down to the electoral college. Citizens of the united states are allowed to vote at the age of 18, these votes are said to mean so much, but that isnt always the case. It really all comes down to the number of electoral votes. Why make all these citizens vote, when the outcome might not even follow along with these votes. There are two types of votes. The electoral college votes, and the popular votes which is the number of citizens who voted for one certain canidate. How ever there has been times where the popular vote did not win the election. In 2000, canidate Gore had more of the popular votes then Bush did, but Bush had the most electoral votes. Shouldn't the citizens of this country be the ones who get to determine who the President is? I mean the President has a big duty and the citizens rely on His/Hers duty as president to keep things going right. The President can make huge decisions that affect these citizens which can make things horribly wrong or amazingly right. Yes, I know the people in the electoral college are super smart geniuses that know what they are doing, but? This is the country i live in, this is the country i was raised in, this is the country i love and am so blessed to be \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    I deserve to be able to pick the president i want, or at least have my vote be the reason the president i was rooting for wins. \n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Adequate/Ineffective (Predict/True) - Position</span>\n",
              "</mark>\n",
              "Us fellow citizens of the united states only want whats best for us. We may not be as smart as the people in the electoral college, but that sure wont stop us from knowing who we like and who we think is better for our country. We deserve as much right to have our own president as much as anyone in the elecotral college does.  This God blessed country is home to millions, it might not be perfect, but it is the greatest country in the world. The people who get the amazing benefit of living here deserve to be able to elect the President they want. These people want what they believe is best.    </div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "sample_id = ineffective_bad_pred_df.sample(1)['essay_id'].values[0]\n",
        "display_sample(sample_id,bad_pred_df,data_path.sort_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba5361a2",
      "metadata": {
        "id": "ba5361a2",
        "papermill": {
          "duration": 0.01569,
          "end_time": "2022-08-03T04:11:03.372615",
          "exception": false,
          "start_time": "2022-08-03T04:11:03.356925",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Predict and Submission to Kaggle\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ecae8f2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:11:03.405109Z",
          "iopub.status.busy": "2022-08-03T04:11:03.404263Z",
          "iopub.status.idle": "2022-08-03T04:11:03.414421Z",
          "shell.execute_reply": "2022-08-03T04:11:03.413526Z"
        },
        "id": "0ecae8f2",
        "papermill": {
          "duration": 0.028442,
          "end_time": "2022-08-03T04:11:03.416629",
          "exception": false,
          "start_time": "2022-08-03T04:11:03.388187",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def predict(_Text_Classifier,config):\n",
        "    \n",
        "    data_path = pd.read_csv('/kaggle/input/feedback-prize-effectiveness/train.csv')\n",
        "    test_path = pd.read_csv('/kaggle/input/feedback-prize-effectiveness/test.csv')\n",
        "    attributes = [\"Adequate\" ,\"Effective\",\"Ineffective\"]\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(config['model_name'], use_fast=True)\n",
        "    le = LabelEncoder()\n",
        "    \n",
        "    # Initialize data module\n",
        "    test_data_module = _Data_Module(data_path,\n",
        "                                    test_path,\n",
        "                                    attributes,\n",
        "                                    le,\n",
        "                                    tokenizer,\n",
        "                                    config['model_name'],\n",
        "                                    batch_size=config['batch_size'],\n",
        "                                    text_method = config['text_method']\n",
        "                                   )\n",
        "    test_data_module.setup()\n",
        "\n",
        "    # Initialize Model\n",
        "    model = _Text_Classifier(config,test_data_module)\n",
        "    model.load_state_dict(torch.load(config['PATH']))\n",
        "\n",
        "    # Initialize Trainer\n",
        "    trainer = pl.Trainer(accelerator='auto')\n",
        "\n",
        "    # Run predictions\n",
        "    def predict_text_classification(model, dm):\n",
        "        predictions = trainer.predict(model, datamodule=dm)\n",
        "        return predictions\n",
        "    predictions = predict_text_classification(model, test_data_module)\n",
        "\n",
        "    # Pass logit into a softmax\n",
        "    pred_list = []\n",
        "    for logits in predictions:\n",
        "        pred_list.append(logits)\n",
        "    y_pred = torch.cat(pred_list)\n",
        "    y_pred.shape\n",
        "\n",
        "    softmax_outputs = softmax(y_pred, axis=1)\n",
        "    test_df = test_path.copy()\n",
        "    output_df = pd.concat([test_df[['discourse_id']].reset_index(drop=True), pd.DataFrame(softmax_outputs.numpy(), columns=attributes)], axis=1)\n",
        "#     output_df = pd.concat([test_df[['discourse_id']].reset_index(drop=True), pd.DataFrame(y_pred.numpy(), columns=attributes)], axis=1)\n",
        "    new_cols = [\"discourse_id\",\"Ineffective\",\"Adequate\",\"Effective\"]\n",
        "    output_df = output_df[new_cols]\n",
        "\n",
        "    return output_df, y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f256cb3",
      "metadata": {
        "papermill": {
          "duration": 0.015224,
          "end_time": "2022-08-03T04:11:03.447125",
          "exception": false,
          "start_time": "2022-08-03T04:11:03.431901",
          "status": "completed"
        },
        "tags": [],
        "id": "2f256cb3"
      },
      "source": [
        "## Predict using multiple models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7423ec5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:11:03.479728Z",
          "iopub.status.busy": "2022-08-03T04:11:03.479462Z",
          "iopub.status.idle": "2022-08-03T04:12:42.253103Z",
          "shell.execute_reply": "2022-08-03T04:12:42.251827Z"
        },
        "id": "d7423ec5",
        "papermill": {
          "duration": 98.793349,
          "end_time": "2022-08-03T04:12:42.256062",
          "exception": false,
          "start_time": "2022-08-03T04:11:03.462713",
          "status": "completed"
        },
        "tags": [],
        "outputId": "226de12d-cf95-4f58-976e-4caf1bb57a27"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/opt/conda/lib/python3.7/site-packages/transformers/convert_slow_tokenizer.py:435: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Some weights of the model checkpoint at ../input/deberta-v3-base/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifer.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifer.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.bias']\n",
            "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['embeddings.word_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query_proj.weight', 'encoder.layer.0.attention.self.query_proj.bias', 'encoder.layer.0.attention.self.key_proj.weight', 'encoder.layer.0.attention.self.key_proj.bias', 'encoder.layer.0.attention.self.value_proj.weight', 'encoder.layer.0.attention.self.value_proj.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query_proj.weight', 'encoder.layer.1.attention.self.query_proj.bias', 'encoder.layer.1.attention.self.key_proj.weight', 'encoder.layer.1.attention.self.key_proj.bias', 'encoder.layer.1.attention.self.value_proj.weight', 'encoder.layer.1.attention.self.value_proj.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/loops/utilities.py:95: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
            "  category=PossibleUserWarning,\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "464016aa78d44bd3aa4eca36eb9d3872",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Predicting: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['embeddings.word_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'transformer.layer.0.attention.q_lin.weight', 'transformer.layer.0.attention.q_lin.bias', 'transformer.layer.0.attention.k_lin.weight', 'transformer.layer.0.attention.k_lin.bias', 'transformer.layer.0.attention.v_lin.weight', 'transformer.layer.0.attention.v_lin.bias', 'transformer.layer.0.attention.out_lin.weight', 'transformer.layer.0.attention.out_lin.bias', 'transformer.layer.0.sa_layer_norm.weight', 'transformer.layer.0.sa_layer_norm.bias', 'transformer.layer.0.ffn.lin1.weight', 'transformer.layer.0.ffn.lin1.bias', 'transformer.layer.0.ffn.lin2.weight', 'transformer.layer.0.ffn.lin2.bias', 'transformer.layer.0.output_layer_norm.weight', 'transformer.layer.0.output_layer_norm.bias', 'transformer.layer.1.attention.q_lin.weight', 'transformer.layer.1.attention.q_lin.bias', 'transformer.layer.1.attention.k_lin.weight', 'transformer.layer.1.attention.k_lin.bias', 'transformer.layer.1.attention.v_lin.weight', 'transformer.layer.1.attention.v_lin.bias', 'transformer.layer.1.attention.out_lin.weight', 'transformer.layer.1.attention.out_lin.bias', 'transformer.layer.1.sa_layer_norm.weight', 'transformer.layer.1.sa_layer_norm.bias', 'transformer.layer.1.ffn.lin1.weight', 'transformer.layer.1.ffn.lin1.bias', 'transformer.layer.1.ffn.lin2.weight', 'transformer.layer.1.ffn.lin2.bias', 'transformer.layer.1.output_layer_norm.weight', 'transformer.layer.1.output_layer_norm.bias', 'transformer.layer.2.attention.q_lin.weight', 'transformer.layer.2.attention.q_lin.bias', 'transformer.layer.2.attention.k_lin.weight', 'transformer.layer.2.attention.k_lin.bias', 'transformer.layer.2.attention.v_lin.weight', 'transformer.layer.2.attention.v_lin.bias', 'transformer.layer.2.attention.out_lin.weight', 'transformer.layer.2.attention.out_lin.bias', 'transformer.layer.2.sa_layer_norm.weight', 'transformer.layer.2.sa_layer_norm.bias', 'transformer.layer.2.ffn.lin1.weight', 'transformer.layer.2.ffn.lin1.bias', 'transformer.layer.2.ffn.lin2.weight', 'transformer.layer.2.ffn.lin2.bias', 'transformer.layer.2.output_layer_norm.weight', 'transformer.layer.2.output_layer_norm.bias']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/loops/utilities.py:95: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
            "  category=PossibleUserWarning,\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c565b18a3bbe4e6a8a2ac3827106bcaf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Predicting: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at ../input/bertlargeuncasedsparse90unstructuredpruned/bert-large-uncased-sparse-90-unstructured-pruneofa were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['embeddings.word_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.20.output.LayerNorm.bias']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/loops/utilities.py:95: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
            "  category=PossibleUserWarning,\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eedf4875d3d5451ca82ad69183cc4c5c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Predicting: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "output_DeBerta, y_pred_deberta = predict(DeBerta_Text_Classifier,deberta_config)\n",
        "output_DistilBert, y_pred_distilbert = predict(DistilBert_Text_Classifier,distilbert_config)\n",
        "output_BertOFA, y_pred_bertofa = predict(BertOFA_Text_Classifier,bertofa_config)\n",
        "# output_distilRoBerta = predict(DistilRoBerta_Text_Classifier,distilroberta_config)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e670012c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:12:42.295212Z",
          "iopub.status.busy": "2022-08-03T04:12:42.294894Z",
          "iopub.status.idle": "2022-08-03T04:12:42.299529Z",
          "shell.execute_reply": "2022-08-03T04:12:42.298600Z"
        },
        "id": "e670012c",
        "papermill": {
          "duration": 0.025474,
          "end_time": "2022-08-03T04:12:42.301754",
          "exception": false,
          "start_time": "2022-08-03T04:12:42.276280",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "# output_df = output_DeBerta.copy()\n",
        "\n",
        "# for attribute in attributes:\n",
        "#     output_df[attribute] =  (output_DeBerta[attribute]*weight['deberta'] + \n",
        "#                             output_DistilBert[attribute]*weight['distilbert'] + \n",
        "#                             output_BertOFA[attribute]*weight['bertofa'])/(weight['deberta']+weight['distilbert']+weight['bertofa'])\n",
        "# for atttribute in attributes:\n",
        "#     output_df[attribute] =  (output_DeBerta[attribute]*weight['deberta'] + \n",
        "#                             output_DistilBert[attribute]*weight['distilbert'] + \n",
        "#                             output_BertOFA[attribute]*weight['bertofa'] +\n",
        "#                             output_distilRoBerta[attribute]*weight['distilroberta'])/4\n",
        "\n",
        "# output_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d935eab",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:12:42.340523Z",
          "iopub.status.busy": "2022-08-03T04:12:42.340171Z",
          "iopub.status.idle": "2022-08-03T04:12:42.353245Z",
          "shell.execute_reply": "2022-08-03T04:12:42.352211Z"
        },
        "papermill": {
          "duration": 0.035868,
          "end_time": "2022-08-03T04:12:42.355976",
          "exception": false,
          "start_time": "2022-08-03T04:12:42.320108",
          "status": "completed"
        },
        "tags": [],
        "id": "3d935eab"
      },
      "outputs": [],
      "source": [
        "weight_deberta = torch.tensor([weight['deberta']])\n",
        "weight_distilbert = torch.tensor([weight['distilbert']])\n",
        "weight_bertofa = torch.tensor([weight['bertofa']])\n",
        "\n",
        "weight_deberta=weight_deberta.repeat(y_pred_deberta.shape[0],1)\n",
        "weight_distilbert=weight_distilbert.repeat(y_pred_distilbert.shape[0],1)\n",
        "weight_bertofa=weight_bertofa.repeat(y_pred_bertofa.shape[0],1)\n",
        "\n",
        "    # Method 1\n",
        "# for idx,ypred in enumerate(y_pred_deberta):\n",
        "#     if (ypred[2]>ypred[0]) &(ypred[2]>ypred[1]):\n",
        "#         ratio_bertofa = weight_bertofa[idx]/(weight_distilbert[idx]+weight_deberta[idx])\n",
        "#         ratio_distilbert = weight_distilbert[idx]/(weight_bertofa[idx]+weight_deberta[idx])\n",
        "#         weight_deberta[idx]=0.35\n",
        "#         weight_bertofa[idx]=(1-weight_deberta[idx])*ratio_bertofa\n",
        "#         weight_distilbert[idx]=(1-weight_deberta[idx])*ratio_distilbert\n",
        "        \n",
        "# Method 3\n",
        "for idx,ypred in enumerate(y_pred_deberta):\n",
        "    if (ypred[2]>ypred[0]) &(ypred[2]>ypred[1]):\n",
        "        ratio_bertofa = weight_bertofa[idx]/(weight_distilbert[idx]+weight_deberta[idx])\n",
        "        ratio_distilbert = weight_distilbert[idx]/(weight_bertofa[idx]+weight_deberta[idx])\n",
        "        weight_deberta[idx]=0.6\n",
        "        weight_bertofa[idx]=0.02\n",
        "        weight_distilbert[idx]=0.38 \n",
        "        \n",
        "numerator = torch.mul(y_pred_deberta,weight_deberta) + torch.mul(y_pred_distilbert,weight_bertofa) + torch.mul(y_pred_bertofa,weight_distilbert)\n",
        "denominator = torch.add(torch.add(weight_deberta,weight_bertofa),weight_distilbert)\n",
        "y_pred_overall = torch.div(numerator,denominator)\n",
        "\n",
        "softmax_outputs = softmax(y_pred_overall, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75e05d8f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:12:42.396270Z",
          "iopub.status.busy": "2022-08-03T04:12:42.395955Z",
          "iopub.status.idle": "2022-08-03T04:12:42.405659Z",
          "shell.execute_reply": "2022-08-03T04:12:42.404713Z"
        },
        "papermill": {
          "duration": 0.032056,
          "end_time": "2022-08-03T04:12:42.407914",
          "exception": false,
          "start_time": "2022-08-03T04:12:42.375858",
          "status": "completed"
        },
        "tags": [],
        "id": "75e05d8f"
      },
      "outputs": [],
      "source": [
        "output_df = pd.concat([test_path[['discourse_id']].reset_index(drop=True), pd.DataFrame(softmax_outputs.numpy(), columns=attributes)], axis=1)\n",
        "#     output_df = pd.concat([test_df[['discourse_id']].reset_index(drop=True), pd.DataFrame(y_pred.numpy(), columns=attributes)], axis=1)\n",
        "new_cols = [\"discourse_id\",\"Ineffective\",\"Adequate\",\"Effective\"]\n",
        "output_df = output_df[new_cols]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fdd3a9d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-03T04:12:42.447665Z",
          "iopub.status.busy": "2022-08-03T04:12:42.446722Z",
          "iopub.status.idle": "2022-08-03T04:12:42.465512Z",
          "shell.execute_reply": "2022-08-03T04:12:42.464531Z"
        },
        "id": "0fdd3a9d",
        "papermill": {
          "duration": 0.040895,
          "end_time": "2022-08-03T04:12:42.467749",
          "exception": false,
          "start_time": "2022-08-03T04:12:42.426854",
          "status": "completed"
        },
        "tags": [],
        "outputId": "291b0a2f-3b26-490c-af24-7d2a63cbfff5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>discourse_id</th>\n",
              "      <th>Ineffective</th>\n",
              "      <th>Adequate</th>\n",
              "      <th>Effective</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a261b6e14276</td>\n",
              "      <td>0.019432</td>\n",
              "      <td>0.308107</td>\n",
              "      <td>0.672461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5a88900e7dc1</td>\n",
              "      <td>0.031250</td>\n",
              "      <td>0.499879</td>\n",
              "      <td>0.468872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9790d835736b</td>\n",
              "      <td>0.018704</td>\n",
              "      <td>0.364542</td>\n",
              "      <td>0.616753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>75ce6d68b67b</td>\n",
              "      <td>0.031078</td>\n",
              "      <td>0.440425</td>\n",
              "      <td>0.528497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>93578d946723</td>\n",
              "      <td>0.029202</td>\n",
              "      <td>0.408765</td>\n",
              "      <td>0.562033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2e214524dbe3</td>\n",
              "      <td>0.015405</td>\n",
              "      <td>0.265103</td>\n",
              "      <td>0.719492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>84812fc2ab9f</td>\n",
              "      <td>0.017534</td>\n",
              "      <td>0.273256</td>\n",
              "      <td>0.709210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>c668ff840720</td>\n",
              "      <td>0.019813</td>\n",
              "      <td>0.359249</td>\n",
              "      <td>0.620938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>739a6d00f44a</td>\n",
              "      <td>0.018331</td>\n",
              "      <td>0.234742</td>\n",
              "      <td>0.746927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>bcfae2c9a244</td>\n",
              "      <td>0.018542</td>\n",
              "      <td>0.318517</td>\n",
              "      <td>0.662942</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   discourse_id  Ineffective  Adequate  Effective\n",
              "0  a261b6e14276     0.019432  0.308107   0.672461\n",
              "1  5a88900e7dc1     0.031250  0.499879   0.468872\n",
              "2  9790d835736b     0.018704  0.364542   0.616753\n",
              "3  75ce6d68b67b     0.031078  0.440425   0.528497\n",
              "4  93578d946723     0.029202  0.408765   0.562033\n",
              "5  2e214524dbe3     0.015405  0.265103   0.719492\n",
              "6  84812fc2ab9f     0.017534  0.273256   0.709210\n",
              "7  c668ff840720     0.019813  0.359249   0.620938\n",
              "8  739a6d00f44a     0.018331  0.234742   0.746927\n",
              "9  bcfae2c9a244     0.018542  0.318517   0.662942"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# output_df = output_distilRoBerta.copy()\n",
        "output_df.to_csv('submission.csv', index=False)\n",
        "pd.read_csv('submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9407588e",
      "metadata": {
        "papermill": {
          "duration": 0.016088,
          "end_time": "2022-08-03T04:12:42.501132",
          "exception": false,
          "start_time": "2022-08-03T04:12:42.485044",
          "status": "completed"
        },
        "tags": [],
        "id": "9407588e"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 153.40383,
      "end_time": "2022-08-03T04:12:45.778290",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-08-03T04:10:12.374460",
      "version": "2.3.4"
    },
    "colab": {
      "name": "2-modelling-evaluation.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}