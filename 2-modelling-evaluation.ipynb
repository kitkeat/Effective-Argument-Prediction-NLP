{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "2-modelling-evaluation.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "106d82b288ff4f6fa4213623f1fb3908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37ba5bb6440e422f9f9f29c6089f5e99",
              "IPY_MODEL_36f50cf8f400400aab50a21a261bbfe1",
              "IPY_MODEL_77893e3c601a4c7d99048ffa554bfc86"
            ],
            "layout": "IPY_MODEL_441f471ebc904df0bbc29206f0de32d4"
          }
        },
        "37ba5bb6440e422f9f9f29c6089f5e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c6de79c7cff48c4871a8c7fc19f8006",
            "placeholder": "​",
            "style": "IPY_MODEL_94b316ec50524588ac39dd45bc1945de",
            "value": "Downloading: 100%"
          }
        },
        "36f50cf8f400400aab50a21a261bbfe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe7b3c31c943408ba7c8f54dabdc68bd",
            "max": 579,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_009db0817af449ae8e42c4f71549e7b0",
            "value": 579
          }
        },
        "77893e3c601a4c7d99048ffa554bfc86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_679e7c93e2b04648aac364b89320ae9e",
            "placeholder": "​",
            "style": "IPY_MODEL_5f5e7b44f1204f0996b030f91d50117d",
            "value": " 579/579 [00:00&lt;00:00, 5.30kB/s]"
          }
        },
        "441f471ebc904df0bbc29206f0de32d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c6de79c7cff48c4871a8c7fc19f8006": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94b316ec50524588ac39dd45bc1945de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe7b3c31c943408ba7c8f54dabdc68bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "009db0817af449ae8e42c4f71549e7b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "679e7c93e2b04648aac364b89320ae9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f5e7b44f1204f0996b030f91d50117d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88fddf9864fd49bf82c64f0abfbe92f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51826e4285a94b2d9ef6076edf49113f",
              "IPY_MODEL_4759b17f00e545ed8e4f8f4bc2d0785c",
              "IPY_MODEL_30dd49097e934ba49bc10d4c4fe2695f"
            ],
            "layout": "IPY_MODEL_c331d60bd4f44ef089d9d6506e7f02c6"
          }
        },
        "51826e4285a94b2d9ef6076edf49113f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e08fb56f80a4bf19b129130debd5b68",
            "placeholder": "​",
            "style": "IPY_MODEL_e6375386b2324eb5b4193ffcce63f74a",
            "value": "Downloading: 100%"
          }
        },
        "4759b17f00e545ed8e4f8f4bc2d0785c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8349088604e443b3b4be10b229aabdcc",
            "max": 371146213,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d4894e5cf8246f79ec6b85fd36cd874",
            "value": 371146213
          }
        },
        "30dd49097e934ba49bc10d4c4fe2695f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1775707efd04eb6bbfeb4d5ee1c9cce",
            "placeholder": "​",
            "style": "IPY_MODEL_e98b4a5bb1e44925939a147c8be955b0",
            "value": " 354M/354M [00:19&lt;00:00, 15.5MB/s]"
          }
        },
        "c331d60bd4f44ef089d9d6506e7f02c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e08fb56f80a4bf19b129130debd5b68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6375386b2324eb5b4193ffcce63f74a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8349088604e443b3b4be10b229aabdcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d4894e5cf8246f79ec6b85fd36cd874": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1775707efd04eb6bbfeb4d5ee1c9cce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e98b4a5bb1e44925939a147c8be955b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bc0a0bd1bad41058db2248134e55560": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b16a4ead8164d1b931ac946717b8b80",
              "IPY_MODEL_97ad4c53916f4d5e92e97de506443719",
              "IPY_MODEL_e7798f0a99864ff4836b04d11ee1d2e0"
            ],
            "layout": "IPY_MODEL_506fbd65151b48b2a51cfb35ca8a6ed3"
          }
        },
        "5b16a4ead8164d1b931ac946717b8b80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b81839b90bb474eaa8a9bf61f68f71d",
            "placeholder": "​",
            "style": "IPY_MODEL_2fc680a3a14646ad8c17d2ab7a8b2c4c",
            "value": "Downloading: 100%"
          }
        },
        "97ad4c53916f4d5e92e97de506443719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_266762c9f79547c7b0a69dc20d9ec12f",
            "max": 657,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bbd7fb43a7b4e2f8c55d525c704373a",
            "value": 657
          }
        },
        "e7798f0a99864ff4836b04d11ee1d2e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdfe2e4f110b439e8d72b97b2f80e592",
            "placeholder": "​",
            "style": "IPY_MODEL_8f329f935a6747a79601fed8484b38c4",
            "value": " 657/657 [00:00&lt;00:00, 4.87kB/s]"
          }
        },
        "506fbd65151b48b2a51cfb35ca8a6ed3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b81839b90bb474eaa8a9bf61f68f71d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fc680a3a14646ad8c17d2ab7a8b2c4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "266762c9f79547c7b0a69dc20d9ec12f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bbd7fb43a7b4e2f8c55d525c704373a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cdfe2e4f110b439e8d72b97b2f80e592": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f329f935a6747a79601fed8484b38c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98f4757bf6ae40c38007495c41bf8285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25b3a9a3e32d4c73abccaac9f51ebb54",
              "IPY_MODEL_5db510e600c849fea36340f4088df75a",
              "IPY_MODEL_9f41598f98164e41a7bb160e4c84eeaa"
            ],
            "layout": "IPY_MODEL_eb599e4df9234c8ebd77e080e69070b0"
          }
        },
        "25b3a9a3e32d4c73abccaac9f51ebb54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afd2eddc109f4b33912d0dce2a8ad79b",
            "placeholder": "​",
            "style": "IPY_MODEL_dc848060e80f4beb990ecf6b09223ab8",
            "value": "Downloading: 100%"
          }
        },
        "5db510e600c849fea36340f4088df75a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0af99a9e70b45c9ad1c773836ce6ecf",
            "max": 1345068133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8833c6e9a46046d2915400a9feab9c06",
            "value": 1345068133
          }
        },
        "9f41598f98164e41a7bb160e4c84eeaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bae8ed778823410e9b4ea20f7609ed34",
            "placeholder": "​",
            "style": "IPY_MODEL_06e4044212eb4cc6ac23cf00dc3c3f5e",
            "value": " 1.25G/1.25G [00:31&lt;00:00, 51.7MB/s]"
          }
        },
        "eb599e4df9234c8ebd77e080e69070b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afd2eddc109f4b33912d0dce2a8ad79b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc848060e80f4beb990ecf6b09223ab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0af99a9e70b45c9ad1c773836ce6ecf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8833c6e9a46046d2915400a9feab9c06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bae8ed778823410e9b4ea20f7609ed34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06e4044212eb4cc6ac23cf00dc3c3f5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50b78c46abcd4002886493bff2cf0463": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e02e322aeb245598e7ffd0aa07dc644",
              "IPY_MODEL_9502e05784ee41eca2df5b5dc7ee5c29",
              "IPY_MODEL_62280ad770d641b7a35c9015e703159e"
            ],
            "layout": "IPY_MODEL_6b2473debb544c4c9d81cbc79a793dc8"
          }
        },
        "6e02e322aeb245598e7ffd0aa07dc644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d05d301f8ee4d48aff0a1009b42a871",
            "placeholder": "​",
            "style": "IPY_MODEL_026903422bfc435cb7672c21548d6690",
            "value": "Downloading: 100%"
          }
        },
        "9502e05784ee41eca2df5b5dc7ee5c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be3307f447774feba3b42f18e9cca272",
            "max": 267967963,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05876b7e299845a083c5272aba198e38",
            "value": 267967963
          }
        },
        "62280ad770d641b7a35c9015e703159e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1fe78d2235c4abb9c0171ff89dea171",
            "placeholder": "​",
            "style": "IPY_MODEL_12f077eefc234438913806b7fd636b5f",
            "value": " 256M/256M [00:05&lt;00:00, 52.2MB/s]"
          }
        },
        "6b2473debb544c4c9d81cbc79a793dc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d05d301f8ee4d48aff0a1009b42a871": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "026903422bfc435cb7672c21548d6690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be3307f447774feba3b42f18e9cca272": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05876b7e299845a083c5272aba198e38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1fe78d2235c4abb9c0171ff89dea171": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12f077eefc234438913806b7fd636b5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cead9ce1ed374ddfacaef322e6618293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a0ce15c506d4e2db87101af59fd31b9",
              "IPY_MODEL_5900203915cd4c79aee31a614bcae0d3",
              "IPY_MODEL_ba76d1e07a0c4c7d85553582e30e68f1"
            ],
            "layout": "IPY_MODEL_1115a0b8363d4b79b12993e32d5fd4a0"
          }
        },
        "3a0ce15c506d4e2db87101af59fd31b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7877c34d95b44e38caee0473d7fe846",
            "placeholder": "​",
            "style": "IPY_MODEL_2adeba72070d483694581941f2c4829b",
            "value": "Predicting DataLoader 0: 100%"
          }
        },
        "5900203915cd4c79aee31a614bcae0d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efe8de5719e446f58e899261b86826cf",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20b4a80bd25f45b58a55d98a3aa08b10",
            "value": 2
          }
        },
        "ba76d1e07a0c4c7d85553582e30e68f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f6081cd5e6b47619aba8f5a47f82151",
            "placeholder": "​",
            "style": "IPY_MODEL_66cb02fd0bff494695bb179438a41879",
            "value": " 2/2 [00:32&lt;00:00, 16.26s/it]"
          }
        },
        "1115a0b8363d4b79b12993e32d5fd4a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "b7877c34d95b44e38caee0473d7fe846": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2adeba72070d483694581941f2c4829b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efe8de5719e446f58e899261b86826cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20b4a80bd25f45b58a55d98a3aa08b10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f6081cd5e6b47619aba8f5a47f82151": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66cb02fd0bff494695bb179438a41879": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f07fc0492e804a4a8e7d544262683762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2555f4b319b74cd48c33e77df16c2b74",
              "IPY_MODEL_e163904e7ba943409f5c6dec62361987"
            ],
            "layout": "IPY_MODEL_0b650a25b5b044f780a784401d68df8e"
          }
        },
        "2555f4b319b74cd48c33e77df16c2b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da519896ea914bf3a02897659942301e",
            "placeholder": "​",
            "style": "IPY_MODEL_b401e4d6184e425b847ce6f105719b18",
            "value": "0.009 MB of 0.009 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "e163904e7ba943409f5c6dec62361987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36a20af1970248888d27e1b063a119ce",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff26b1344587414f8fd825675b990b70",
            "value": 1
          }
        },
        "0b650a25b5b044f780a784401d68df8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da519896ea914bf3a02897659942301e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b401e4d6184e425b847ce6f105719b18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36a20af1970248888d27e1b063a119ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff26b1344587414f8fd825675b990b70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kitkeat/Effective-Argument-Prediction-NLP/blob/main/2-modelling-evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # ! pip install accelerate nvidia-ml-py3\n",
        "! pip install datasets==2.1.0\n",
        "! pip install transformers==4.18.0\n",
        "! pip install sentencepiece==0.1.96\n",
        "! pip install pytorch-lightning==1.6.5\n",
        "! pip install torchmetrics==0.9.2\n",
        "! pip install wandb==0.12.21"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "id": "wMqf8jrybYJf",
        "outputId": "bd487750-3b7f-47e0-cf06-6faf87c9c23d",
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:06.301478Z",
          "iopub.execute_input": "2022-08-03T12:57:06.302153Z",
          "iopub.status.idle": "2022-08-03T12:57:06.333004Z",
          "shell.execute_reply.started": "2022-08-03T12:57:06.302027Z",
          "shell.execute_reply": "2022-08-03T12:57:06.331457Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets==2.1.0 in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==2.1.0) (0.3.5.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets==2.1.0) (4.64.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets==2.1.0) (3.8.1)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets==2.1.0) (6.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets==2.1.0) (21.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==2.1.0) (1.3.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets==2.1.0) (4.12.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets==2.1.0) (2.23.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets==2.1.0) (3.0.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets==2.1.0) (2022.7.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets==2.1.0) (0.8.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets==2.1.0) (0.18.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==2.1.0) (0.70.13)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets==2.1.0) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.1.0) (3.7.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.1.0) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.1.0) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets==2.1.0) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==2.1.0) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==2.1.0) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==2.1.0) (2.10)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==2.1.0) (6.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==2.1.0) (0.13.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==2.1.0) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==2.1.0) (22.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==2.1.0) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==2.1.0) (2.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==2.1.0) (1.7.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets==2.1.0) (3.8.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==2.1.0) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==2.1.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==2.1.0) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers==4.18.0 in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (4.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (0.8.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (3.7.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (0.0.53)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.18.0) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.18.0) (3.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0) (1.25.11)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.18.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.18.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.18.0) (1.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece==0.1.96 in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch-lightning==1.6.5 in /usr/local/lib/python3.7/dist-packages (1.6.5)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.5) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.5) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.5) (4.1.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.5) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.5) (4.64.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.5) (6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.5) (0.9.2)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.5) (2022.7.1)\n",
            "Requirement already satisfied: pyDeprecate>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.5) (0.3.2)\n",
            "Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.5) (1.12.0+cu113)\n",
            "Requirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.5) (3.17.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (3.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning==1.6.5) (3.0.9)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1->pytorch-lightning==1.6.5) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (1.47.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (1.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (0.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (0.37.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5) (1.35.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.5) (3.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (1.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (0.13.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (1.7.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.5) (2.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchmetrics==0.9.2 in /usr/local/lib/python3.7/dist-packages (0.9.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics==0.9.2) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics==0.9.2) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics==0.9.2) (1.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics==0.9.2) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics==0.9.2) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb==0.12.21 in /usr/local/lib/python3.7/dist-packages (0.12.21)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.21) (5.4.8)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.21) (0.1.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.21) (0.4.0)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.21) (1.0.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.21) (57.4.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.21) (2.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.21) (2.23.0)\n",
            "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.21) (3.17.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.21) (7.1.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.21) (1.3.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.21) (1.15.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.21) (6.0)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.21) (3.1.27)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.21) (1.9.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb==0.12.21) (4.0.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb==0.12.21) (4.1.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb==0.12.21) (5.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb==0.12.21) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb==0.12.21) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb==0.12.21) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb==0.12.21) (2022.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         os.path.join(dirname, filename)\n",
        "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "# run_type = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option(\"max_colwidth\", None)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import re\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding, AdamW, get_cosine_schedule_with_warmup, EarlyStoppingCallback, AutoModel\n",
        "from datasets import Dataset, Value, ClassLabel, Features, load_metric\n",
        "import math\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.checkpoint import checkpoint # need to call when using gradient_checkpointing\n",
        "\n",
        "from sklearn.metrics import log_loss, confusion_matrix\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from scipy.special import softmax\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import seed_everything\n",
        "from pytorch_lightning.callbacks import EarlyStopping, TQDMProgressBar\n",
        "from torchmetrics.functional import f1_score\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "import wandb\n",
        "\n",
        "from text_unidecode import unidecode\n",
        "from typing import Dict, List, Tuple\n",
        "import codecs"
      ],
      "metadata": {
        "id": "_Qo3zsKzbYJi",
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:07.957068Z",
          "iopub.execute_input": "2022-08-03T12:57:07.957534Z",
          "iopub.status.idle": "2022-08-03T12:57:23.489128Z",
          "shell.execute_reply.started": "2022-08-03T12:57:07.957491Z",
          "shell.execute_reply": "2022-08-03T12:57:23.487742Z"
        },
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3zN9GhJeqtx",
        "outputId": "de5e7ad4-18b9-4c52-d8ac-160e1132c0c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check GPU availability"
      ],
      "metadata": {
        "id": "bHeiH9uLelCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "id": "gYfDzL4vbYJi",
        "outputId": "49024bc0-69a7-4741-fa23-ca4773b776f5",
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:23.566611Z",
          "iopub.execute_input": "2022-08-03T12:57:23.566954Z",
          "iopub.status.idle": "2022-08-03T12:57:23.576544Z",
          "shell.execute_reply.started": "2022-08-03T12:57:23.566922Z",
          "shell.execute_reply": "2022-08-03T12:57:23.575606Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Login to Weight and Bias"
      ],
      "metadata": {
        "id": "tQi2UWQaelC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  wandb_api = open('/content/drive/MyDrive/Colab Notebooks/WandBapi/wandbapi.txt', 'r').read()\n",
        "  !wandb login {wandb_api}\n",
        "except:\n",
        "  try:\n",
        "    from kaggle_secrets import UserSecretsClient\n",
        "    user_secrets = UserSecretsClient()\n",
        "    secret_value = user_secrets.get_secret(\"wand_api\")\n",
        "    !wandb login {secret_value}\n",
        "\n",
        "  except:\n",
        "    print(\"wandb failed to login...\")\n",
        "    \n"
      ],
      "metadata": {
        "id": "ZvmYfktWDgpz",
        "outputId": "246647de-8a6f-419b-f8d9-4a94e2d0e250",
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:23.581113Z",
          "iopub.execute_input": "2022-08-03T12:57:23.581498Z",
          "iopub.status.idle": "2022-08-03T12:57:26.679144Z",
          "shell.execute_reply.started": "2022-08-03T12:57:23.581448Z",
          "shell.execute_reply": "2022-08-03T12:57:26.677602Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "print(f'Current datetime: {timestr}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNfe3qbFvV5b",
        "outputId": "baac59dd-23a9-4bf3-9c55-44ca8eca0855"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current datetime: 20220804-051933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration"
      ],
      "metadata": {
        "id": "PAKCk5__elC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "attributes = [\"Adequate\" ,\"Effective\",\"Ineffective\"]\n",
        "\n",
        "try:\n",
        "  data_path = pd.read_csv('/kaggle/input/feedback-prize-effectiveness/train.csv')\n",
        "  test_path = pd.read_csv('/kaggle/input/feedback-prize-effectiveness/test.csv')\n",
        "except:\n",
        "  data_path = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/train.csv')\n",
        "  test_path = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/test.csv')\n",
        "\n",
        "deberta_config={'name':'deberta',\n",
        "                'model_name': 'microsoft/deberta-v3-base',\n",
        "                'existing_tuned_model_name' : 'kitkeat/deberta-v3-base-argumentativewriting',\n",
        "                'newly_tuned_model_path' : '',\n",
        "                # 'PATH': '/content/drive/MyDrive/Colab Notebooks/FineTuneModel/deberta_E3Size16Lr3e-05Warm0.01Weight0.01Freeze2Drop0.1Text0.pth',\n",
        "                # 'model_name': '../input/deberta-v3-base/deberta-v3-base',\n",
        "                # 'PATH' : '../input/debertav3basefinetuned3172022/deberta_E3Size16Lr3e-05Warm0.01Weight0.01Freeze2Drop0.1Text0.pth',\n",
        "                'n_labels': 3,\n",
        "                'batch_size': 16,\n",
        "                'lr': 3e-5,\n",
        "                'warmup': 0.01, \n",
        "                'weight_decay': 0.01,\n",
        "                'n_epochs': 4,\n",
        "                'n_freeze' : 2,#9,\n",
        "                'p_dropout':0.65,\n",
        "                'text_method': 2\n",
        "                }\n",
        "\n",
        "distilbert_config={'name': 'distilbert',\n",
        "                'model_name':'distilbert-base-uncased',\n",
        "                'existing_tuned_model_name' : 'kitkeat/distilbert-based-uncased-argumentativewriting',\n",
        "                'newly_tuned_model_path' : '',\n",
        "                # 'PATH':'/content/drive/MyDrive/Colab Notebooks/FineTuneModel/distilbert-frozenembedding&2transformlayer-5epoch-lr6e5-drop02.pth',\n",
        "                # 'model_name': '../input/transformers-pretrained-distilbert/distilbert-base-uncased-distilled-squad',\n",
        "                # 'PATH' : '../input/distilberttuned/distilbert-frozenembedding2transformlayer-5epoch-lr6e5-drop02.pth',\n",
        "                'n_labels': 3,\n",
        "                'batch_size': 64,\n",
        "                'lr': 8e-4,#6e-5,\n",
        "                'warmup': 0.2, \n",
        "                'weight_decay': 0.001,\n",
        "                'n_epochs': 5,#4,\n",
        "                'n_freeze' : 3,\n",
        "                'p_dropout':0.6,#0.2,#0.6,\n",
        "                'text_method': 1\n",
        "                }\n",
        "\n",
        "bertofa_config={'name':'bertofa',\n",
        "                'model_name':'Intel/bert-large-uncased-sparse-90-unstructured-pruneofa',\n",
        "                'existing_tuned_model_name': 'kitkeat/bert-large-uncased-sparse-90-unstructured-pruneofa-argumentativewriting',\n",
        "                'newly_tuned_model_path' : '',\n",
        "                # 'PATH' : '/content/drive/MyDrive/Colab Notebooks/FineTuneModel/Bert_OFA_E3Size64Lr0.0001Warm02Weight1e-06Freeze21Drop001_full.pth',\n",
        "                # 'model_name': '../input/bertlargeuncasedsparse90unstructuredpruned/bert-large-uncased-sparse-90-unstructured-pruneofa',\n",
        "                # 'PATH' : '../input/bert-ofa-pretuned3072022/Bert_OFA_E3Size64Lr0.0001Warm02Weight1e-06Freeze21Drop001_full.pth',\n",
        "                'n_labels': 3,\n",
        "                'batch_size': 64,\n",
        "                'lr': 1e-4,\n",
        "                'warmup': 0.2, \n",
        "                'weight_decay': 1e-6,\n",
        "                'n_epochs': 3,\n",
        "                'n_freeze' : 21,\n",
        "                'p_dropout':0.1,\n",
        "                'text_method': 2\n",
        "                }\n",
        "\n",
        "# distilroberta_config={'name':'distilroberta',\n",
        "#                 # 'model_name': '../input/distilrobertabase/distilroberta-base',\n",
        "#                 # 'PATH' : '../input/distilrobertafinetuned3072022/epoch7-step1840.pth',\n",
        "#                 'n_labels': 3,\n",
        "#                 'batch_size': 128,\n",
        "#                 'lr': 6e-5,\n",
        "#                 'warmup': 0.2, \n",
        "#                 'weight_decay': 0.001,\n",
        "#                 'n_epochs': 10,\n",
        "#                 'n_freeze' : 5,\n",
        "#                 'p_dropout':0,\n",
        "#                 'text_method': 2\n",
        "#                 }\n",
        "\n",
        "seed_everything(91, workers=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:26.681852Z",
          "iopub.execute_input": "2022-08-03T12:57:26.682304Z",
          "iopub.status.idle": "2022-08-03T12:57:27.022672Z",
          "shell.execute_reply.started": "2022-08-03T12:57:26.682268Z",
          "shell.execute_reply": "2022-08-03T12:57:27.021894Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q06p8Uj8elC3",
        "outputId": "0d65fe7b-9973-4bc3-b116-ff46ae4a55cc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 91\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utility"
      ],
      "metadata": {
        "id": "Ei6ESM-jelC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_essay(essay_id, is_train=True):\n",
        "\n",
        "    # INPUT_DIR = '../input/feedback-prize-effectiveness/'\n",
        "    INPUT_DIR = '/content/drive/MyDrive/Colab Notebooks/Data/'\n",
        "    parent_path = INPUT_DIR + 'train' if is_train else INPUT_DIR + 'test'\n",
        "    \n",
        "    try:\n",
        "        essay_path = os.path.join(parent_path, f\"{essay_id}.txt\")\n",
        "        essay_text = open(essay_path, 'r').read()\n",
        "    except:\n",
        "        parent_path = INPUT_DIR + 'train'\n",
        "        essay_path = os.path.join(parent_path, f\"{essay_id}.txt\")\n",
        "        essay_text = open(essay_path, 'r').read()        \n",
        "    return essay_text\n",
        "\n",
        "# Freeze the hidden layer within the pretrained model\n",
        "def freeze(module):\n",
        "    \"\"\"\n",
        "    Freezes module's parameters.\n",
        "    \"\"\"\n",
        "    \n",
        "    for parameter in module.parameters():\n",
        "        parameter.requires_grad = False\n",
        "        \n",
        "def get_freezed_parameters(module):\n",
        "    \"\"\"\n",
        "    Returns names of freezed parameters of the given module.\n",
        "    \"\"\"\n",
        "    \n",
        "    freezed_parameters = []\n",
        "    for name, parameter in module.named_parameters():\n",
        "        if not parameter.requires_grad:\n",
        "            freezed_parameters.append(name)\n",
        "            \n",
        "    return freezed_parameters\n",
        "\n",
        "# Remove unicode error (https://www.kaggle.com/competitions/feedback-prize-2021/discussion/313330)\n",
        "def replace_encoding_with_utf8(error: UnicodeError) -> Tuple[bytes, int]:\n",
        "    return error.object[error.start : error.end].encode(\"utf-8\"), error.end\n",
        "\n",
        "\n",
        "def replace_decoding_with_cp1252(error: UnicodeError) -> Tuple[str, int]:\n",
        "    return error.object[error.start : error.end].decode(\"cp1252\"), error.end\n",
        "\n",
        "# Register the encoding and decoding error handlers for `utf-8` and `cp1252`.\n",
        "codecs.register_error(\"replace_encoding_with_utf8\", replace_encoding_with_utf8)\n",
        "codecs.register_error(\"replace_decoding_with_cp1252\", replace_decoding_with_cp1252)\n",
        "\n",
        "def resolve_encodings_and_normalize(text: str) -> str:\n",
        "    \"\"\"Resolve the encoding problems and normalize the abnormal characters.\"\"\"\n",
        "    text = (\n",
        "        text.encode(\"raw_unicode_escape\")\n",
        "        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n",
        "        .encode(\"cp1252\", errors=\"replace_encoding_with_utf8\")\n",
        "        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n",
        "    )\n",
        "    text = unidecode(text)\n",
        "    return text"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:27.023955Z",
          "iopub.execute_input": "2022-08-03T12:57:27.024682Z",
          "iopub.status.idle": "2022-08-03T12:57:27.039001Z",
          "shell.execute_reply.started": "2022-08-03T12:57:27.024650Z",
          "shell.execute_reply": "2022-08-03T12:57:27.037735Z"
        },
        "trusted": true,
        "id": "ERcD4UBAelC5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODELLING\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "dtRiSL4aelC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "---\n",
        "\n",
        "Used to convert raw text into tokenized data"
      ],
      "metadata": {
        "id": "x0oYnmlqbYJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class _Dataset(Dataset):\n",
        "    def __init__(self,data_path,test_path, tokenizer,label_encoder,attributes, max_token_len: int = 512, is_train=True,is_test=False, text_method=0):\n",
        "        self.data_path = data_path\n",
        "        self.test_path = test_path\n",
        "        self.tokenizer = tokenizer\n",
        "        self.attributes = attributes\n",
        "        self.max_token_len = max_token_len\n",
        "        self.is_train = is_train\n",
        "        self.is_test = is_test\n",
        "        self.label_encoder = label_encoder\n",
        "        self.text_method = text_method\n",
        "        self._prepare_data()\n",
        "\n",
        "    def _prepare_data(self):\n",
        "\n",
        "\n",
        "\n",
        "        SEP = self.tokenizer.sep_token # different model uses different to text as seperator (e.g. [SEP], </s>)\n",
        "        if self.is_test:\n",
        "#             df = pd.read_csv(self.test_path)\n",
        "            df = self.test_path\n",
        "            try:\n",
        "                df['essay_text']  = df['essay_id'].apply(lambda x: get_essay(x, is_train=False))\n",
        "            except:\n",
        "                print(\"Fail to get essay\")\n",
        "            df['discourse_text'] = df['discourse_text'].apply(resolve_encodings_and_normalize)\n",
        "#             df['discourse_text'] = df['discourse_text'].replace(r'\\n',' ', regex=True)\n",
        "            \n",
        "            try:\n",
        "                if self.text_method == 0:\n",
        "                    df['text'] = df['discourse_text']\n",
        "                elif self.text_method == 1:\n",
        "                    df['text'] = df['discourse_type'] + SEP + df['discourse_text']\n",
        "                elif self.text_method == 2:\n",
        "                    df['text'] = df['discourse_type'] + ' ' + df['discourse_text'] + SEP + df['essay_text'] # BERT was trained on 2 sentences\n",
        "            except:\n",
        "                df['text'] = df['discourse_text']\n",
        "                \n",
        "            try:\n",
        "                # Validation use\n",
        "                df = df.loc[:,['text','labels']]\n",
        "            except:\n",
        "                # Test use\n",
        "                df = df.loc[:,['text']]\n",
        "\n",
        "        else:\n",
        "#             df = pd.read_csv(self.data_path)\n",
        "            df = self.data_path\n",
        "            df = df.sample(1000)\n",
        "            try:\n",
        "                df['essay_text']  = df['essay_id'].apply(lambda x: get_essay(x, is_train=True))\n",
        "            except:\n",
        "                print('Fail to get essay')\n",
        "                \n",
        "            y = df['discourse_effectiveness']\n",
        "\n",
        "            train_df, val_df = train_test_split(df, test_size=0.2,stratify=y,random_state=91)\n",
        "\n",
        "            if self.is_train:\n",
        "                df = train_df.copy()\n",
        "            else:\n",
        "                df = val_df.copy()\n",
        "\n",
        "            df['discourse_text'] = df['discourse_text'].apply(resolve_encodings_and_normalize)\n",
        "#             df['discourse_text'] = df['discourse_text'].replace(r'\\n',' ', regex=True)\n",
        "            try:\n",
        "                if self.text_method == 0:\n",
        "                    df['text'] = df['discourse_text']\n",
        "                elif self.text_method == 1:\n",
        "                    df['text'] = df['discourse_type'] + SEP + df['discourse_text']\n",
        "                elif self.text_method == 2:\n",
        "                    df['text'] = df['discourse_type'] + ' ' + df['discourse_text'] + SEP + df['essay_text'] # BERT was trained on 2 sentences\n",
        "            except:\n",
        "                df['text'] = df['discourse_text']\n",
        "                \n",
        "            df = df.rename(columns={'discourse_effectiveness':'labels'})\n",
        "            df = df.loc[:,['text','labels']]\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        item = self.df.iloc[index]\n",
        "        text = str(item.text)\n",
        "        tokens = self.tokenizer.encode_plus(text,\n",
        "                                  add_special_tokens= True,\n",
        "                                  return_tensors='pt',\n",
        "                                  truncation=True,\n",
        "#                                   padding='max_length',\n",
        "                                  max_length=self.max_token_len,\n",
        "                                  return_attention_mask = True)\n",
        "        if self.is_test:\n",
        "            return {'input_ids':tokens.input_ids.flatten(),'attention_mask': tokens.attention_mask.flatten()}\n",
        "        else:\n",
        "            # # Convert strings to numerics, follow alphabetical order\n",
        "            attributes = item['labels'].split()\n",
        "            self.label_encoder.fit(self.attributes)\n",
        "            attributes = self.label_encoder.transform(attributes)\n",
        "            attributes = torch.as_tensor(attributes)\n",
        "            #         attributes = torch.FloatTensor(item[self.attributes])\n",
        "            return {'input_ids':tokens.input_ids.flatten(),'attention_mask': tokens.attention_mask.flatten(), 'labels':attributes}\n"
      ],
      "metadata": {
        "id": "M553vuuRbYJp",
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:27.040551Z",
          "iopub.execute_input": "2022-08-03T12:57:27.041180Z",
          "iopub.status.idle": "2022-08-03T12:57:27.064525Z",
          "shell.execute_reply.started": "2022-08-03T12:57:27.041137Z",
          "shell.execute_reply": "2022-08-03T12:57:27.063200Z"
        },
        "trusted": true
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collate (Dynamic Padding)\n",
        "\n",
        "---\n",
        "\n",
        "Dynamically pad tokenized text to match the max length of each batch to reduce computational time"
      ],
      "metadata": {
        "id": "XeHIWmVHelC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Collate:\n",
        "    def __init__(self, tokenizer, isTrain=True):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.isTrain = isTrain\n",
        "        # self.args = args\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        output = dict()\n",
        "        output[\"input_ids\"] = [sample[\"input_ids\"] for sample in batch]\n",
        "        output[\"attention_mask\"] = [sample[\"attention_mask\"] for sample in batch]\n",
        "        if self.isTrain:\n",
        "            output[\"labels\"] = [sample[\"labels\"] for sample in batch]\n",
        "\n",
        "        # calculate max token length of this batch\n",
        "        batch_max = max([len(ids) for ids in output[\"input_ids\"]])\n",
        "\n",
        "        # add padding\n",
        "        if self.tokenizer.padding_side == \"right\":\n",
        "            output[\"input_ids\"] = [s.tolist() + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"input_ids\"]]\n",
        "            output[\"attention_mask\"] = [s.tolist() + (batch_max - len(s)) * [0] for s in output[\"attention_mask\"]]\n",
        "\n",
        "#             output[\"input_ids\"] = [torch.cat(s, torch.FloatTensor((batch_max - len(s)) * [0]), 0) for s in output[\"input_ids\"]]\n",
        "#             output[\"attention_mask\"] = [torch.cat(s, torch.FloatTensor((batch_max - len(s)) * [0]), 0) for s in output[\"attention_mask\"]]\n",
        "        else:\n",
        "            output[\"input_ids\"] = [torch.FloatTensor((batch_max - len(s)) * [self.tokenizer.pad_token_id].tolist()) + s.tolist() for s in output[\"input_ids\"]]\n",
        "            output[\"attention_mask\"] = [torch.FloatTensor((batch_max - len(s)) * [0]) + s.tolist() for s in output[\"attention_mask\"]]\n",
        "            \n",
        "        # convert to tensors\n",
        "        output[\"input_ids\"] = torch.tensor(output[\"input_ids\"], dtype=torch.long)\n",
        "        output[\"attention_mask\"] = torch.tensor(output[\"attention_mask\"], dtype=torch.long)\n",
        "        if self.isTrain:\n",
        "            output[\"labels\"] = torch.tensor(output[\"labels\"], dtype=torch.long)\n",
        "        return output\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:27.066218Z",
          "iopub.execute_input": "2022-08-03T12:57:27.066663Z",
          "iopub.status.idle": "2022-08-03T12:57:27.083365Z",
          "shell.execute_reply.started": "2022-08-03T12:57:27.066621Z",
          "shell.execute_reply": "2022-08-03T12:57:27.082286Z"
        },
        "trusted": true,
        "id": "54bAri16elC-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Module\n",
        "\n",
        "---\n",
        "\n",
        "Data preparation by calling dataset and passing it to the dataloader where the data is collated and batched"
      ],
      "metadata": {
        "id": "N3ZT1vpFbYJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class _Data_Module(pl.LightningDataModule):\n",
        "\n",
        "    def __init__(self, data_path, test_path,attributes,label_encoder,tokenizer, model_name, batch_size: int = 8, max_token_length: int = 512,text_method=0 ):\n",
        "        super().__init__()\n",
        "        self.data_path = data_path\n",
        "        self.test_path = test_path\n",
        "        self.attributes = attributes\n",
        "        self.batch_size = batch_size\n",
        "        self.max_token_length = max_token_length\n",
        "        self.model_name = model_name\n",
        "        self.tokenizer = tokenizer #AutoTokenizer.from_pretrained(model_name)\n",
        "        self.label_encoder = label_encoder\n",
        "        self.text_method = text_method\n",
        "\n",
        "    def setup(self, stage = None):\n",
        "        if stage in (None, \"fit\"):\n",
        "            self.train_dataset = _Dataset(self.data_path, self.test_path, label_encoder = self.label_encoder,  attributes=self.attributes, is_train=True, tokenizer=self.tokenizer,text_method=self.text_method)\n",
        "            self.val_dataset = _Dataset(self.data_path, self.test_path, label_encoder = self.label_encoder, attributes=self.attributes, is_train=False,  tokenizer=self.tokenizer,text_method=self.text_method)\n",
        "        if stage == 'predict':\n",
        "            self.test_dataset = _Dataset(self.data_path, self.test_path, label_encoder = self.label_encoder, attributes=self.attributes, is_train=False,is_test=True, tokenizer=self.tokenizer,text_method=self.text_method)\n",
        "\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        collate_fn = Collate(self.tokenizer, \n",
        "                             isTrain=True)\n",
        "\n",
        "        return DataLoader(self.train_dataset, \n",
        "                          batch_size = self.batch_size, \n",
        "                          num_workers=2, \n",
        "                          shuffle=True,\n",
        "                          collate_fn = collate_fn)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        collate_fn = Collate(self.tokenizer, \n",
        "                             isTrain=True)\n",
        "\n",
        "        return DataLoader(self.val_dataset, \n",
        "                          batch_size = self.batch_size, \n",
        "                          num_workers=2, \n",
        "                          shuffle=False,\n",
        "                          collate_fn = collate_fn)\n",
        "\n",
        "    def predict_dataloader(self):\n",
        "        collate_fn = Collate(self.tokenizer, \n",
        "                             isTrain=False)\n",
        "\n",
        "        return DataLoader(self.test_dataset, \n",
        "                          batch_size = self.batch_size, \n",
        "                          num_workers=2, \n",
        "                          shuffle=False,\n",
        "                          collate_fn = collate_fn)\n"
      ],
      "metadata": {
        "id": "_pUquMv6bYJq",
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:27.084542Z",
          "iopub.execute_input": "2022-08-03T12:57:27.085432Z",
          "iopub.status.idle": "2022-08-03T12:57:27.101884Z",
          "shell.execute_reply.started": "2022-08-03T12:57:27.085382Z",
          "shell.execute_reply": "2022-08-03T12:57:27.100789Z"
        },
        "trusted": true
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classifier\n",
        "\n",
        "---\n",
        "\n",
        "4 Types of classifier module were created according to different pretrained model:\n",
        "\n",
        "1. Bert Pruned OFA (https://huggingface.co/Intel/bert-large-uncased-sparse-90-unstructured-pruneofa)\n",
        "2. DistilBert (https://huggingface.co/distilbert-base-uncased)\n",
        "3. Deberta-v3-base (https://huggingface.co/microsoft/deberta-v3-base)\n",
        "4. DistilRoberta (https://huggingface.co/distilroberta-base)\n",
        "\n",
        "The classifier module comprises of 5 components:\n",
        "\n",
        "* Computations (init)\n",
        "* Train Loop (training_step)\n",
        "* Validation Loop (validation_step)\n",
        "* Prediction Loop (predict_step)\n",
        "* Optimizers and LR Schedulers (configure_optimizers)\n"
      ],
      "metadata": {
        "id": "hGuHN2DqbYJq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. BertOFA Classifier"
      ],
      "metadata": {
        "id": "nIK22sWEelDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertOFA_Text_Classifier(pl.LightningModule):\n",
        "    \n",
        "    def __init__(self, config: dict,data_module):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.data_module=data_module\n",
        "        self.pretrained_model = AutoModel.from_pretrained(config['model_name'], return_dict = False)\n",
        "        freeze((self.pretrained_model).embeddings)\n",
        "        freeze((self.pretrained_model).encoder.layer[:config['n_freeze']])\n",
        "        print(get_freezed_parameters(self.pretrained_model))\n",
        "        # Adding an additional hidden layer on top of the pretrained model\n",
        "        self.hidden = torch.nn.Linear(self.pretrained_model.config.hidden_size, self.pretrained_model.config.hidden_size)\n",
        "        \n",
        "        # Adding classifier on top of the pretrained model\n",
        "        self.classifier = torch.nn.Linear(self.pretrained_model.config.hidden_size, self.config['n_labels'])\n",
        "        \n",
        "        # Used to initialize the weight of the newly created classifier layer, not sure whether hidden layer need it or not\n",
        "        torch.nn.init.xavier_uniform_(self.classifier.weight)\n",
        "        \n",
        "        self.loss_func = nn.CrossEntropyLoss() # do not put SoftMax, just use CrossEntropyLoss\n",
        "        \n",
        "        self.dropout = nn.Dropout(config['p_dropout'])\n",
        "\n",
        "    # For inference        \n",
        "    def forward(self, input_ids, attention_mask, labels = None):\n",
        "        outputs = self.pretrained_model(input_ids = input_ids, attention_mask = attention_mask)\n",
        "#         pooled_output = torch.mean(outputs.last_hidden_state, 1) \n",
        "#         pooled_output = self.dropout(pooled_output)\n",
        "#         pooled_output = self.dropout(outputs[1])\n",
        "        pooled_output = self.hidden(outputs[1])\n",
        "        pooled_output = F.relu(pooled_output)\n",
        "        pooled_output = self.hidden(pooled_output)\n",
        "        pooled_output = F.relu(pooled_output)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        # calculate loss\n",
        "        loss = 0\n",
        "        if labels is not None:\n",
        "            loss = self.loss_func(logits,labels)\n",
        "        return loss, logits\n",
        "    \n",
        "    def training_step(self, batch, batch_index):\n",
        "        loss, logits = self(**batch)  # self(**batch) = model(**batch), where **batch = unpack batch\n",
        "        f1 = f1_score(logits.argmax(dim=1),batch['labels'],num_classes=3,multiclass=True)\n",
        "        f1_weighted = f1_score(logits.softmax(dim=1),batch['labels'],num_classes=3,multiclass=True,average='weighted')\n",
        "        wandb.log({\"Training Loss\": loss.item(),'Train F1 Score':f1,'Train F1_weighted Score':f1_weighted})\n",
        "        self.log(\"f1\", f1, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"f1_weighted\", f1_weighted, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"loss \", loss,on_step=False,on_epoch = True, prog_bar = True, logger=True)\n",
        "        return {\"loss\":loss}#, \"predictions\":logits, \"labels\": batch[\"labels\"],\"progress_bar\":pbar}\n",
        "    \n",
        "    def validation_step(self, batch, batch_index):\n",
        "        loss, logits = self(**batch)\n",
        "        f1 = f1_score(logits.argmax(dim=1),batch['labels'],num_classes=3,multiclass=True)\n",
        "        f1_weighted = f1_score(logits.softmax(dim=1),batch['labels'],num_classes=3,multiclass=True,average='weighted')\n",
        "        wandb.log({\"Validation Loss\": loss.item(),'Validation F1 Score':f1,'Validation F1_weighted Score':f1_weighted})\n",
        "        self.log(\"f1\", f1, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"f1_weighted\", f1_weighted, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"val_loss\", loss, on_step=False,on_epoch = True, prog_bar = True, logger=True)\n",
        "        return {\"val_loss\": loss}#, \"predictions\":logits, \"labels\": batch[\"labels\"]}\n",
        "\n",
        "    def predict_step(self, batch, batch_index):\n",
        "        loss, logits = self(**batch)\n",
        "        return logits\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        train_size = len(self.data_module.train_dataloader())\n",
        "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.config['lr'], weight_decay=self.config['weight_decay'])\n",
        "        total_steps = train_size/self.config['batch_size']\n",
        "        warmup_steps = math.floor(total_steps * self.config['warmup'])\n",
        "        scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "        return [optimizer],[scheduler]"
      ],
      "metadata": {
        "id": "P-rc5irkbYJq",
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:27.103360Z",
          "iopub.execute_input": "2022-08-03T12:57:27.104448Z",
          "iopub.status.idle": "2022-08-03T12:57:27.128381Z",
          "shell.execute_reply.started": "2022-08-03T12:57:27.104403Z",
          "shell.execute_reply": "2022-08-03T12:57:27.127152Z"
        },
        "trusted": true
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. DistilBert classifier"
      ],
      "metadata": {
        "id": "3twx77pselDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DistilBert_Text_Classifier(pl.LightningModule):\n",
        "    \n",
        "    def __init__(self, config: dict,data_module):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.data_module=data_module\n",
        "        self.pretrained_model = AutoModel.from_pretrained(config['model_name'], return_dict = True)\n",
        "        freeze((self.pretrained_model).embeddings)\n",
        "        freeze((self.pretrained_model).transformer.layer[:config['n_freeze']])\n",
        "        print(get_freezed_parameters(self.pretrained_model))\n",
        "        # Adding an additional hidden layer on top of the pretrained model\n",
        "        self.hidden = torch.nn.Linear(self.pretrained_model.config.hidden_size,self.pretrained_model.config.hidden_size)\n",
        "#         self.hidden2 = torch.nn.Linear(self.pretrained_model.config.hidden_size,100)\n",
        "\n",
        "#         self.batchnorm = nn.BatchNorm1d(self.pretrained_model.config.hidden_size)\n",
        "        # Adding classifier on top of the pretrained model\n",
        "        self.classifier = torch.nn.Linear(self.pretrained_model.config.hidden_size, self.config['n_labels'])\n",
        "        \n",
        "        # Used to initialize the weight of the newly created classifier layer, not sure whether hidden layer need it or not\n",
        "        torch.nn.init.xavier_uniform_(self.classifier.weight)\n",
        "        \n",
        "        self.loss_func = nn.CrossEntropyLoss() # do not put SoftMax, just use CrossEntropyLoss\n",
        "        \n",
        "        self.dropout = nn.Dropout(config['p_dropout'])\n",
        "\n",
        "    # For inference        \n",
        "    def forward(self, input_ids, attention_mask, labels = None):\n",
        "        output = self.pretrained_model(input_ids = input_ids, attention_mask = attention_mask)\n",
        "        logits = self.classifier(output.last_hidden_state)\n",
        "        pooled_output = torch.mean(output.last_hidden_state, 1) \n",
        "        pooled_output = self.hidden(pooled_output)\n",
        "        pooled_output = F.relu(pooled_output)\n",
        "#         pooled_output = self.batchnorm(pooled_output)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "            \n",
        "        # calculate loss\n",
        "        loss = 0\n",
        "        if labels is not None:\n",
        "            loss = self.loss_func(logits,labels)\n",
        "        return loss, logits\n",
        "    \n",
        "#     def training_step(self, batch, batch_index):\n",
        "#         logits = self(**batch)  # self(**batch) = model(**batch), where **batch = unpack batch\n",
        "# #         print(f\"batch[labels] = {batch['labels']}\")\n",
        "# #         print(f\"{type(batch['labels'])}\")\n",
        "#         class_weights=class_weight.compute_class_weight(class_weight='balanced',classes=np.unique(batch['labels'].tolist()),y=batch['labels'].tolist())\n",
        "#         class_weights=torch.tensor(class_weights,dtype=torch.float)\n",
        "#         loss_func = nn.CrossEntropyLoss(weight=class_weights,reduction='mean').to('cuda:0')\n",
        "#         loss = loss_func(logits,batch['labels']).to('cuda:0')\n",
        "        \n",
        "#         f1 = f1_score(logits.argmax(dim=1),batch['labels'],num_classes=3,multiclass=True)\n",
        "#         f1_weighted = f1_score(logits.softmax(dim=1),batch['labels'],num_classes=3,multiclass=True,average='weighted')\n",
        "#         wandb.log({\"Training Loss\": loss.item(),'Train F1 Score':f1,'Train F1_weighted Score':f1_weighted})\n",
        "#         self.log(\"f1\", f1, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "#         self.log(\"f1_weighted\", f1_weighted, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "#         self.log(\"loss \", loss,on_step=False,on_epoch = True, prog_bar = True, logger=True)\n",
        "#         return {\"loss\":loss}#, \"predictions\":logits, \"labels\": batch[\"labels\"],\"progress_bar\":pbar}\n",
        "    \n",
        "#     def validation_step(self, batch, batch_index):\n",
        "#         logits = self(**batch)\n",
        "# #         print(f\"batch[labels] = {batch['labels']}\")\n",
        "#         class_weights=class_weight.compute_class_weight(class_weight='balanced',classes=np.unique(batch['labels'].tolist()),y=batch['labels'].tolist())\n",
        "#         class_weights=torch.tensor(class_weights,dtype=torch.float)\n",
        "#         loss_func = nn.CrossEntropyLoss(weight=class_weights,reduction='mean').to('cuda:0')\n",
        "#         loss = loss_func(logits,batch['labels']).to('cuda:0')\n",
        "        \n",
        "        \n",
        "#         f1 = f1_score(logits.argmax(dim=1),batch['labels'],num_classes=3,multiclass=True)\n",
        "#         f1_weighted = f1_score(logits.softmax(dim=1),batch['labels'],num_classes=3,multiclass=True,average='weighted')\n",
        "#         wandb.log({\"Validation Loss\": loss.item(),'Validation F1 Score':f1,'Validation F1_weighted Score':f1_weighted})\n",
        "#         self.log(\"f1\", f1, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "#         self.log(\"f1_weighted\", f1_weighted, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "#         self.log(\"val_loss\", loss, on_step=False,on_epoch = True, prog_bar = True, logger=True)\n",
        "#         return {\"val_loss\": loss}#, \"predictions\":logits, \"labels\": batch[\"labels\"]}\n",
        "#     \n",
        "#     def predict_step(self, batch, batch_index):\n",
        "#         logits = self(**batch)\n",
        "#         return logits\n",
        "\n",
        "    def training_step(self, batch, batch_index):\n",
        "        loss, logits = self(**batch)  # self(**batch) = model(**batch), where **batch = unpack batch\n",
        "        f1 = f1_score(logits.argmax(dim=1),batch['labels'],num_classes=3,multiclass=True)\n",
        "        f1_weighted = f1_score(logits.softmax(dim=1),batch['labels'],num_classes=3,multiclass=True,average='weighted')\n",
        "        wandb.log({\"Training Loss\": loss.item(),'Train F1 Score':f1,'Train F1_weighted Score':f1_weighted})\n",
        "        self.log(\"f1\", f1, on_step=True,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"f1_weighted\", f1_weighted, on_step=True,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"loss \", loss,on_step=True,on_epoch = True, prog_bar = True, logger=True)\n",
        "        return {\"loss\":loss}#, \"predictions\":logits, \"labels\": batch[\"labels\"],\"progress_bar\":pbar}\n",
        "    \n",
        "    def validation_step(self, batch, batch_index):\n",
        "        loss, logits = self(**batch)\n",
        "        f1 = f1_score(logits.argmax(dim=1),batch['labels'],num_classes=3,multiclass=True)\n",
        "        f1_weighted = f1_score(logits.softmax(dim=1),batch['labels'],num_classes=3,multiclass=True,average='weighted')\n",
        "        wandb.log({\"Validation Loss\": loss.item(),'Validation F1 Score':f1,'Validation F1_weighted Score':f1_weighted})\n",
        "        self.log(\"f1\", f1, on_step=True,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"f1_weighted\", f1_weighted, on_step=True,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"val_loss\", loss, on_step=True,on_epoch = True, prog_bar = True, logger=True)\n",
        "        return {\"val_loss\": loss}#, \"predictions\":logits, \"labels\": batch[\"labels\"]}\n",
        "\n",
        "    def predict_step(self, batch, batch_index):\n",
        "        loss, logits = self(**batch)\n",
        "        return logits\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        train_size = len(self.data_module.train_dataloader())\n",
        "        print(train_size)\n",
        "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.config['lr'], weight_decay=self.config['weight_decay'])\n",
        "        total_steps = train_size/self.config['batch_size']\n",
        "        warmup_steps = math.floor(total_steps * self.config['warmup'])\n",
        "        scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "        return [optimizer],[scheduler]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:27.130415Z",
          "iopub.execute_input": "2022-08-03T12:57:27.130913Z",
          "iopub.status.idle": "2022-08-03T12:57:27.156423Z",
          "shell.execute_reply.started": "2022-08-03T12:57:27.130869Z",
          "shell.execute_reply": "2022-08-03T12:57:27.155391Z"
        },
        "trusted": true,
        "id": "jBzhFi4ZelDE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Deberta Classifier"
      ],
      "metadata": {
        "id": "4woJkOd5elDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DeBerta_Text_Classifier(pl.LightningModule):\n",
        "    \n",
        "    def __init__(self, config: dict,data_module):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.data_module = data_module\n",
        "        self.pretrained_model = AutoModel.from_pretrained(config['model_name'], return_dict = True)\n",
        "        freeze((self.pretrained_model).embeddings)\n",
        "        freeze((self.pretrained_model).encoder.layer[:config['n_freeze']])\n",
        "        print(get_freezed_parameters(self.pretrained_model))\n",
        "\n",
        "        # Adding an additional hidden layer on top of the pretrained model\n",
        "        self.hidden = torch.nn.Linear(self.pretrained_model.config.hidden_size,self.pretrained_model.config.hidden_size)\n",
        "        \n",
        "        # Adding classifier on top of the pretrained model\n",
        "        self.classifier = torch.nn.Linear(self.pretrained_model.config.hidden_size, self.config['n_labels'])\n",
        "        \n",
        "        # Used to initialize the weight of the newly created classifier layer, not sure whether hidden layer need it or not\n",
        "        torch.nn.init.xavier_uniform_(self.classifier.weight)\n",
        "        \n",
        "        self.loss_func = nn.CrossEntropyLoss() # do not put SoftMax, just use CrossEntropyLoss\n",
        "        \n",
        "        self.dropout = nn.Dropout(config['p_dropout'])\n",
        "\n",
        "    # For inference        \n",
        "    def forward(self, input_ids, attention_mask, labels = None):\n",
        "        # deBERTa layer\n",
        "        output = self.pretrained_model(input_ids = input_ids, attention_mask = attention_mask)\n",
        "\n",
        "        ## instead of only using the first token from the output, we will take the mean of all the tokens in the outputs to learn the representation of the entire sentence\n",
        "        ## pooled_output is the output before going into the final classifier\n",
        "        pooled_output = torch.mean(output.last_hidden_state, 1) \n",
        "        \n",
        "        # final logits\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        pooled_output = self.hidden(pooled_output)\n",
        "        pooled_output = F.relu(pooled_output)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        \n",
        "        # calculate loss\n",
        "        loss = 0\n",
        "        if labels is not None:\n",
        "            loss = self.loss_func(logits,labels)\n",
        "        return loss, logits\n",
        "    \n",
        "    def training_step(self, batch, batch_index):\n",
        "        loss, logits = self(**batch)  # self(**batch) = model(**batch), where **batch = unpack batch\n",
        "        f1 = f1_score(logits.argmax(dim=1),batch['labels'],num_classes=3,multiclass=True)\n",
        "        f1_weighted = f1_score(logits.softmax(dim=1),batch['labels'],num_classes=3,multiclass=True,average='weighted')\n",
        "        wandb.log({\"Training Loss\": loss.item(),'Train F1 Score':f1,'Train F1_weighted Score':f1_weighted})\n",
        "        self.log(\"f1\", f1, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"f1_weighted\", f1_weighted, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"loss \", loss,on_step=False,on_epoch = True, prog_bar = True, logger=True)\n",
        "        return {\"loss\":loss}#, \"predictions\":logits, \"labels\": batch[\"labels\"],\"progress_bar\":pbar}\n",
        "    \n",
        "    def validation_step(self, batch, batch_index):\n",
        "        loss, logits = self(**batch)\n",
        "        f1 = f1_score(logits.argmax(dim=1),batch['labels'],num_classes=3,multiclass=True)\n",
        "        f1_weighted = f1_score(logits.softmax(dim=1),batch['labels'],num_classes=3,multiclass=True,average='weighted')\n",
        "        wandb.log({\"Validation Loss\": loss.item(),'Validation F1 Score':f1,'Validation F1_weighted Score':f1_weighted})\n",
        "        self.log(\"f1\", f1, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"f1_weighted\", f1_weighted, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"val_loss\", loss, on_step=False,on_epoch = True, prog_bar = True, logger=True)\n",
        "        return {\"val_loss\": loss}#, \"predictions\":logits, \"labels\": batch[\"labels\"]}\n",
        "\n",
        "    def predict_step(self, batch, batch_index):\n",
        "        loss, logits = self(**batch)\n",
        "        return logits\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        train_size = len(self.data_module.train_dataloader())\n",
        "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.config['lr'], weight_decay=self.config['weight_decay'])\n",
        "        total_steps = train_size/self.config['batch_size']\n",
        "        warmup_steps = math.floor(total_steps * self.config['warmup'])\n",
        "        scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "        return [optimizer],[scheduler]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:27.158016Z",
          "iopub.execute_input": "2022-08-03T12:57:27.158594Z",
          "iopub.status.idle": "2022-08-03T12:57:27.180937Z",
          "shell.execute_reply.started": "2022-08-03T12:57:27.158551Z",
          "shell.execute_reply": "2022-08-03T12:57:27.179612Z"
        },
        "trusted": true,
        "id": "hp9uHKTLelDF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. DistilRoBerta Classifer"
      ],
      "metadata": {
        "id": "BxpZgKfjelDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DistilRoBerta_Text_Classifier(pl.LightningModule):\n",
        "    \n",
        "    def __init__(self, config: dict,data_module):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.data_module=data_module\n",
        "        self.pretrained_model = AutoModel.from_pretrained(config['model_name'], return_dict = True)\n",
        "        freeze((self.pretrained_model).embeddings)\n",
        "        freeze((self.pretrained_model).encoder.layer[:config['n_freeze']]) # 5 layer\n",
        "        print(get_freezed_parameters(self.pretrained_model))\n",
        "        # Adding an additional hidden layer on top of the pretrained model\n",
        "        self.hidden = torch.nn.Linear(self.pretrained_model.config.hidden_size,self.pretrained_model.config.hidden_size)\n",
        "        \n",
        "        # Adding classifier on top of the pretrained model\n",
        "        self.classifier = torch.nn.Linear(self.pretrained_model.config.hidden_size, self.config['n_labels'])\n",
        "        \n",
        "        # Used to initialize the weight of the newly created classifier layer, not sure whether hidden layer need it or not\n",
        "        torch.nn.init.xavier_uniform_(self.classifier.weight)\n",
        "        \n",
        "        self.loss_func = nn.CrossEntropyLoss() # do not put SoftMax, just use CrossEntropyLoss\n",
        "        \n",
        "        self.dropout = nn.Dropout(config['p_dropout'])\n",
        "\n",
        "    # For inference        \n",
        "    def forward(self, input_ids, attention_mask, labels = None):\n",
        "        output = self.pretrained_model(input_ids = input_ids, attention_mask = attention_mask)\n",
        "        pooled_output = torch.mean(output.last_hidden_state, 1)\n",
        "        logits = self.classifier(pooled_output)        \n",
        "#         pooled_output = self.hidden(pooled_output)\n",
        "#         pooled_output = F.relu(pooled_output)\n",
        "#         pooled_output = self.dropout(pooled_output)\n",
        "        \n",
        "        # calculate loss\n",
        "        loss = 0\n",
        "        if labels is not None:\n",
        "            loss = self.loss_func(logits,labels)\n",
        "        return loss, logits\n",
        "    \n",
        "    def training_step(self, batch, batch_index):\n",
        "        loss, logits = self(**batch)  # self(**batch) = model(**batch), where **batch = unpack batch\n",
        "        f1 = f1_score(logits.argmax(dim=1),batch['labels'],num_classes=3,multiclass=True)\n",
        "        f1_weighted = f1_score(logits.softmax(dim=1),batch['labels'],num_classes=3,multiclass=True,average='weighted')\n",
        "        wandb.log({\"Training Loss\": loss.item(),'Train F1 Score':f1,'Train F1_weighted Score':f1_weighted})\n",
        "        self.log(\"f1\", f1, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"f1_weighted\", f1_weighted, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"loss \", loss,on_step=False,on_epoch = True, prog_bar = True, logger=True)\n",
        "        return {\"loss\":loss}#, \"predictions\":logits, \"labels\": batch[\"labels\"],\"progress_bar\":pbar}\n",
        "    \n",
        "    def validation_step(self, batch, batch_index):\n",
        "        loss, logits = self(**batch)\n",
        "        f1 = f1_score(logits.argmax(dim=1),batch['labels'],num_classes=3,multiclass=True)\n",
        "        f1_weighted = f1_score(logits.softmax(dim=1),batch['labels'],num_classes=3,multiclass=True,average='weighted')\n",
        "        wandb.log({\"Validation Loss\": loss.item(),'Validation F1 Score':f1,'Validation F1_weighted Score':f1_weighted})\n",
        "        self.log(\"f1\", f1, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"f1_weighted\", f1_weighted, on_step=False,on_epoch=True, prog_bar = True, logger=True)\n",
        "        self.log(\"val_loss\", loss, on_step=False,on_epoch = True, prog_bar = True, logger=True)\n",
        "        return {\"val_loss\": loss}#, \"predictions\":logits, \"labels\": batch[\"labels\"]}\n",
        "\n",
        "    def predict_step(self, batch, batch_index):\n",
        "        loss, logits = self(**batch)\n",
        "        return logits\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        train_size = len(self.data_module.train_dataloader())\n",
        "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.config['lr'], weight_decay=self.config['weight_decay'])\n",
        "        total_steps = train_size/self.config['batch_size']\n",
        "        warmup_steps = math.floor(total_steps * self.config['warmup'])\n",
        "        scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "        return [optimizer],[scheduler]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:27.182834Z",
          "iopub.execute_input": "2022-08-03T12:57:27.183504Z",
          "iopub.status.idle": "2022-08-03T12:57:27.205089Z",
          "shell.execute_reply.started": "2022-08-03T12:57:27.183470Z",
          "shell.execute_reply": "2022-08-03T12:57:27.204019Z"
        },
        "trusted": true,
        "id": "7gsllx54elDG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# config={'name': 'distilbert',\n",
        "#                 'model_name':'distilbert-base-uncased',\n",
        "#                 'PATH':'/content/drive/MyDrive/Colab Notebooks/FineTuneModel/distilbert-frozenembedding&2transformlayer-5epoch-lr6e5-drop02.pth',\n",
        "#                 # 'PATH' : 'kitkeat/distilbert-based-uncased-argumentativewriting/distilbert-frozenembedding&2transformlayer-5epoch-lr6e5-drop02.pth',\n",
        "#                 # 'model_name': '../input/transformers-pretrained-distilbert/distilbert-base-uncased-distilled-squad',\n",
        "#                 # 'PATH' : '../input/distilberttuned/distilbert-frozenembedding2transformlayer-5epoch-lr6e5-drop02.pth',\n",
        "#                 'n_labels': 3,\n",
        "#                 'batch_size': 64,\n",
        "#                 'lr': 8e-4,#6e-5,\n",
        "#                 'warmup': 0.2, \n",
        "#                 'weight_decay': 0.001,\n",
        "#                 'n_epochs': 5,#4,\n",
        "#                 'n_freeze' : 3,\n",
        "#                 'p_dropout':0.6,#0.2,#0.6,\n",
        "#                 'text_method': 1\n",
        "#                 }\n",
        "\n",
        "# df = data_path.copy()\n",
        "# y = df['discourse_effectiveness']\n",
        "# train_df,val_df = train_test_split(df, test_size=0.2,stratify=y,random_state=91)\n",
        "# val_path = val_df\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(config['model_name'], use_fast=True)\n",
        "# le = LabelEncoder()\n",
        "\n",
        "# val_data_module = _Data_Module(data_path,\n",
        "#                                 val_path, # using \n",
        "#                                 attributes,\n",
        "#                                 le,\n",
        "#                                 tokenizer,\n",
        "#                                 config['model_name'],\n",
        "#                                 batch_size=config['batch_size'],\n",
        "#                                 text_method = config['text_method']\n",
        "#                                 )\n",
        "# val_data_module.setup()\n",
        "\n",
        "# # Initialize Model\n",
        "# # model = DistilBert_Text_Classifier(config,val_data_module)\n",
        "# # model.load_state_dict(torch.load(config['PATH']))\n"
      ],
      "metadata": {
        "id": "JWbhVT7a5Gbu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# deberta_config={'name':'deberta',\n",
        "#                 'model_name': 'microsoft/deberta-v3-base',\n",
        "#                 'PATH': '/content/drive/MyDrive/Colab Notebooks/FineTuneModel/deberta_E3Size16Lr3e-05Warm0.01Weight0.01Freeze2Drop0.1Text0.pth',\n",
        "#                 # 'model_name': '../input/deberta-v3-base/deberta-v3-base',\n",
        "#                 # 'PATH' : '../input/debertav3basefinetuned3172022/deberta_E3Size16Lr3e-05Warm0.01Weight0.01Freeze2Drop0.1Text0.pth',\n",
        "#                 'n_labels': 3,\n",
        "#                 'batch_size': 16,\n",
        "#                 'lr': 3e-5,\n",
        "#                 'warmup': 0.01, \n",
        "#                 'weight_decay': 0.01,\n",
        "#                 'n_epochs': 4,\n",
        "#                 'n_freeze' : 2,#9,\n",
        "#                 'p_dropout':0.65,\n",
        "#                 'text_method': 2\n",
        "#                 }\n",
        "\n",
        "# bertofa_config={'name':'bertofa',\n",
        "#                 'model_name':'Intel/bert-large-uncased-sparse-90-unstructured-pruneofa',\n",
        "#                 'PATH' : '/content/drive/MyDrive/Colab Notebooks/FineTuneModel/Bert_OFA_E3Size64Lr0.0001Warm02Weight1e-06Freeze21Drop001_full.pth',\n",
        "#                 # 'model_name': '../input/bertlargeuncasedsparse90unstructuredpruned/bert-large-uncased-sparse-90-unstructured-pruneofa',\n",
        "#                 # 'PATH' : '../input/bert-ofa-pretuned3072022/Bert_OFA_E3Size64Lr0.0001Warm02Weight1e-06Freeze21Drop001_full.pth',\n",
        "#                 'n_labels': 3,\n",
        "#                 'batch_size': 64,\n",
        "#                 'lr': 1e-4,\n",
        "#                 'warmup': 0.2, \n",
        "#                 'weight_decay': 1e-6,\n",
        "#                 'n_epochs': 3,\n",
        "#                 'n_freeze' : 21,\n",
        "#                 'p_dropout':0.1,\n",
        "#                 'text_method': 2\n",
        "#                 }\n",
        "# model_db = AutoModel.from_pretrained(deberta_config['model_name'],state_dict=deberta_config['PATH'])\n",
        "# model_db.save_pretrained(f\"/content/drive/MyDrive/Colab Notebooks/FineTuneModel/{deberta_config['name']}_{timestr}\")\n",
        "\n",
        "# model_b = AutoModel.from_pretrained(bertofa_config['model_name'],state_dict=bertofa_config['PATH'])\n",
        "# model_b.save_pretrained(f\"/content/drive/MyDrive/Colab Notebooks/FineTuneModel/{bertofa_config['name']}_{timestr}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "106d82b288ff4f6fa4213623f1fb3908",
            "37ba5bb6440e422f9f9f29c6089f5e99",
            "36f50cf8f400400aab50a21a261bbfe1",
            "77893e3c601a4c7d99048ffa554bfc86",
            "441f471ebc904df0bbc29206f0de32d4",
            "8c6de79c7cff48c4871a8c7fc19f8006",
            "94b316ec50524588ac39dd45bc1945de",
            "fe7b3c31c943408ba7c8f54dabdc68bd",
            "009db0817af449ae8e42c4f71549e7b0",
            "679e7c93e2b04648aac364b89320ae9e",
            "5f5e7b44f1204f0996b030f91d50117d",
            "88fddf9864fd49bf82c64f0abfbe92f5",
            "51826e4285a94b2d9ef6076edf49113f",
            "4759b17f00e545ed8e4f8f4bc2d0785c",
            "30dd49097e934ba49bc10d4c4fe2695f",
            "c331d60bd4f44ef089d9d6506e7f02c6",
            "7e08fb56f80a4bf19b129130debd5b68",
            "e6375386b2324eb5b4193ffcce63f74a",
            "8349088604e443b3b4be10b229aabdcc",
            "8d4894e5cf8246f79ec6b85fd36cd874",
            "f1775707efd04eb6bbfeb4d5ee1c9cce",
            "e98b4a5bb1e44925939a147c8be955b0",
            "8bc0a0bd1bad41058db2248134e55560",
            "5b16a4ead8164d1b931ac946717b8b80",
            "97ad4c53916f4d5e92e97de506443719",
            "e7798f0a99864ff4836b04d11ee1d2e0",
            "506fbd65151b48b2a51cfb35ca8a6ed3",
            "5b81839b90bb474eaa8a9bf61f68f71d",
            "2fc680a3a14646ad8c17d2ab7a8b2c4c",
            "266762c9f79547c7b0a69dc20d9ec12f",
            "3bbd7fb43a7b4e2f8c55d525c704373a",
            "cdfe2e4f110b439e8d72b97b2f80e592",
            "8f329f935a6747a79601fed8484b38c4",
            "98f4757bf6ae40c38007495c41bf8285",
            "25b3a9a3e32d4c73abccaac9f51ebb54",
            "5db510e600c849fea36340f4088df75a",
            "9f41598f98164e41a7bb160e4c84eeaa",
            "eb599e4df9234c8ebd77e080e69070b0",
            "afd2eddc109f4b33912d0dce2a8ad79b",
            "dc848060e80f4beb990ecf6b09223ab8",
            "a0af99a9e70b45c9ad1c773836ce6ecf",
            "8833c6e9a46046d2915400a9feab9c06",
            "bae8ed778823410e9b4ea20f7609ed34",
            "06e4044212eb4cc6ac23cf00dc3c3f5e"
          ]
        },
        "id": "fAXMtqBiB-jI",
        "outputId": "07255f5f-5dab-4e08-baca-0409982d5691"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/579 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "106d82b288ff4f6fa4213623f1fb3908"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/354M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88fddf9864fd49bf82c64f0abfbe92f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/657 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8bc0a0bd1bad41058db2248134e55560"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.25G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98f4757bf6ae40c38007495c41bf8285"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at Intel/bert-large-uncased-sparse-90-unstructured-pruneofa were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAINING\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "rGzFc2J_elDH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to execute training"
      ],
      "metadata": {
        "id": "vVg3xt2DelDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(config,Text_Classifier,project,samplesize, notes,text_method=0):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(config['model_name'], use_fast=True)\n",
        "    le = LabelEncoder()\n",
        "    \n",
        "    data_module = _Data_Module(data_path,\n",
        "                                    test_path,\n",
        "                                    attributes,\n",
        "                                    le,\n",
        "                                    tokenizer,\n",
        "                                    config['model_name'],\n",
        "                                    batch_size=config['batch_size'],\n",
        "                                    text_method=text_method\n",
        "                                   )\n",
        "    data_module.setup()\n",
        "    \n",
        "    # model\n",
        "    model = Text_Classifier(config,data_module)\n",
        "\n",
        "    # trainer and fit\n",
        "    trainer = pl.Trainer(max_epochs=config['n_epochs'],\n",
        "                         accelerator='auto',\n",
        "                         callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\",patience = 3),TQDMProgressBar(refresh_rate=30)],\n",
        "                         default_root_dir=\"./checkpoints\",\n",
        "                         precision = 16,\n",
        "                        ) # automatic mixed precision to reduce memory\n",
        "\n",
        "    # Create a W&B Run\n",
        "    run = wandb.init(name = f\"E{config['n_epochs']}Size{config['batch_size']}Lr{config['lr']}Warm{config['warmup']}Weight{config['weight_decay']}Freeze{config['n_freeze']}Drop{config['p_dropout']}Text{config['text_method']}\" + samplesize,\n",
        "                     notes = str(config) + notes,\n",
        "                     project=project)\n",
        "    trainer.fit(model, data_module)\n",
        "    \n",
        "    run.finish()\n",
        "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    tuned_model_path = f\"/content/drive/MyDrive/Colab Notebooks/FineTuneModel/{config['name']}_E{config['n_epochs']}Size{config['batch_size']}Lr{config['lr']}Warm{config['warmup']}Weight{config['weight_decay']}Freeze{config['n_freeze']}Drop{config['p_dropout']}Text{config['text_method']}_{timestr}.pth\"\n",
        "    config['newly_tuned_model_path'] = tuned_model_path\n",
        "    torch.save(model.state_dict(), tuned_model_path)\n",
        "\n",
        "    # Convert model to huggingface compatible model\n",
        "    model_hf = AutoModel.from_pretrained(config['model_name'],state_dict=config['newly_tuned_model_path'])\n",
        "    model_hf.save_pretrained(f\"/content/drive/MyDrive/Colab Notebooks/FineTuneModel/{config['name']}-{config['newly_tuned_model_path']}_{timestr}\")\n",
        "    return model,config\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:27.206683Z",
          "iopub.execute_input": "2022-08-03T12:57:27.207075Z",
          "iopub.status.idle": "2022-08-03T12:57:27.222224Z",
          "shell.execute_reply.started": "2022-08-03T12:57:27.207043Z",
          "shell.execute_reply": "2022-08-03T12:57:27.221027Z"
        },
        "trusted": true,
        "id": "ypMDoU4telDI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bertofa_model,bertofa_config = train(config = bertofa_config,\n",
        "                      Text_Classifier = BertOFA_Text_Classifier,\n",
        "                      project = 'BertOFA_Text_Classifier',\n",
        "                      samplesize = ' Full',\n",
        "                      notes = \n",
        "                      \"\"\"\n",
        "                        outputs = self.pretrained_model(input_ids = input_ids, attention_mask = attention_mask), \n",
        "                        pooled_output = self.hidden(outputs[1]), \n",
        "                        pooled_output = F.relu(pooled_output), \n",
        "                        pooled_output = self.hidden(pooled_output), \n",
        "                        pooled_output = F.relu(pooled_output), \n",
        "                        pooled_output = self.dropout(pooled_output), \n",
        "                        logits = self.classifier(pooled_output)\n",
        "                        \"\"\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:27.223897Z",
          "iopub.execute_input": "2022-08-03T12:57:27.225417Z",
          "iopub.status.idle": "2022-08-03T12:57:27.238695Z",
          "shell.execute_reply.started": "2022-08-03T12:57:27.225381Z",
          "shell.execute_reply": "2022-08-03T12:57:27.237365Z"
        },
        "trusted": true,
        "id": "BZ-jUWwaelDI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distilroberta_model,distilroberta_config = train(config = distilroberta_config,\n",
        "                      Text_Classifier = DistilRoBerta_Text_Classifier,\n",
        "                      project = 'DistilRoBerta_Text_Classifier',\n",
        "                      samplesize = ' Full',\n",
        "                      notes = \n",
        "\"\"\"\n",
        "output = self.pretrained_model(input_ids = input_ids, attention_mask = attention_mask),\n",
        "pooled_output = torch.mean(output.last_hidden_state, 1), \n",
        "logits = self.classifier(pooled_output)  \n",
        "\"\"\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:27.240917Z",
          "iopub.execute_input": "2022-08-03T12:57:27.241291Z",
          "iopub.status.idle": "2022-08-03T12:57:27.255443Z",
          "shell.execute_reply.started": "2022-08-03T12:57:27.241257Z",
          "shell.execute_reply": "2022-08-03T12:57:27.254440Z"
        },
        "trusted": true,
        "id": "xll7iVjlelDJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distilbert_model, distilbert_config  = train(config = distilbert_config,\n",
        "                                      Text_Classifier = DistilBert_Text_Classifier,\n",
        "                                      project = 'DistilBert_Text_Classifier',\n",
        "                                      samplesize = ' Full',\n",
        "                                      notes = \n",
        "\"\"\"\n",
        "output = self.pretrained_model(input_ids = input_ids, attention_mask = attention_mask),\n",
        "pooled_output = torch.mean(output.last_hidden_state, 1),\n",
        "logits = self.classifier(pooled_output)\n",
        "\"\"\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:27.257074Z",
          "iopub.execute_input": "2022-08-03T12:57:27.257409Z",
          "iopub.status.idle": "2022-08-03T12:57:27.266813Z",
          "shell.execute_reply.started": "2022-08-03T12:57:27.257380Z",
          "shell.execute_reply": "2022-08-03T12:57:27.265333Z"
        },
        "trusted": true,
        "id": "EidUj0OhelDJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# deberta_model,deberta_config = train(config = deberta_config,\n",
        "#                       Text_Classifier = DeBerta_Text_Classifier,\n",
        "#                       project = 'DeBerta_Text_Classifier',\n",
        "#                       samplesize = ' full',\n",
        "#                       notes = \n",
        "# \"\"\"\n",
        "# pooled_output = self.dropout(pooled_output), \n",
        "# pooled_output = self.hidden(pooled_output), \n",
        "# pooled_output = F.relu(pooled_output), \n",
        "# pooled_output = self.dropout(pooled_output), \n",
        "# logits = self.classifier(pooled_output)\n",
        "# \"\"\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:27.268409Z",
          "iopub.execute_input": "2022-08-03T12:57:27.269372Z",
          "iopub.status.idle": "2022-08-03T12:57:27.277731Z",
          "shell.execute_reply.started": "2022-08-03T12:57:27.269323Z",
          "shell.execute_reply": "2022-08-03T12:57:27.276861Z"
        },
        "trusted": true,
        "id": "eRvSNLTRelDK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VALIDATION\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "ctnhXvjWelDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(_Text_Classifier,config,data_path,val_path,attributes):\n",
        "    # Important step, will run the tuned model instead!\n",
        "    config['model_name'] = config['existing_tuned_model_name']\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(config['model_name'], use_fast=True)\n",
        "    le = LabelEncoder()\n",
        "    \n",
        "    val_data_module = _Data_Module(data_path,\n",
        "                                    val_path, # using \n",
        "                                    attributes,\n",
        "                                    le,\n",
        "                                    tokenizer,\n",
        "                                    config['model_name'],\n",
        "                                    batch_size=config['batch_size'],\n",
        "                                    text_method = config['text_method']\n",
        "                                   )\n",
        "    val_data_module.setup()\n",
        "\n",
        "    # Initialize Model\n",
        "    model = _Text_Classifier(config,val_data_module)\n",
        "    # model.load_state_dict(torch.load(config['PATH']))\n",
        "\n",
        "    # Initialize Trainer\n",
        "    trainer = pl.Trainer(accelerator='auto')\n",
        "\n",
        "    run = wandb.init(name = f\"Validation\",notes = str(config),project= 'Validation')\n",
        "    \n",
        "    logits = trainer.predict(model, datamodule=val_data_module)\n",
        "\n",
        "    run.finish()\n",
        "    \n",
        "    pred_list = []\n",
        "    for logit in logits:\n",
        "        pred_list.append(logit)\n",
        "    y_pred = torch.cat(pred_list)\n",
        "\n",
        "    argmax_output = y_pred.argmax(dim=1)\n",
        "    argmax_output = argmax_output.numpy()\n",
        "    \n",
        "    val_df = val_path.copy()\n",
        "    output_df = pd.concat([val_df.reset_index(drop=True), pd.DataFrame(argmax_output,columns=['pred_discourse_effectiveness'])], axis=1)\n",
        "    output_df['pred_discourse_effectiveness'] = output_df['pred_discourse_effectiveness'].map({0:'Adequate',1:'Effective',2:'Ineffective'})\n",
        "\n",
        "    return output_df,y_pred"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:27.279483Z",
          "iopub.execute_input": "2022-08-03T12:57:27.280592Z",
          "iopub.status.idle": "2022-08-03T12:57:27.295926Z",
          "shell.execute_reply.started": "2022-08-03T12:57:27.280545Z",
          "shell.execute_reply": "2022-08-03T12:57:27.295073Z"
        },
        "trusted": true,
        "id": "_DUx3xQTelDL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieve Validation Data set from train test split"
      ],
      "metadata": {
        "id": "_YYD1qIPelDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attributes = [\"Adequate\" ,\"Effective\",\"Ineffective\"]\n",
        "\n",
        "# Create validation csv file from traintestsplit\n",
        "df = data_path.copy()\n",
        "y = df['discourse_effectiveness']\n",
        "train_df,val_df = train_test_split(df, test_size=0.2,stratify=y,random_state=91)\n",
        "y = val_df['discourse_effectiveness']\n",
        "train_df,val_df = train_test_split(val_df, test_size=0.01,stratify=y,random_state=91)\n",
        "val_path = val_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:27.297722Z",
          "iopub.execute_input": "2022-08-03T12:57:27.298534Z",
          "iopub.status.idle": "2022-08-03T12:57:27.368927Z",
          "shell.execute_reply.started": "2022-08-03T12:57:27.298490Z",
          "shell.execute_reply": "2022-08-03T12:57:27.367973Z"
        },
        "trusted": true,
        "id": "LstX65gSelDM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_df['discourse_effectiveness'].value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:27.370491Z",
          "iopub.execute_input": "2022-08-03T12:57:27.371137Z",
          "iopub.status.idle": "2022-08-03T12:57:27.385254Z",
          "shell.execute_reply.started": "2022-08-03T12:57:27.371091Z",
          "shell.execute_reply": "2022-08-03T12:57:27.383834Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZNFxWX_elDM",
        "outputId": "0eb97659-50e7-456c-9961-b0da351277ba"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Adequate       42\n",
              "Effective      19\n",
              "Ineffective    13\n",
              "Name: discourse_effectiveness, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execute Validation"
      ],
      "metadata": {
        "id": "xlQTm51eelDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_output_df_distilbert, y_pred_distilbert = validate(DistilBert_Text_Classifier,\n",
        "                                                      distilbert_config,\n",
        "                                                      data_path,\n",
        "                                                      val_path,\n",
        "                                                      attributes)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:27.391023Z",
          "iopub.execute_input": "2022-08-03T12:57:27.391565Z",
          "iopub.status.idle": "2022-08-03T12:57:27.396181Z",
          "shell.execute_reply.started": "2022-08-03T12:57:27.391533Z",
          "shell.execute_reply": "2022-08-03T12:57:27.395073Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448,
          "referenced_widgets": [
            "50b78c46abcd4002886493bff2cf0463",
            "6e02e322aeb245598e7ffd0aa07dc644",
            "9502e05784ee41eca2df5b5dc7ee5c29",
            "62280ad770d641b7a35c9015e703159e",
            "6b2473debb544c4c9d81cbc79a793dc8",
            "9d05d301f8ee4d48aff0a1009b42a871",
            "026903422bfc435cb7672c21548d6690",
            "be3307f447774feba3b42f18e9cca272",
            "05876b7e299845a083c5272aba198e38",
            "f1fe78d2235c4abb9c0171ff89dea171",
            "12f077eefc234438913806b7fd636b5f",
            "cead9ce1ed374ddfacaef322e6618293",
            "3a0ce15c506d4e2db87101af59fd31b9",
            "5900203915cd4c79aee31a614bcae0d3",
            "ba76d1e07a0c4c7d85553582e30e68f1",
            "1115a0b8363d4b79b12993e32d5fd4a0",
            "b7877c34d95b44e38caee0473d7fe846",
            "2adeba72070d483694581941f2c4829b",
            "efe8de5719e446f58e899261b86826cf",
            "20b4a80bd25f45b58a55d98a3aa08b10",
            "2f6081cd5e6b47619aba8f5a47f82151",
            "66cb02fd0bff494695bb179438a41879",
            "f07fc0492e804a4a8e7d544262683762",
            "2555f4b319b74cd48c33e77df16c2b74",
            "e163904e7ba943409f5c6dec62361987",
            "0b650a25b5b044f780a784401d68df8e",
            "da519896ea914bf3a02897659942301e",
            "b401e4d6184e425b847ce6f105719b18",
            "36a20af1970248888d27e1b063a119ce",
            "ff26b1344587414f8fd825675b990b70"
          ]
        },
        "id": "sShqN8sgelDN",
        "outputId": "4ce79389-0881-464b-96b3-31909829f3eb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50b78c46abcd4002886493bff2cf0463"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py:95: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
            "  category=PossibleUserWarning,\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['embeddings.word_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'transformer.layer.0.attention.q_lin.weight', 'transformer.layer.0.attention.q_lin.bias', 'transformer.layer.0.attention.k_lin.weight', 'transformer.layer.0.attention.k_lin.bias', 'transformer.layer.0.attention.v_lin.weight', 'transformer.layer.0.attention.v_lin.bias', 'transformer.layer.0.attention.out_lin.weight', 'transformer.layer.0.attention.out_lin.bias', 'transformer.layer.0.sa_layer_norm.weight', 'transformer.layer.0.sa_layer_norm.bias', 'transformer.layer.0.ffn.lin1.weight', 'transformer.layer.0.ffn.lin1.bias', 'transformer.layer.0.ffn.lin2.weight', 'transformer.layer.0.ffn.lin2.bias', 'transformer.layer.0.output_layer_norm.weight', 'transformer.layer.0.output_layer_norm.bias', 'transformer.layer.1.attention.q_lin.weight', 'transformer.layer.1.attention.q_lin.bias', 'transformer.layer.1.attention.k_lin.weight', 'transformer.layer.1.attention.k_lin.bias', 'transformer.layer.1.attention.v_lin.weight', 'transformer.layer.1.attention.v_lin.bias', 'transformer.layer.1.attention.out_lin.weight', 'transformer.layer.1.attention.out_lin.bias', 'transformer.layer.1.sa_layer_norm.weight', 'transformer.layer.1.sa_layer_norm.bias', 'transformer.layer.1.ffn.lin1.weight', 'transformer.layer.1.ffn.lin1.bias', 'transformer.layer.1.ffn.lin2.weight', 'transformer.layer.1.ffn.lin2.bias', 'transformer.layer.1.output_layer_norm.weight', 'transformer.layer.1.output_layer_norm.bias', 'transformer.layer.2.attention.q_lin.weight', 'transformer.layer.2.attention.q_lin.bias', 'transformer.layer.2.attention.k_lin.weight', 'transformer.layer.2.attention.k_lin.bias', 'transformer.layer.2.attention.v_lin.weight', 'transformer.layer.2.attention.v_lin.bias', 'transformer.layer.2.attention.out_lin.weight', 'transformer.layer.2.attention.out_lin.bias', 'transformer.layer.2.sa_layer_norm.weight', 'transformer.layer.2.sa_layer_norm.bias', 'transformer.layer.2.ffn.lin1.weight', 'transformer.layer.2.ffn.lin1.bias', 'transformer.layer.2.ffn.lin2.weight', 'transformer.layer.2.ffn.lin2.bias', 'transformer.layer.2.output_layer_norm.weight', 'transformer.layer.2.output_layer_norm.bias']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkitkeat\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "wandb version 0.13.0 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.21"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220804_052905-l0sh64an</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/kitkeat/Validation/runs/l0sh64an\" target=\"_blank\">Validation</a></strong> to <a href=\"https://wandb.ai/kitkeat/Validation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Missing logger folder: /content/lightning_logs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predicting: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cead9ce1ed374ddfacaef322e6618293"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f07fc0492e804a4a8e7d544262683762"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">Validation</strong>: <a href=\"https://wandb.ai/kitkeat/Validation/runs/l0sh64an\" target=\"_blank\">https://wandb.ai/kitkeat/Validation/runs/l0sh64an</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220804_052905-l0sh64an/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_output_df_deberta,y_pred_deberta = validate(DeBerta_Text_Classifier,\n",
        "                                                  deberta_config,\n",
        "                                                  data_path,\n",
        "                                                  val_path,\n",
        "                                                  attributes)\n",
        "\n"
      ],
      "metadata": {
        "id": "yWb8IB862_WY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_output_df_bertofa, y_pred_bertofa = validate(BertOFA_Text_Classifier,\n",
        "                                                  bertofa_config,\n",
        "                                                  data_path,\n",
        "                                                  val_path,\n",
        "                                                  attributes)"
      ],
      "metadata": {
        "id": "xVjSKQSz2_LY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## val_output_df_distilroberta, y_pred_distilroberta = validate(DistilRoBerta_Text_Classifier,\n",
        "##                                                               distilroberta_config,\n",
        "##                                                               data_path,\n",
        "##                                                               val_path,\n",
        "##                                                               attributes)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:27.397915Z",
          "iopub.execute_input": "2022-08-03T12:57:27.398454Z",
          "iopub.status.idle": "2022-08-03T12:57:27.409554Z",
          "shell.execute_reply.started": "2022-08-03T12:57:27.398422Z",
          "shell.execute_reply": "2022-08-03T12:57:27.408631Z"
        },
        "trusted": true,
        "id": "Y9EmM_nmelDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Validation Results"
      ],
      "metadata": {
        "id": "u5Ak-LYoelDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_distilbert = pd.concat([val_output_df_distilbert.reset_index(drop=True),pd.DataFrame(y_pred_distilbert.tolist(),columns=attributes)],axis=1)\n",
        "df_deberta = pd.concat([val_output_df_deberta.reset_index(drop=True),pd.DataFrame(y_pred_deberta.tolist(),columns=attributes)],axis=1)\n",
        "df_bertofa = pd.concat([val_output_df_bertofa.reset_index(drop=True),pd.DataFrame(y_pred_bertofa.tolist(),columns=attributes)],axis=1)\n",
        "\n",
        "df_distilbert.to_csv(f'/content/drive/MyDrive/Colab Notebooks/FineTuneModel/ValidationResult/distilbert_valresult_{timestr}.csv',index=False)\n",
        "df_deberta.to_csv(f'/content/drive/MyDrive/Colab Notebooks/FineTuneModel/ValidationResult/deberta_valresult_{timestr}.csv',index=False)\n",
        "df_bertofa.to_csv(f'/content/drive/MyDrive/Colab Notebooks/FineTuneModel/ValidationResult/bertofa_valresult_{timestr}.csv',index=False)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:27.411084Z",
          "iopub.execute_input": "2022-08-03T12:57:27.411822Z",
          "iopub.status.idle": "2022-08-03T12:57:27.426028Z",
          "shell.execute_reply.started": "2022-08-03T12:57:27.411774Z",
          "shell.execute_reply": "2022-08-03T12:57:27.424652Z"
        },
        "trusted": true,
        "id": "YhrlPD_SelDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explore Validation Results"
      ],
      "metadata": {
        "id": "GkdonVfoelDP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read data from saved Validation results"
      ],
      "metadata": {
        "id": "XPxf3uVuelDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_distilbert=pd.read_csv('../input/validation-result/distilbert_valresult.csv')\n",
        "# df_deberta=pd.read_csv('../input/validation-result/deberta_valresult.csv')\n",
        "# df_bertofa=pd.read_csv('../input/validation-result/bertofa_valresult.csv')\n",
        "\n",
        "df_distilbert=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/FineTuneModel/ValidationResult/distilbert_valresult.csv')\n",
        "df_deberta=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/FineTuneModel/ValidationResult/deberta_valresult.csv')\n",
        "df_bertofa=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/FineTuneModel/ValidationResult/bertofa_valresult.csv')\n",
        "\n",
        "ypred_distilbert = torch.from_numpy(df_distilbert.loc[:,['Adequate','Effective','Ineffective']].values)\n",
        "ypred_deberta = torch.from_numpy(df_deberta.loc[:,['Adequate','Effective','Ineffective']].values)\n",
        "ypred_bertofa = torch.from_numpy(df_bertofa.loc[:,['Adequate','Effective','Ineffective']].values)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:27.427908Z",
          "iopub.execute_input": "2022-08-03T12:57:27.428360Z",
          "iopub.status.idle": "2022-08-03T12:57:29.855699Z",
          "shell.execute_reply.started": "2022-08-03T12:57:27.428317Z",
          "shell.execute_reply": "2022-08-03T12:57:29.854574Z"
        },
        "trusted": true,
        "id": "TLzipWEkelDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize weights for ensembling"
      ],
      "metadata": {
        "id": "lx7thW1gelDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weight ={\n",
        "        'deberta':0.10,\n",
        "        'distilbert':0.50,\n",
        "        'bertofa':0.40,\n",
        "#         'distilroberta':0.25\n",
        "        }"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:29.856935Z",
          "iopub.execute_input": "2022-08-03T12:57:29.857259Z",
          "iopub.status.idle": "2022-08-03T12:57:29.863088Z",
          "shell.execute_reply.started": "2022-08-03T12:57:29.857229Z",
          "shell.execute_reply": "2022-08-03T12:57:29.861662Z"
        },
        "trusted": true,
        "id": "A87X_zcxelDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility Function for Exploration"
      ],
      "metadata": {
        "id": "K_OnA8xHelDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert prediction in tensor format to argmax numpy format\n",
        "def pred_to_argmax(y_pred,df,model_name):\n",
        "    argmax_output = y_pred.argmax(dim=1)\n",
        "    argmax_output = argmax_output.numpy()\n",
        "    df = pd.concat([df.reset_index(drop=True),pd.DataFrame(argmax_output,columns=[f'pred_effectiveness_{model_name}'])], axis=1)\n",
        "    df[f'pred_effectiveness_{model_name}'] = df[f'pred_effectiveness_{model_name}'].map({0:'Adequate',1:'Effective',2:'Ineffective'})\n",
        "    return df\n",
        "\n",
        "#Plot confusion matrix\n",
        "def do_conf_matrix(y_true, y_pred, ax, title=None):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=attributes)\n",
        "    cm\n",
        "\n",
        "    sns.heatmap(cm/np.sum(cm), annot=True, fmt='.2%', ax=ax, cmap='Blues');  \n",
        "    \n",
        "    \n",
        "    # labels, title and ticks\n",
        "    ax.set_xlabel('Predicted labels');\n",
        "    ax.set_ylabel('True labels'); \n",
        "    ax.set_title(f'Confusion Matrix - {title}'); \n",
        "\n",
        "    ax.xaxis.set_ticklabels(attributes)\n",
        "    ax.yaxis.set_ticklabels(attributes);\n",
        "\n",
        "# Calculate metrics\n",
        "def calculate_score(y_pred,df):\n",
        "    cel = nn.CrossEntropyLoss()\n",
        "    f1 = f1_score(y_pred.argmax(dim=1),torch.tensor(df['discourse_effectiveness_numeric'].values),num_classes=3,average=None)\n",
        "    f1_weighted = f1_score(y_pred.softmax(dim=1),torch.tensor(df['discourse_effectiveness_numeric'].values),num_classes=3,multiclass=True,average='weighted')\n",
        "    loss = cel(y_pred,torch.tensor(df['discourse_effectiveness_numeric'].values))\n",
        "    \n",
        "    return f1, f1_weighted, loss\n",
        "\n",
        "# Main validation function\n",
        "def validate_result(y_pred_deberta,y_pred_distilbert,y_pred_bertofa,weight,val_path,preds):\n",
        "\n",
        "#     y_pred_overall = (y_pred_deberta*weight[preds[0]] + y_pred_distilbert*weight[preds[1]] + y_pred_bertofa*weight[preds[2]])/(weight[preds[0]]+weight[preds[1]]+weight[preds[2]])\n",
        "    \n",
        "    weight_deberta = torch.tensor([weight['deberta']])\n",
        "    weight_distilbert = torch.tensor([weight['distilbert']])\n",
        "    weight_bertofa = torch.tensor([weight['bertofa']])\n",
        "\n",
        "    weight_deberta=weight_deberta.repeat(ypred_deberta.shape[0],1)\n",
        "    weight_distilbert=weight_distilbert.repeat(ypred_distilbert.shape[0],1)\n",
        "    weight_bertofa=weight_bertofa.repeat(ypred_bertofa.shape[0],1)\n",
        "\n",
        "#     Method 1\n",
        "#     for idx,ypred in enumerate(ypred_deberta):\n",
        "#         if (ypred[2]>ypred[0]) &(ypred[2]>ypred[1]):\n",
        "#             ratio_bertofa = weight_bertofa[idx]/(weight_distilbert[idx]+weight_deberta[idx])\n",
        "#             ratio_distilbert = weight_distilbert[idx]/(weight_bertofa[idx]+weight_deberta[idx])\n",
        "#             weight_deberta[idx]=0.35\n",
        "#             weight_bertofa[idx]=(1-weight_deberta[idx])*ratio_bertofa\n",
        "#             weight_distilbert[idx]=(1-weight_deberta[idx])*ratio_distilbert\n",
        "\n",
        "# Method 3\n",
        "    for idx,ypred in enumerate(ypred_deberta):\n",
        "        if (ypred[2]>ypred[0]) &(ypred[2]>ypred[1]):# & (ypred_distilbert[idx][2]>ypred_distilbert[idx][0]) &(ypred_distilbert[idx][2]>ypred_distilbert[idx][1]):\n",
        "            ratio_bertofa = weight_bertofa[idx]/(weight_distilbert[idx]+weight_deberta[idx])\n",
        "            ratio_distilbert = weight_distilbert[idx]/(weight_bertofa[idx]+weight_deberta[idx])\n",
        "            weight_deberta[idx]=0.6\n",
        "            weight_bertofa[idx]=0.02\n",
        "            weight_distilbert[idx]=0.38 \n",
        "\n",
        "    \n",
        "    numerator = torch.mul(ypred_deberta,weight_deberta) + torch.mul(ypred_distilbert,weight_bertofa) + torch.mul(ypred_bertofa,weight_distilbert)\n",
        "    denominator = torch.add(torch.add(weight_deberta,weight_bertofa),weight_distilbert)\n",
        "    y_pred_overall = torch.div(numerator,denominator)\n",
        "    \n",
        "#         # Method 2\n",
        "#     for idx,ypred in enumerate(y_pred_overall):\n",
        "#         if ypred[]\n",
        "#         if (ypred[2]>ypred[0]) &(ypred[2]>ypred[1])& (ypred_distilbert[idx][2]<ypred_distilbert[idx][0])& (ypred_distilbert[idx][2]<ypred_distilbert[idx][1]):\n",
        "#             ratio_bertofa = weight_bertofa[idx]/(weight_distilbert[idx]+weight_deberta[idx])\n",
        "#             ratio_distilbert = weight_distilbert[idx]/(weight_bertofa[idx]+weight_deberta[idx])\n",
        "#             weight_deberta[idx]=0.35\n",
        "#             weight_bertofa[idx]=(1-weight_deberta[idx])*ratio_bertofa\n",
        "#             weight_distilbert[idx]=(1-weight_deberta[idx])*ratio_distilbert  \n",
        "    \n",
        "    df = val_path.copy()\n",
        "    df['discourse_effectiveness_numeric'] = df['discourse_effectiveness'].map({'Adequate':0,'Effective':1,'Ineffective':2})\n",
        "    y_true = df['discourse_effectiveness'].values\n",
        "    \n",
        "\n",
        "    \n",
        "    fig, axs = plt.subplots(2,2,figsize=(20, 10))\n",
        "    \n",
        "    df = pred_to_argmax(y_pred_deberta,df,preds[0])    \n",
        "    df = pred_to_argmax(y_pred_distilbert,df,preds[1])\n",
        "    df = pred_to_argmax(y_pred_bertofa,df,preds[2])\n",
        "    df = pred_to_argmax(y_pred_overall,df,preds[3])\n",
        "    \n",
        "    print(df.info())\n",
        "    do_conf_matrix(y_true, df[f'pred_effectiveness_deberta'].values, ax=axs[0,0],title = preds[0])\n",
        "    do_conf_matrix(y_true, df[f'pred_effectiveness_distilbert'].values, ax=axs[1,0],title = preds[1])\n",
        "    do_conf_matrix(y_true, df[f'pred_effectiveness_bertofa'].values, ax=axs[0,1],title = preds[2])\n",
        "    do_conf_matrix(y_true, df[f'pred_effectiveness_OVERALL'].values, ax=axs[1,1],title = preds[3])\n",
        "\n",
        "    output1 = calculate_score(y_pred_deberta,df)\n",
        "    output2 = calculate_score(y_pred_distilbert,df)\n",
        "    output3 = calculate_score(y_pred_bertofa,df)\n",
        "    output4 = calculate_score(y_pred_overall,df)\n",
        "\n",
        "    return output1, output2, output3, output4\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:29.865247Z",
          "iopub.execute_input": "2022-08-03T12:57:29.866201Z",
          "iopub.status.idle": "2022-08-03T12:57:29.893339Z",
          "shell.execute_reply.started": "2022-08-03T12:57:29.866154Z",
          "shell.execute_reply": "2022-08-03T12:57:29.891881Z"
        },
        "trusted": true,
        "id": "FpMDLCBjelDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "preds = ['deberta','distilbert','bertofa','OVERALL']\n",
        "\n",
        "output1, output2, output3, output4 = validate_result(ypred_deberta,ypred_distilbert,ypred_bertofa,weight,val_path, preds)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:29.895056Z",
          "iopub.execute_input": "2022-08-03T12:57:29.895854Z",
          "iopub.status.idle": "2022-08-03T12:57:31.874857Z",
          "shell.execute_reply.started": "2022-08-03T12:57:29.895806Z",
          "shell.execute_reply": "2022-08-03T12:57:31.873826Z"
        },
        "trusted": true,
        "id": "JUGz3Y0AelDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read F1 Score for each class"
      ],
      "metadata": {
        "id": "KPo_VKMtelDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "f1_score_df = pd.DataFrame({'deberta':output1[0].tolist(),\n",
        "                         'distilbert':output2[0].tolist(),\n",
        "                         'bertofa':output3[0].tolist(),\n",
        "                         'overall':output4[0].tolist(),\n",
        "                            })\n",
        "f1_score_df['label']=attributes\n",
        "f1_score_df.set_index(['label'])\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:31.877882Z",
          "iopub.execute_input": "2022-08-03T12:57:31.878292Z",
          "iopub.status.idle": "2022-08-03T12:57:31.903789Z",
          "shell.execute_reply.started": "2022-08-03T12:57:31.878259Z",
          "shell.execute_reply": "2022-08-03T12:57:31.902952Z"
        },
        "trusted": true,
        "id": "-12zMapoelDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read weighted average f1 score from various models, including ensembled model"
      ],
      "metadata": {
        "id": "djCuVKrbelDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1_weight_score = []\n",
        "f1_weight_score.append(output1[1].item())\n",
        "f1_weight_score.append(output2[1].item())\n",
        "f1_weight_score.append(output3[1].item())\n",
        "f1_weight_score.append(output4[1].item())\n",
        "f1_weight_score\n",
        "\n",
        "logloss_score = []\n",
        "logloss_score.append(output1[2].item())\n",
        "logloss_score.append(output2[2].item())\n",
        "logloss_score.append(output3[2].item())\n",
        "logloss_score.append(output4[2].item())\n",
        "logloss_score\n",
        "\n",
        "score_df = pd.DataFrame({'f1_weighted_score':f1_weight_score})\n",
        "score_df['log loss'] = logloss_score\n",
        "score_df['model']=preds\n",
        "score_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:31.907806Z",
          "iopub.execute_input": "2022-08-03T12:57:31.908510Z",
          "iopub.status.idle": "2022-08-03T12:57:31.924696Z",
          "shell.execute_reply.started": "2022-08-03T12:57:31.908474Z",
          "shell.execute_reply": "2022-08-03T12:57:31.923324Z"
        },
        "trusted": true,
        "id": "RFG_EABKelDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # y_pred_overall = (y_pred_deberta*weight['deberta'] + y_pred_distilroberta*weight['distilbert'] + y_pred_bertofa*weight['bertofa'] + y_pred_distilbert*weight['distilroberta'])/4\n",
        "# y_pred_overall = (y_pred_deberta*weight['deberta'] + y_pred_distilbert*weight['distilbert'] + y_pred_bertofa*weight['bertofa'])/(weight['deberta']+weight['distilbert']+weight['bertofa'])\n",
        "\n",
        "\n",
        "# argmax_output = y_pred_overall.argmax(dim=1)\n",
        "# argmax_output = argmax_output.numpy()\n",
        "# output_overall_df = pd.concat([val_df.reset_index(drop=True), pd.DataFrame(argmax_output,columns=['pred_discourse_effectiveness'])], axis=1)\n",
        "# output_overall_df['pred_discourse_effectiveness'] = output_overall_df['pred_discourse_effectiveness'].map({0:'Adequate',1:'Effective',2:'Ineffective'})\n",
        "# #Plot Confusion Matrix\n",
        "# y_true = output_df['discourse_effectiveness'].values\n",
        "# y_pred = output_df['pred_discourse_effectiveness'].values\n",
        "# ax= plt.subplot()\n",
        "# do_conf_matrix(y_true, y_pred, ax=ax)\n",
        "# output_overall_df['discourse_effectiveness_numeric'] = output_overall_df['discourse_effectiveness'].map({'Adequate':0,'Effective':1,'Ineffective':2})\n",
        "# output_overall_df.info()\n",
        "# f1 = f1_score(y_pred_overall.argmax(dim=1),torch.tensor(output_overall_df['discourse_effectiveness_numeric'].values),average=None)\n",
        "# f1\n",
        "# f1_weighted = f1_score(y_pred_overall.softmax(dim=1),torch.tensor(output_overall_df['discourse_effectiveness_numeric'].values),num_classes=3,multiclass=True,average='weighted')\n",
        "# f1_weighted\n",
        "# cel = nn.CrossEntropyLoss()\n",
        "# loss = cel(y_pred_overall,torch.tensor(output_overall_df['discourse_effectiveness_numeric'].values))\n",
        "# loss"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:31.926586Z",
          "iopub.execute_input": "2022-08-03T12:57:31.927565Z",
          "iopub.status.idle": "2022-08-03T12:57:31.932939Z",
          "shell.execute_reply.started": "2022-08-03T12:57:31.927528Z",
          "shell.execute_reply": "2022-08-03T12:57:31.931721Z"
        },
        "trusted": true,
        "id": "DOzp3b2kelDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read text with wrong classification"
      ],
      "metadata": {
        "id": "APR_t8xQelDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_overall = (ypred_deberta*weight['deberta'] + ypred_distilbert*weight['distilbert'] + ypred_bertofa*weight['bertofa'])/(weight['deberta']+weight['distilbert']+weight['bertofa'])\n",
        "argmax_output = y_pred_overall.argmax(dim=1)\n",
        "argmax_output = argmax_output.numpy()\n",
        "output_overall_df = pd.concat([val_df.reset_index(drop=True), pd.DataFrame(argmax_output,columns=['pred_discourse_effectiveness'])], axis=1)\n",
        "output_overall_df['pred_discourse_effectiveness'] = output_overall_df['pred_discourse_effectiveness'].map({0:'Adequate',1:'Effective',2:'Ineffective'})\n",
        "\n",
        "output_overall_df.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T12:57:31.936143Z",
          "iopub.execute_input": "2022-08-03T12:57:31.937113Z",
          "iopub.status.idle": "2022-08-03T12:57:31.966187Z",
          "shell.execute_reply.started": "2022-08-03T12:57:31.937075Z",
          "shell.execute_reply": "2022-08-03T12:57:31.965295Z"
        },
        "trusted": true,
        "id": "pigFdTJselDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bad_pred_df = output_overall_df[output_overall_df['pred_discourse_effectiveness']!=output_overall_df['discourse_effectiveness']]\n",
        "ineffective_bad_pred_df = bad_pred_df.loc[(bad_pred_df['pred_discourse_effectiveness']!=bad_pred_df['discourse_effectiveness'])& (bad_pred_df['discourse_effectiveness']=='Ineffective')]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T13:04:35.292119Z",
          "iopub.execute_input": "2022-08-03T13:04:35.292517Z",
          "iopub.status.idle": "2022-08-03T13:04:35.303554Z",
          "shell.execute_reply.started": "2022-08-03T13:04:35.292485Z",
          "shell.execute_reply": "2022-08-03T13:04:35.302414Z"
        },
        "trusted": true,
        "id": "v0LWsjeaelDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_text(ids):\n",
        "    # with open(f'../input/feedback-prize-effectiveness/train/{ids}.txt', 'r') as file: data = file.read()\n",
        "    with open(f'/content/drive/MyDrive/Colab Notebooks/Data/train/{ids}.txt', 'r') as file: data = file.read()\n",
        "    return data\n",
        "\n",
        "def display_sample(essay_id,bad_df,train_df):\n",
        "    char_pos = 0\n",
        "    ex = [{\"text\": '',\"ents\": [],\"title\":\"\"}]\n",
        "    ex2 = [{\"text\": '',\"ents\": [],\"title\":\"\"}]\n",
        "    text = ''\n",
        "    for idx in range(train_df.loc[(train_df['essay_id']==essay_id)].shape[0]):\n",
        "        \n",
        "        discourse_text = train_df.loc[(df.essay_id == essay_id),'discourse_text'].values[idx]\n",
        "        discourse_text = resolve_encodings_and_normalize(discourse_text)\n",
        "        begin = char_pos\n",
        "        end = begin + len(discourse_text)\n",
        "        discoursetype = train_df.loc[(train_df.essay_id == essay_id),'discourse_type'].values[idx]\n",
        "        discourse_id = train_df.loc[(train_df.essay_id == essay_id),'discourse_id'].values[idx]\n",
        "        \n",
        "        if bad_df[bad_df.discourse_id == discourse_id].shape[0] != 0:\n",
        "            label_bad = bad_df.loc[(bad_df.discourse_id == discourse_id),'pred_discourse_effectiveness'].values[0]\n",
        "            label_good = bad_df.loc[(bad_df.discourse_id == discourse_id),'discourse_effectiveness'].values[0]\n",
        "            ex[0]['ents'].append({\"start\":begin,\n",
        "                  \"end\":end,\n",
        "                  \"label\":label_bad + '/' + label_good+ ' (Predict/True)' + ' - ' + discoursetype\n",
        "                    })\n",
        "\n",
        "            ex2[0]['ents'].append({\"start\":begin,\n",
        "                  \"end\":end,\n",
        "                  \"label\":label_good + ' - ' + discoursetype + ' (True)'\n",
        "                    })\n",
        "        char_pos = end\n",
        "        text += discourse_text\n",
        "    ex[0]['text']=text\n",
        "    ex2[0]['text']=text\n",
        "    ex[0]['title']=f\"Essay ID: {essay_id}\"\n",
        "    displacy.render(ex, style=\"ent\", manual=True,jupyter=True,options={\"distance\":100})\n",
        "    print()\n",
        "#     displacy.render(ex2, style=\"ent\", manual=True,jupyter=True,options={\"distance\":100})\n",
        "    return\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T13:04:59.977027Z",
          "iopub.execute_input": "2022-08-03T13:04:59.978118Z",
          "iopub.status.idle": "2022-08-03T13:04:59.993103Z",
          "shell.execute_reply.started": "2022-08-03T13:04:59.978071Z",
          "shell.execute_reply": "2022-08-03T13:04:59.991805Z"
        },
        "trusted": true,
        "id": "rQJGM4yCelDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_id = ineffective_bad_pred_df.sample(1)['essay_id'].values[0]\n",
        "display_sample(sample_id,bad_pred_df,data_path.sort_index())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T13:07:10.255337Z",
          "iopub.execute_input": "2022-08-03T13:07:10.255837Z",
          "iopub.status.idle": "2022-08-03T13:07:10.332695Z",
          "shell.execute_reply.started": "2022-08-03T13:07:10.255800Z",
          "shell.execute_reply": "2022-08-03T13:07:10.331173Z"
        },
        "trusted": true,
        "id": "m2cJEGCCelDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PREDICTION AND KAGGLE SUBMISSION\n",
        "---\n",
        "\n",
        "https://www.kaggle.com/competitions/feedback-prize-effectiveness\n"
      ],
      "metadata": {
        "id": "jnvJg9SLty00"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main function to execute prediction on test dataset"
      ],
      "metadata": {
        "id": "vSfLG9yGelDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(_Text_Classifier,config):\n",
        "    try:\n",
        "      data_path = pd.read_csv('/kaggle/input/feedback-prize-effectiveness/train.csv')\n",
        "      test_path = pd.read_csv('/kaggle/input/feedback-prize-effectiveness/test.csv')\n",
        "    except:\n",
        "      data_path = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/train.csv')\n",
        "      test_path = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/test.csv')\n",
        "\n",
        "    attributes = [\"Adequate\" ,\"Effective\",\"Ineffective\"]\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(config['model_name'], use_fast=True)\n",
        "    le = LabelEncoder()\n",
        "    \n",
        "    # Initialize data module\n",
        "    test_data_module = _Data_Module(data_path,\n",
        "                                    test_path,\n",
        "                                    attributes,\n",
        "                                    le,\n",
        "                                    tokenizer,\n",
        "                                    config['model_name'],\n",
        "                                    batch_size=config['batch_size'],\n",
        "                                    text_method = config['text_method']\n",
        "                                   )\n",
        "    test_data_module.setup()\n",
        "\n",
        "    # Initialize Model\n",
        "    model = _Text_Classifier(config,test_data_module)\n",
        "    model.load_state_dict(torch.load(config['PATH']))\n",
        "\n",
        "    # Initialize Trainer\n",
        "    trainer = pl.Trainer(accelerator='auto')\n",
        "\n",
        "    # Run predictions\n",
        "    def predict_text_classification(model, dm):\n",
        "        predictions = trainer.predict(model, datamodule=dm)\n",
        "        return predictions\n",
        "    predictions = predict_text_classification(model, test_data_module)\n",
        "\n",
        "    # Pass logit into a softmax\n",
        "    pred_list = []\n",
        "    for logits in predictions:\n",
        "        pred_list.append(logits)\n",
        "    y_pred = torch.cat(pred_list)\n",
        "    y_pred.shape\n",
        "\n",
        "    softmax_outputs = softmax(y_pred, axis=1)\n",
        "    test_df = test_path.copy()\n",
        "    output_df = pd.concat([test_df[['discourse_id']].reset_index(drop=True), pd.DataFrame(softmax_outputs.numpy(), columns=attributes)], axis=1)\n",
        "#     output_df = pd.concat([test_df[['discourse_id']].reset_index(drop=True), pd.DataFrame(y_pred.numpy(), columns=attributes)], axis=1)\n",
        "    new_cols = [\"discourse_id\",\"Ineffective\",\"Adequate\",\"Effective\"]\n",
        "    output_df = output_df[new_cols]\n",
        "\n",
        "    return output_df, y_pred"
      ],
      "metadata": {
        "id": "RgBhridfs8uF",
        "execution": {
          "iopub.status.busy": "2022-08-03T04:05:44.306196Z",
          "iopub.execute_input": "2022-08-03T04:05:44.306511Z",
          "iopub.status.idle": "2022-08-03T04:05:44.320763Z",
          "shell.execute_reply.started": "2022-08-03T04:05:44.306478Z",
          "shell.execute_reply": "2022-08-03T04:05:44.319680Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict using multiple models"
      ],
      "metadata": {
        "id": "J-pfZwOjelDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "output_DeBerta, y_pred_deberta = predict(DeBerta_Text_Classifier,deberta_config)\n",
        "output_DistilBert, y_pred_distilbert = predict(DistilBert_Text_Classifier,distilbert_config)\n",
        "output_BertOFA, y_pred_bertofa = predict(BertOFA_Text_Classifier,bertofa_config)\n",
        "# output_distilRoBerta = predict(DistilRoBerta_Text_Classifier,distilroberta_config)\n",
        "\n"
      ],
      "metadata": {
        "id": "D871lnt73fYK",
        "execution": {
          "iopub.status.busy": "2022-08-03T04:05:44.322607Z",
          "iopub.execute_input": "2022-08-03T04:05:44.323097Z",
          "iopub.status.idle": "2022-08-03T04:07:17.567180Z",
          "shell.execute_reply.started": "2022-08-03T04:05:44.323056Z",
          "shell.execute_reply": "2022-08-03T04:07:17.564718Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# output_df = output_DeBerta.copy()\n",
        "\n",
        "# for attribute in attributes:\n",
        "#     output_df[attribute] =  (output_DeBerta[attribute]*weight['deberta'] + \n",
        "#                             output_DistilBert[attribute]*weight['distilbert'] + \n",
        "#                             output_BertOFA[attribute]*weight['bertofa'])/(weight['deberta']+weight['distilbert']+weight['bertofa'])\n",
        "# for atttribute in attributes:\n",
        "#     output_df[attribute] =  (output_DeBerta[attribute]*weight['deberta'] + \n",
        "#                             output_DistilBert[attribute]*weight['distilbert'] + \n",
        "#                             output_BertOFA[attribute]*weight['bertofa'] +\n",
        "#                             output_distilRoBerta[attribute]*weight['distilroberta'])/4\n",
        "\n",
        "# output_df"
      ],
      "metadata": {
        "id": "IubxfQVeR8OD",
        "execution": {
          "iopub.status.busy": "2022-08-03T04:07:17.569883Z",
          "iopub.execute_input": "2022-08-03T04:07:17.571288Z",
          "iopub.status.idle": "2022-08-03T04:07:17.589588Z",
          "shell.execute_reply.started": "2022-08-03T04:07:17.571214Z",
          "shell.execute_reply": "2022-08-03T04:07:17.587908Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble predicted values by various model and pass it to softmax to normalize data to be between 0 to 1"
      ],
      "metadata": {
        "id": "ZImXNWskelDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weight_deberta = torch.tensor([weight['deberta']])\n",
        "weight_distilbert = torch.tensor([weight['distilbert']])\n",
        "weight_bertofa = torch.tensor([weight['bertofa']])\n",
        "\n",
        "weight_deberta=weight_deberta.repeat(y_pred_deberta.shape[0],1)\n",
        "weight_distilbert=weight_distilbert.repeat(y_pred_distilbert.shape[0],1)\n",
        "weight_bertofa=weight_bertofa.repeat(y_pred_bertofa.shape[0],1)\n",
        "        \n",
        "for idx,ypred in enumerate(y_pred_deberta):\n",
        "    if (ypred[2]>ypred[0]) &(ypred[2]>ypred[1]):\n",
        "        ratio_bertofa = weight_bertofa[idx]/(weight_distilbert[idx]+weight_deberta[idx])\n",
        "        ratio_distilbert = weight_distilbert[idx]/(weight_bertofa[idx]+weight_deberta[idx])\n",
        "        weight_deberta[idx]=0.6\n",
        "        weight_bertofa[idx]=0.02\n",
        "        weight_distilbert[idx]=0.38 \n",
        "        \n",
        "numerator = torch.mul(y_pred_deberta,weight_deberta) + torch.mul(y_pred_distilbert,weight_bertofa) + torch.mul(y_pred_bertofa,weight_distilbert)\n",
        "denominator = torch.add(torch.add(weight_deberta,weight_bertofa),weight_distilbert)\n",
        "y_pred_overall = torch.div(numerator,denominator)\n",
        "\n",
        "softmax_outputs = softmax(y_pred_overall, axis=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T04:09:08.946409Z",
          "iopub.execute_input": "2022-08-03T04:09:08.947017Z",
          "iopub.status.idle": "2022-08-03T04:09:08.965510Z",
          "shell.execute_reply.started": "2022-08-03T04:09:08.946972Z",
          "shell.execute_reply": "2022-08-03T04:09:08.964545Z"
        },
        "trusted": true,
        "id": "01e3bxkUelDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataframe for submission\n",
        "output_df = pd.concat([test_path[['discourse_id']].reset_index(drop=True), pd.DataFrame(softmax_outputs.numpy(), columns=attributes)], axis=1)\n",
        "#     output_df = pd.concat([test_df[['discourse_id']].reset_index(drop=True), pd.DataFrame(y_pred.numpy(), columns=attributes)], axis=1)\n",
        "\n",
        "# Re-arrange columns\n",
        "new_cols = [\"discourse_id\",\"Ineffective\",\"Adequate\",\"Effective\"]\n",
        "output_df = output_df[new_cols]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-03T04:09:19.157807Z",
          "iopub.execute_input": "2022-08-03T04:09:19.158521Z",
          "iopub.status.idle": "2022-08-03T04:09:19.168002Z",
          "shell.execute_reply.started": "2022-08-03T04:09:19.158483Z",
          "shell.execute_reply": "2022-08-03T04:09:19.166831Z"
        },
        "trusted": true,
        "id": "D0VC6WZbelDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_df.to_csv('/content/drive/MyDrive/Colab Notebooks/FineTuneModel/ValidationResult/submission.csv', index=False)\n",
        "pd.read_csv('/content/drive/MyDrive/Colab Notebooks/FineTuneModel/ValidationResult/submission.csv')"
      ],
      "metadata": {
        "id": "NylMBGU1P-z6",
        "execution": {
          "iopub.status.busy": "2022-08-03T04:09:23.166366Z",
          "iopub.execute_input": "2022-08-03T04:09:23.166736Z",
          "iopub.status.idle": "2022-08-03T04:09:23.187501Z",
          "shell.execute_reply.started": "2022-08-03T04:09:23.166702Z",
          "shell.execute_reply": "2022-08-03T04:09:23.186294Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EmQBtJt5elDh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}